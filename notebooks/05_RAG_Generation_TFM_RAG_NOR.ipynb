{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be7a6b7c",
   "metadata": {},
   "source": [
    "# RAG Generation en TFM_RAG_NOR\n",
    "\n",
    "## Índice\n",
    "\n",
    "\n",
    "1. [Introducción y objetivos](#1-introducción-y-objetivos)\n",
    "2. [Carga de datos y configuración](#2-carga-de-datos-y-configuración)\n",
    "3. [Pipeline RAG: Recuperación + Generación](#3-pipeline-rag-recuperación--generación)\n",
    "    - 3.1. Recuperación de chunks relevantes (Hybrid MPNet α=0.3)\n",
    "    - 3.2. Construcción del prompt\n",
    "    - 3.3. Generación de respuesta con LLM\n",
    "    - 3.4. Visualización de resultados (respuesta + chunks)\n",
    "4. [Evaluación de la generación](#4-evaluación-de-la-generación)\n",
    "    - 4.1. Evaluación manual (exactitud, completitud, estilo)\n",
    "    - 4.2. Evaluación automática (BERTScore y opcionalmente métricas RAGAS simples)\n",
    "5. [Demo tester](#5-demo-tester) \n",
    "6. [Extensión con modelos entrenados](#6-Extensión-con-modelos-entrenados)\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Introducción y objetivos\n",
    "\n",
    "En este notebook se implementa la fase de generación del sistema RAG sobre el corpus de documentos normativos.  \n",
    "Hasta ahora se han preparado los datos, creado los índices y evaluado diferentes métodos de recuperación. El mejor rendimiento lo dio el método híbrido BM25 + MPNet (α=0.3), que será el que se use aquí como base.\n",
    "\n",
    "El objetivo es montar un pipeline completo de RAG (retrieval → generación), capaz de:\n",
    "- Recuperar los chunks más relevantes para una query.\n",
    "- Construir un prompt con esos chunks y la pregunta.\n",
    "- Enviar el prompt a un LLM open-source vía API gratuita.\n",
    "- Obtener una respuesta fundamentada en los documentos recuperados.\n",
    "- Guardar y evaluar las respuestas generadas.\n",
    "\n",
    "Este notebook servirá como prototipo mínimo viable de RAG, sobre el que se podrá analizar el alcance, limitaciones y posibles mejoras.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Carga de datos y configuración\n",
    "\n",
    "En esta parte se importan las librerías necesarias, se cargan los datos de soporte (benchmark de preguntas y respuestas) y se configuran las claves de acceso para el modelo de lenguaje.  \n",
    "\n",
    "También se definen las rutas de trabajo (`data/`, `results/`) y se cargan las funciones de recuperación que ya se usaron en la fase anterior para garantizar coherencia.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97554646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in d:\\tfm_rag_nor\\venv\\lib\\site-packages (1.101.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from openai) (0.10.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from openai) (2.11.7)\n",
      "Requirement already satisfied: sniffio in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from openai) (4.14.1)\n",
      "Requirement already satisfied: idna>=2.8 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2025.7.14)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
      "Requirement already satisfied: colorama in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621ad324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preguntas cargadas: 150\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from openai import OpenAI\n",
    "\n",
    "DATA_PATH = \"../data/\"\n",
    "RESULTS_PATH = \"../results/\"\n",
    "os.makedirs(RESULTS_PATH, exist_ok=True)\n",
    "\n",
    "with open(os.path.join(DATA_PATH, \"eval\", \"qa_eval_set.json\"), \"r\", encoding=\"utf-8\") as f:\n",
    "    qa_eval_set = json.load(f)\n",
    "\n",
    "print(\"Preguntas cargadas:\", len(qa_eval_set))\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=\"api_key\",\n",
    "    base_url=\"https://api.groq.com/openai/v1\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084b7262",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Pipeline RAG: Recuperación + Generación\n",
    "\n",
    "### 3.1. Recuperación de chunks relevantes (Hybrid MPNet α=0.3)\n",
    "\n",
    "En esta parte se reutilizan los índices creados en la fase anterior para recuperar los chunks más relevantes a partir de una query.  \n",
    "Se aplicará el mismo pipeline de preprocesado y combinación híbrida (BM25 + MPNet con α=0.3) que dio los mejores resultados en la evaluación.  \n",
    "\n",
    "El objetivo es garantizar que cualquier nueva pregunta, ya sea escrita a mano o tomada del benchmark, pase por el mismo proceso de recuperación coherente antes de la generación de respuesta.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6dc6a92a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipywidgets in d:\\tfm_rag_nor\\venv\\lib\\site-packages (8.1.7)\n",
      "Requirement already satisfied: comm>=0.1.3 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from ipywidgets) (0.2.3)\n",
      "Requirement already satisfied: ipython>=6.1.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from ipywidgets) (9.4.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.14 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from ipywidgets) (4.0.14)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from ipywidgets) (3.0.15)\n",
      "Requirement already satisfied: colorama in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.4.6)\n",
      "Requirement already satisfied: decorator in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (3.0.51)\n",
      "Requirement already satisfied: pygments>=2.4.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (2.19.2)\n",
      "Requirement already satisfied: stack_data in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: wcwidth in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: executing>=1.2.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "006e56dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pdf': 'ai_hleg_ethics_guidelines.pdf', 'pages': [], 'titles': [], 'chunk_index': 50, 'n_words': 300} Fundamental rights: Did you carry out a fundamental rights impact assessment where there could be a negative impact on fundamental rights? Did you identify and document potential trade-offs made betwe ...\n",
      "\n",
      "{'pdf': 'ai_hleg_ethics_guidelines.pdf', 'pages': [32], 'titles': ['6. Societal and environmental well-being'], 'chunk_index': 56, 'n_words': 300} a set of procedures to avoid creating or reinforcing unfair bias in the AI system, both regarding the use of input data as well as for the algorithm design? Did you assess and acknowledge the possible ...\n",
      "\n",
      "{'pdf': 'ai_hleg_ethics_guidelines.pdf', 'pages': [], 'titles': [], 'chunk_index': 55, 'n_words': 300} in mind from the start? Did you research and try to use the simplest and most interpretable model possible for the application in question? Did you assess whether you can analyse your training and tes ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import pickle\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import json\n",
    "\n",
    "# BM25\n",
    "with open(\"../data/bm25/bm25_index.pkl\", \"rb\") as f:\n",
    "    bm25 = pickle.load(f)\n",
    "\n",
    "# FAISS MPNet\n",
    "faiss_index = faiss.read_index(\"../data/faiss_index/faiss_index_mpnet.faiss\")\n",
    "\n",
    "# Cargar chunks y metadatos (listas)\n",
    "with open(\"../data/chunks/texts.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    texts = json.load(f)\n",
    "\n",
    "with open(\"../data/chunks/metadata.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    metadata = json.load(f)\n",
    "\n",
    "# Modelo embeddings MPNet\n",
    "mpnet_model = SentenceTransformer(\"sentence-transformers/all-mpnet-base-v2\")\n",
    "\n",
    "def preprocess(text):\n",
    "    return text.lower().strip()\n",
    "\n",
    "def hybrid_retrieval(query, alpha=0.3, top_k=3):\n",
    "    q = preprocess(query)\n",
    "\n",
    "    # BM25\n",
    "    tokenized_q = q.split()\n",
    "    bm25_scores = bm25.get_scores(tokenized_q)\n",
    "\n",
    "    # MPNet\n",
    "    q_emb = mpnet_model.encode([q])\n",
    "    D, I = faiss_index.search(q_emb, len(texts))\n",
    "    mpnet_scores = [0] * len(texts)\n",
    "    for idx, score in zip(I[0], D[0]):\n",
    "        mpnet_scores[idx] = float(score)\n",
    "\n",
    "    # Híbrido\n",
    "    hybrid_scores = [\n",
    "        alpha * mpnet_scores[i] + (1 - alpha) * bm25_scores[i]\n",
    "        for i in range(len(texts))\n",
    "    ]\n",
    "\n",
    "    # Top-k\n",
    "    ranked = sorted(enumerate(hybrid_scores), key=lambda x: x[1], reverse=True)[:top_k]\n",
    "\n",
    "    # Devolver chunks\n",
    "    results = []\n",
    "    for idx, score in ranked:\n",
    "        results.append({\n",
    "            \"chunk\": texts[idx],\n",
    "            \"meta\": metadata[idx],\n",
    "            \"score\": score\n",
    "        })\n",
    "    return results\n",
    "\n",
    "# Test\n",
    "test_query = \"What principles does UNESCO establish on AI ethics?\"\n",
    "chunks = hybrid_retrieval(test_query, alpha=0.3, top_k=3)\n",
    "for c in chunks:\n",
    "    print(c[\"meta\"], c[\"chunk\"][:200], \"...\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052e0919",
   "metadata": {},
   "source": [
    "### 3.2. Construcción del prompt\n",
    "\n",
    "Se genera un prompt que combina la pregunta del usuario con los chunks recuperados.  \n",
    "El prompt incluye referencias al documento y página de cada chunk, de forma que el modelo pueda usar esa información como contexto y devolver una respuesta fundamentada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a031dee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What principles does UNESCO establish on AI ethics?\n",
      "\n",
      "Context:\n",
      "[Doc: ai_hleg_ethics_guidelines.pdf, page: []]\n",
      "Fundamental rights: Did you carry out a fundamental rights impact assessment where there could be a negative impact on fundamental rights? Did you identify and document potential trade-offs made between the different principles and rights? Does the AI system interact with decisions by human (end) users (e.g. recommended actions or decisions to take, presenting of options)? Could the AI system affect human autonomy by interfering with the (end) user s decision-making process in an unintended way? Did you consider whether the AI system should communicate to (end) users that a decision, content, advice or outcome is the result of an algorithmic decision? In case of a chat bot ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def build_prompt(query, chunks):\n",
    "    context_parts = []\n",
    "    for c in chunks:\n",
    "        ref = f\"[Doc: {c['meta']['pdf']}, page: {c['meta']['pages']}]\"\n",
    "        text = c[\"chunk\"]\n",
    "        context_parts.append(f\"{ref}\\n{text}\")\n",
    "    \n",
    "    context = \"\\n\\n\".join(context_parts)\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "Question: {query}\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Instruction:\n",
    "Answer the question using only the context above.\n",
    "If the answer is not in the documents, say clearly that it is not found.\n",
    "Always include the reference (Doc and page).\n",
    "\"\"\"\n",
    "    return prompt.strip()\n",
    "\n",
    "# Test\n",
    "prompt_example = build_prompt(test_query, chunks)\n",
    "print(prompt_example[:800], \"...\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a351bcda",
   "metadata": {},
   "source": [
    "### 3.3. Generación de respuesta con LLM\n",
    "\n",
    "Se conecta con el modelo `llama-3.1-8b-instant` servido por Groq a través de la API compatible con OpenAI.  \n",
    "Se envía el prompt generado y se obtiene como salida una respuesta en lenguaje natural, fundamentada en los documentos recuperados.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7c8f3915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Answer ===\n",
      "\n",
      "UNESCO establishes the following principles on AI ethics:\n",
      "\n",
      "1. **Human Agency**: Ensure that AI systems are designed to augment human capabilities, and not replace them. Implement safeguards to prevent overconfidence in or overreliance on the AI system for work processes. (Doc: ai_hleg_ethics_guidelines.pdf, page: [not specified])\n",
      "\n",
      "2. **Human Oversight**: Establish mechanisms and measures to ensure human control or oversight, including audit and remedy issues related to governing AI autonomy. (Doc: ai_hleg_ethics_guidelines.pdf, page: [32])\n",
      "\n",
      "3. **Fairness and Non-Discrimination**: Establish a strategy or procedures to avoid creating or reinforcing unfair bias in the AI system, both regarding the use of input data as well as for the algorithm design. (Doc: ai_hleg_ethics_guidelines.pdf, page: [32])\n",
      "\n",
      "4. **Accessibility and Universal Design**: Ensure that the AI system accommodates diverse needs from the start, and research and try to use the simplest and most interpretable model possible for the application in question. (Doc: ai_hleg_ethics_guidelines.pdf, page: [not specified])\n",
      "\n",
      "5. **Communication**: Communicate to end-users through a disclaimer or any other means that they are interacting with an AI system and not with another human. Establish mechanisms to inform end-users on the reasons and criteria behind the AI system's outcomes. (Doc: ai_hleg_ethics_guidelines.pdf, page: [not specified])\n",
      "\n",
      "6. **Transparency**: Establish processes that consider users' feedback and use this to adapt the system. Communicate around potential or perceived risks, such as bias. (Doc: ai_hleg_ethics_guidelines.pdf, page: [not specified])\n",
      "\n",
      "These principles are based on the provided context, but it is not specified which document or page they are from.\n"
     ]
    }
   ],
   "source": [
    "def generate_response(prompt, model=\"llama-3.1-8b-instant\"):\n",
    "    completion = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an assistant specialized in AI ethics regulations.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=0.2,\n",
    "        max_tokens=512\n",
    "    )\n",
    "    return completion.choices[0].message.content.strip()\n",
    "\n",
    "# Test con el prompt de ejemplo\n",
    "response = generate_response(prompt_example)\n",
    "print(\"=== Answer ===\\n\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0308d8e9",
   "metadata": {},
   "source": [
    "### 3.4. Visualización de resultados (respuesta + chunks)\n",
    "\n",
    "Se muestra de forma ordenada la pregunta, la respuesta generada y los chunks usados, con sus metadatos (documento, página, título).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "81b4be4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Query ===\n",
      "What principles does UNESCO establish on AI ethics? \n",
      "\n",
      "=== Answer ===\n",
      "UNESCO establishes the following principles on AI ethics:\n",
      "\n",
      "1. **Human Agency**: Ensure that AI systems are designed to augment human capabilities, and not replace them. Implement safeguards to prevent overconfidence in or overreliance on the AI system for work processes. (Doc: ai_hleg_ethics_guidelines.pdf, page: [not specified])\n",
      "\n",
      "2. **Human Oversight**: Establish mechanisms and measures to ensure human control or oversight, including audit and remedy issues related to governing AI autonomy. (Doc: ai_hleg_ethics_guidelines.pdf, page: [32])\n",
      "\n",
      "3. **Fairness and Non-Discrimination**: Establish a strategy or procedures to avoid creating or reinforcing unfair bias in the AI system, both regarding the use of input data as well as for the algorithm design. (Doc: ai_hleg_ethics_guidelines.pdf, page: [32])\n",
      "\n",
      "4. **Accessibility and Universal Design**: Ensure that the AI system accommodates diverse needs from the start, and research and try to use the simplest and most interpretable model possible for the application in question. (Doc: ai_hleg_ethics_guidelines.pdf, page: [not specified])\n",
      "\n",
      "5. **Communication**: Communicate to end-users through a disclaimer or any other means that they are interacting with an AI system and not with another human. Establish mechanisms to inform end-users on the reasons and criteria behind the AI system's outcomes. (Doc: ai_hleg_ethics_guidelines.pdf, page: [not specified])\n",
      "\n",
      "6. **Transparency**: Establish processes that consider users' feedback and use this to adapt the system. Communicate around potential or perceived risks, such as bias. (Doc: ai_hleg_ethics_guidelines.pdf, page: [not specified])\n",
      "\n",
      "These principles are based on the provided context, but it is not specified which document or page they are from. \n",
      "\n",
      "=== Chunks usados ===\n",
      "- Doc: ai_hleg_ethics_guidelines.pdf | Page: [] | Title: []\n",
      "  Text: Fundamental rights: Did you carry out a fundamental rights impact assessment where there could be a negative impact on fundamental rights? Did you identify and document potential trade-offs made betwe...\n",
      "\n",
      "- Doc: ai_hleg_ethics_guidelines.pdf | Page: [32] | Title: ['6. Societal and environmental well-being']\n",
      "  Text: a set of procedures to avoid creating or reinforcing unfair bias in the AI system, both regarding the use of input data as well as for the algorithm design? Did you assess and acknowledge the possible...\n",
      "\n",
      "- Doc: ai_hleg_ethics_guidelines.pdf | Page: [] | Title: []\n",
      "  Text: in mind from the start? Did you research and try to use the simplest and most interpretable model possible for the application in question? Did you assess whether you can analyse your training and tes...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def display_result(query, response, chunks):\n",
    "    print(\"=== Query ===\")\n",
    "    print(query, \"\\n\")\n",
    "\n",
    "    print(\"=== Answer ===\")\n",
    "    print(response, \"\\n\")\n",
    "\n",
    "    print(\"=== Chunks usados ===\")\n",
    "    for c in chunks:\n",
    "        meta = c[\"meta\"]\n",
    "        doc = meta.get(\"pdf\", \"N/A\")\n",
    "        pages = meta.get(\"pages\", [])\n",
    "        title = meta.get(\"titles\", [])\n",
    "        print(f\"- Doc: {doc} | Page: {pages} | Title: {title}\")\n",
    "        print(f\"  Text: {c['chunk'][:200]}...\\n\")  # solo los primeros 200 chars\n",
    "\n",
    "\n",
    "# Ejemplo de flujo completo\n",
    "test_query = \"What principles does UNESCO establish on AI ethics?\"\n",
    "chunks = hybrid_retrieval(test_query, alpha=0.3, top_k=3)\n",
    "prompt_example = build_prompt(test_query, chunks)\n",
    "response = generate_response(prompt_example)\n",
    "\n",
    "display_result(test_query, response, chunks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d643d4c",
   "metadata": {},
   "source": [
    "## 4. Evaluación de la generación\n",
    "\n",
    "### 4.1. Evaluación manual (exactitud, completitud, estilo)\n",
    "\n",
    "La evaluación manual se centra en comprobar si las respuestas generadas cumplen con los siguientes criterios:\n",
    "\n",
    "- **Exactitud:** la respuesta es correcta según el benchmark.\n",
    "- **Completitud:** cubre todos los aspectos de la pregunta y no se queda a medias.\n",
    "- **Estilo:** la respuesta es clara, concisa y comprensible.\n",
    "\n",
    "Se utilizará una tabla con columnas para la query, la respuesta esperada, la respuesta generada y los tres criterios evaluados.  \n",
    "Esto permite tener una revisión cualitativa directa de la calidad del sistema.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "70f74d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] What is the main advisory responsibility of the European Artificial Intelligence Board according to the regulation?\n",
      "Generated: The main advisory responsibility of the European Artificial Intelligence Board according to the regulation is not explicitly stated in the provided do ...\n",
      "\n",
      "[2] Which requirement is imposed on providers of high-risk AI systems regarding post-market activities?\n",
      "Generated: The requirement imposed on providers of high-risk AI systems regarding post-market activities is to establish and document a post-market monitoring sy ...\n",
      "\n",
      "[3] How do the roles and interactions of national competent authorities, national supervisory authorities, and the European Artificial Intelligence Board contribute to the harmonised implementation and enforcement of the regulation across Member States?\n",
      "Generated: The roles and interactions of national competent authorities, national supervisory authorities, and the European Artificial Intelligence Board contrib ...\n",
      "\n",
      "[4] What are the three components that Trustworthy AI should meet throughout its entire life cycle according to the guidelines?\n",
      "Generated: According to the guidelines, Trustworthy AI should meet the following three components throughout its entire life cycle:\n",
      "\n",
      "1. It should be lawful, comp ...\n",
      "\n",
      "[5] Why does the document emphasize a holistic and systemic approach to achieving Trustworthy AI?\n",
      "Generated: The document emphasizes a holistic and systemic approach to achieving Trustworthy AI because it concerns not only the trustworthiness of the AI system ...\n",
      "\n",
      "[6] Explain how the concept of Trustworthy AI in these guidelines draws parallels with public trust in other domains, and describe how this informs the approach recommended for AI systems.\n",
      "Generated: The concept of Trustworthy AI in these guidelines draws parallels with public trust in other domains by emphasizing the importance of accountability,  ...\n",
      "\n",
      "[7] What are some example questions that help determine the transparency and explainability of an AI system according to the OECD framework?\n",
      "Generated: According to the OECD framework, the following are example questions that help determine the transparency and explainability of an AI system:\n",
      "\n",
      "1. Is i ...\n",
      "\n",
      "[8] According to the OECD framework, what aspects should policy makers consider to assess the safety, security, and robustness of AI systems?\n",
      "Generated: According to the OECD framework and the AI HLEG Ethics Guidelines, policy makers should consider the following aspects to assess the safety, security, ...\n",
      "\n",
      "[9] Describe how the OECD framework recommends assessing both the explainability and safety of an AI system throughout its lifecycle, and discuss why these factors are important for responsible AI deployment.\n",
      "Generated: The OECD framework recommends assessing both the explainability and safety of an AI system throughout its lifecycle by considering the following key c ...\n",
      "\n",
      "[10] What are the three pillars of the European Commission's vision for artificial intelligence described in the introduction?\n",
      "Generated: According to the provided context, the three pillars of the European Commission's vision for artificial intelligence are described in the introduction ...\n",
      "\n",
      "\n",
      "Resultados guardados en ../results/rag_generation_manual.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'query': 'What is the main advisory responsibility of the European Artificial Intelligence Board according to the regulation?',\n",
       "  'expected': 'The Board is responsible for issuing opinions, recommendations, advice, or guidance on matters related to the implementation of the regulation, including technical specifications or existing standards.',\n",
       "  'generated': 'The main advisory responsibility of the European Artificial Intelligence Board according to the regulation is not explicitly stated in the provided documents. However, based on the context, it can be inferred that the European Artificial Intelligence Board is expected to provide guidance and oversight on the development and deployment of artificial intelligence systems in the European Union.\\n\\nThe closest information related to the advisory responsibility of the European Artificial Intelligence Board is found in the document \"ai_hleg_ethics_guidelines.pdf\" (page 27), which mentions the importance of governance and stakeholders in implementing a trustworthy AI framework. However, this document does not specifically mention the European Artificial Intelligence Board.\\n\\nTherefore, I must conclude that the main advisory responsibility of the European Artificial Intelligence Board is not explicitly stated in the provided documents.',\n",
       "  'chunks': [{'pdf': 'eu_ai_act_regulation.pdf',\n",
       "    'pages': [2],\n",
       "    'titles': ['EXPLANATORY MEMORANDUM'],\n",
       "    'chunk_index': 1,\n",
       "    'n_words': 300},\n",
       "   {'pdf': 'oecd_legal_0449_en.pdf',\n",
       "    'pages': [],\n",
       "    'titles': [],\n",
       "    'chunk_index': 6,\n",
       "    'n_words': 300},\n",
       "   {'pdf': 'ai_hleg_ethics_guidelines.pdf',\n",
       "    'pages': [27],\n",
       "    'titles': ['HR'],\n",
       "    'chunk_index': 47,\n",
       "    'n_words': 300}],\n",
       "  'dificultad': 'easy'},\n",
       " {'query': 'Which requirement is imposed on providers of high-risk AI systems regarding post-market activities?',\n",
       "  'expected': 'All providers of high-risk AI systems must have a post-market monitoring system in place to enable corrective actions and improvements based on experience from use.',\n",
       "  'generated': 'The requirement imposed on providers of high-risk AI systems regarding post-market activities is to establish and document a post-market monitoring system in a manner that is proportionate to the nature of the artificial intelligence technologies and the risks of the high-risk AI system.\\n\\n(Doc: eu_ai_act_regulation.pdf, page: 76)\\n\\nThis post-market monitoring system shall actively and systematically collect, document and analyse relevant data provided by users or collected through other sources on the performance of high-risk AI systems throughout their lifetime, and allow the provider to evaluate the continuous compliance of AI systems with the requirements set out in Title III, Chapter 2.\\n\\n(Doc: eu_ai_act_regulation.pdf, page: 76)\\n\\nAdditionally, the post-market monitoring system shall be based on a post-market monitoring plan, which shall be part of the technical documentation referred to in Annex IV.\\n\\n(Doc: eu_ai_act_regulation.pdf, page: 76)\\n\\nProviders of high-risk AI systems shall also report any serious incident or any malfunctioning of those systems which constitutes a breach of obligations under Union law.\\n\\n(Doc: eu_ai_act_regulation.pdf, page: 76)',\n",
       "  'chunks': [{'pdf': 'eu_ai_act_regulation.pdf',\n",
       "    'pages': [76],\n",
       "    'titles': ['2.'],\n",
       "    'chunk_index': 124,\n",
       "    'n_words': 300},\n",
       "   {'pdf': 'eu_ai_act_regulation.pdf',\n",
       "    'pages': [37],\n",
       "    'titles': ['2013/36/EU of the European Parliament and of the Council56, it is also appropriate to'],\n",
       "    'chunk_index': 66,\n",
       "    'n_words': 300},\n",
       "   {'pdf': 'eu_ai_act_regulation.pdf',\n",
       "    'pages': [],\n",
       "    'titles': [],\n",
       "    'chunk_index': 28,\n",
       "    'n_words': 300}],\n",
       "  'dificultad': 'medium'},\n",
       " {'query': 'How do the roles and interactions of national competent authorities, national supervisory authorities, and the European Artificial Intelligence Board contribute to the harmonised implementation and enforcement of the regulation across Member States?',\n",
       "  'expected': \"Member States must designate one or more national competent authorities to supervise the regulation's application and implementation, including a national supervisory authority as the official point of contact. The European Artificial Intelligence Board provides advice, guidance, and recommendations to support harmonised and effective implementation of the regulation across the Union.\",\n",
       "  'generated': 'The roles and interactions of national competent authorities, national supervisory authorities, and the European Artificial Intelligence Board contribute to the harmonised implementation and enforcement of the regulation across Member States in the following ways:\\n\\n1. **National Competent Authorities**: These authorities are established or designated by each Member State to ensure the application and implementation of the regulation (Article 59, Doc: eu_ai_act_regulation.pdf, page: []). They are responsible for safeguarding the objectivity and impartiality of their activities and tasks, and must be provided with adequate financial and human resources to fulfill their tasks (Article 59, Doc: eu_ai_act_regulation.pdf, page: []). Member States must report to the Commission on an annual basis on the status of the financial and human resources of the national competent authorities (Article 59, Doc: eu_ai_act_regulation.pdf, page: []).\\n\\n2. **National Supervisory Authorities**: These authorities are designated by each Member State among the national competent authorities (Article 59, Doc: eu_ai_act_regulation.pdf, page: []). They act as notifying authority and market surveillance authority, unless a Member State has organisational and administrative reasons to designate more than one authority (Article 59, Doc: eu_ai_act_regulation.pdf, page: []).\\n\\n3. **European Artificial Intelligence Board**: The Board is composed of representatives from the Member States and the Commission (Article 56, Doc: eu_ai_act_regulation.pdf, page: []). It facilitates a smooth, effective, and harmonised implementation of the regulation by contributing to the effective cooperation of the national supervisory authorities and the Commission, and providing advice and expertise to the Commission (Article 56, Doc: eu_ai_act_regulation.pdf, page: []). The Board also collects and shares best practices among the Member States (Article 56, Doc: eu_ai_act_regulation.pdf, page: []).\\n\\nThe interactions between these entities are as follows:\\n\\n* The national competent authorities and national supervisory authorities are responsible for implementing and enforcing the regulation at the national level (Article 59, Doc: eu_ai_act_regulation.pdf, page: []).\\n* The European Artificial Intelligence Board provides advice and expertise to the Commission, and facilitates cooperation between the national supervisory authorities and the Commission (Article 56, Doc: eu_ai_act_regulation.pdf, page: []).\\n* The Board also collects and shares best practices among the Member States, which helps to ensure harmonised implementation and enforcement of the regulation (Article 56, Doc: eu_ai_act_regulation.pdf',\n",
       "  'chunks': [{'pdf': 'eu_ai_act_regulation.pdf',\n",
       "    'pages': [],\n",
       "    'titles': [],\n",
       "    'chunk_index': 122,\n",
       "    'n_words': 300},\n",
       "   {'pdf': 'eu_ai_act_regulation.pdf',\n",
       "    'pages': [16],\n",
       "    'titles': ['5.2.5.'],\n",
       "    'chunk_index': 27,\n",
       "    'n_words': 300},\n",
       "   {'pdf': 'eu_ai_act_regulation.pdf',\n",
       "    'pages': [74],\n",
       "    'titles': ['CHAPTER 2'],\n",
       "    'chunk_index': 121,\n",
       "    'n_words': 300}],\n",
       "  'dificultad': 'hard'},\n",
       " {'query': 'What are the three components that Trustworthy AI should meet throughout its entire life cycle according to the guidelines?',\n",
       "  'expected': 'Trustworthy AI should be lawful (complying with laws and regulations), ethical (adhering to ethical principles and values), and robust (both technically and socially).',\n",
       "  'generated': 'According to the guidelines, Trustworthy AI should meet the following three components throughout its entire life cycle:\\n\\n1. It should be lawful, complying with all applicable laws and regulations. \\n2. It should be ethical, ensuring adherence to ethical principles and values.\\n3. It should be robust, both from a technical and social perspective.\\n\\nThese components are mentioned on page [7] of the document \"ai_hleg_ethics_guidelines.pdf\".',\n",
       "  'chunks': [{'pdf': 'ai_hleg_ethics_guidelines.pdf',\n",
       "    'pages': [7],\n",
       "    'titles': ['1. it should be lawful, complying with all applicable laws and regulations;'],\n",
       "    'chunk_index': 7,\n",
       "    'n_words': 300},\n",
       "   {'pdf': 'ai_hleg_ethics_guidelines.pdf',\n",
       "    'pages': [],\n",
       "    'titles': [],\n",
       "    'chunk_index': 12,\n",
       "    'n_words': 300},\n",
       "   {'pdf': 'ai_hleg_ethics_guidelines.pdf',\n",
       "    'pages': [17],\n",
       "    'titles': ['1.1 Human agency and oversight'],\n",
       "    'chunk_index': 26,\n",
       "    'n_words': 300}],\n",
       "  'dificultad': 'easy'},\n",
       " {'query': 'Why does the document emphasize a holistic and systemic approach to achieving Trustworthy AI?',\n",
       "  'expected': \"Because trust in AI concerns not only the inherent properties of the technology but also the qualities of the socio-technical systems involving AI. Therefore, achieving Trustworthy AI requires considering the trustworthiness of all actors and processes in the system's socio-technical context throughout its entire life cycle.\",\n",
       "  'generated': \"The document emphasizes a holistic and systemic approach to achieving Trustworthy AI because it concerns not only the trustworthiness of the AI system itself, but also the trustworthiness of all actors and processes that are part of the system's socio-technical context throughout its entire life cycle. \\n\\nThis approach is necessary because trust in AI systems is not simply about the technology's inherent properties, but also about the qualities of the socio-technical systems involving AI applications (Doc: ai_hleg_ethics_guidelines.pdf, page: [7]). \\n\\nThe document highlights that Trustworthy AI has three components: it should be lawful, complying with all applicable laws and regulations; it should be ethical, ensuring adherence to ethical principles and values; and it should be robust, both from a technical and social perspective (Doc: ai_hleg_ethics_guidelines.pdf, page: [7]). \\n\\nA holistic and systemic approach is essential to ensure that these components are met throughout the system's entire life cycle, and that the system is trustworthy and perceived as such (Doc: ai_hleg_ethics_guidelines.pdf, page: [7]).\",\n",
       "  'chunks': [{'pdf': 'ai_hleg_ethics_guidelines.pdf',\n",
       "    'pages': [7],\n",
       "    'titles': ['1. it should be lawful, complying with all applicable laws and regulations;'],\n",
       "    'chunk_index': 7,\n",
       "    'n_words': 300},\n",
       "   {'pdf': 'ai_hleg_ethics_guidelines.pdf',\n",
       "    'pages': [],\n",
       "    'titles': [],\n",
       "    'chunk_index': 4,\n",
       "    'n_words': 300},\n",
       "   {'pdf': 'ai_hleg_ethics_guidelines.pdf',\n",
       "    'pages': [],\n",
       "    'titles': [],\n",
       "    'chunk_index': 40,\n",
       "    'n_words': 300}],\n",
       "  'dificultad': 'medium'},\n",
       " {'query': 'Explain how the concept of Trustworthy AI in these guidelines draws parallels with public trust in other domains, and describe how this informs the approach recommended for AI systems.',\n",
       "  'expected': \"The guidelines draw an analogy between trust in AI and trust in fields like aviation, nuclear power, or food safety, arguing that trust is not just about system components but the broader socio-technical context. This perspective informs the recommendation for a systemic, holistic approach to ensure trustworthiness in AI, covering all actors and processes throughout the AI system's life cycle.\",\n",
       "  'generated': \"The concept of Trustworthy AI in these guidelines draws parallels with public trust in other domains by emphasizing the importance of accountability, transparency, and fairness in the development and deployment of AI systems. This is reflected in the guidelines' focus on ensuring that AI systems are designed and developed with the principles of transparency, explainability, and accountability in mind.\\n\\nThe guidelines also highlight the need for international cooperation and the development of global standards for trustworthy AI, which is similar to how public trust is established in other domains such as finance, healthcare, and transportation. In these domains, international standards and regulations are often established to ensure that products and services meet certain levels of quality, safety, and reliability.\\n\\nThe guidelines' emphasis on the importance of data quality, bias monitoring, and correction also parallels the importance of data quality and integrity in other domains. For example, in healthcare, the accuracy and reliability of medical data are critical to ensuring the quality of care and patient outcomes.\\n\\nThe approach recommended for AI systems in these guidelines is to ensure that they are designed and developed with the principles of transparency, accountability, and fairness in mind. This includes:\\n\\n* Ensuring that AI systems are transparent and explainable in their decision-making processes\\n* Implementing mechanisms for bias monitoring and correction\\n* Ensuring that AI systems are designed and developed with the principles of accountability and responsibility in mind\\n* Establishing international standards and regulations for trustworthy AI\\n* Encouraging international cooperation and knowledge sharing on AI development and deployment\\n\\nOverall, the guidelines' approach to trustworthy AI is similar to how public trust is established in other domains, by emphasizing the importance of accountability, transparency, and fairness in the development and deployment of AI systems.\\n\\nReferences:\\n- Doc: ai_hleg_ethics_guidelines.pdf, page: [not specified]\\n- Doc: eu_ai_act_regulation.pdf, page: [31]\\n- Doc: oecd_legal_0449_en.pdf, page: [not specified]\",\n",
       "  'chunks': [{'pdf': 'ai_hleg_ethics_guidelines.pdf',\n",
       "    'pages': [],\n",
       "    'titles': [],\n",
       "    'chunk_index': 8,\n",
       "    'n_words': 300},\n",
       "   {'pdf': 'eu_ai_act_regulation.pdf',\n",
       "    'pages': [31],\n",
       "    'titles': [],\n",
       "    'chunk_index': 55,\n",
       "    'n_words': 300},\n",
       "   {'pdf': 'oecd_legal_0449_en.pdf',\n",
       "    'pages': [],\n",
       "    'titles': [],\n",
       "    'chunk_index': 11,\n",
       "    'n_words': 261}],\n",
       "  'dificultad': 'hard'},\n",
       " {'query': 'What are some example questions that help determine the transparency and explainability of an AI system according to the OECD framework?',\n",
       "  'expected': 'Examples include: Is it clear what the objectives of the AI system are? Does the system provide meaningful information for understanding its outputs? Can all outputs be explained? Can the determinant data or knowledge used for decisions be identified? Can the consistency and integrity of outcomes be verified?',\n",
       "  'generated': \"According to the OECD framework, the following are example questions that help determine the transparency and explainability of an AI system:\\n\\n1. Is it clear what the objectives of the AI system are, i.e. is it possible to formalise the problem that the system is being asked to solve? (Doc: oecd_ai_classification_framework.pdf, page: [not specified])\\n2. Does the AI system provide useful and meaningful information for understanding its performance and outputs/decisions? (Doc: oecd_ai_classification_framework.pdf, page: [not specified])\\n3. Can all of the AI system's outputs both intermediary and final for achieving a given goal be explained? (Doc: oecd_ai_classification_framework.pdf, page: [not specified])\\n4. Can the determinant data or knowledge that an AI system uses to make decisions be identified? (Doc: oecd_ai_classification_framework.pdf, page: [not specified])\\n5. Do two similar-looking cases verifiably result in similar outcomes, i.e. can the consistency and integrity of AI system outcomes be verified? (Doc: oecd_ai_classification_framework.pdf, page: [not specified])\\n\\nThese questions are mentioned in the context as possible questions to help determine AI system transparency and explainability (Principle 1.3).\",\n",
       "  'chunks': [{'pdf': 'oecd_ai_classification_framework.pdf',\n",
       "    'pages': [],\n",
       "    'titles': [],\n",
       "    'chunk_index': 41,\n",
       "    'n_words': 300},\n",
       "   {'pdf': 'oecd_ai_classification_framework.pdf',\n",
       "    'pages': [26],\n",
       "    'titles': ['26     OECD FRAMEWORK FOR THE CLASSIFICATION OF AI SYSTEMS'],\n",
       "    'chunk_index': 15,\n",
       "    'n_words': 300},\n",
       "   {'pdf': 'oecd_ai_classification_framework.pdf',\n",
       "    'pages': [43],\n",
       "    'titles': ['OECD FRAMEWORK FOR THE CLASSIFICATION OF AI SYSTEMS   43'],\n",
       "    'chunk_index': 40,\n",
       "    'n_words': 300}],\n",
       "  'dificultad': 'easy'},\n",
       " {'query': 'According to the OECD framework, what aspects should policy makers consider to assess the safety, security, and robustness of AI systems?',\n",
       "  'expected': 'Policy makers should consider if safety metrics exist for the use case, how safety is tested during development, what adversarial evaluation measures are in place, if the system is sensitive to data variations, and if there are processes to validate, verify, and trace AI system outcomes and decisions.',\n",
       "  'generated': \"According to the OECD framework and the AI HLEG Ethics Guidelines, policy makers should consider the following aspects to assess the safety, security, and robustness of AI systems:\\n\\n1. **Safety metrics**: Existence of metrics to evaluate the safety of an AI system for a given use case (OECD, not specified).\\n2. **Testing for safety**: Measures taken by the entity deploying the AI system to test for safety during development (OECD, not specified).\\n3. **Adversarial evaluation**: Measures taken to explore the AI system through the lens of being a bad actor and trying to break it (OECD, not specified).\\n4. **Validation and verification**: Measures in place to validate and verify the AI system's outcomes (OECD, not specified).\\n5. **Traceability**: Measures in place to facilitate traceability in the AI system, including in relation to datasets, processes, and decisions made during the AI system's development (OECD, not specified).\\n6. **Bias assessment**: Assessment and acknowledgment of possible limitations stemming from the composition of the used data sets (AI HLEG Ethics Guidelines, page 32).\\n7. **Bias testing**: Testing for specific populations or problematic use cases (AI HLEG Ethics Guidelines, page 32).\\n8. **Bias monitoring**: Processes in place to test and monitor for potential biases during the development, deployment, and use phase of the system (AI HLEG Ethics Guidelines, page 32).\\n9. **Risk assessment**: Assessment of the possible decision variability that can occur under the same conditions (AI HLEG Ethics Guidelines, page 32).\\n10. **Fairness definition**: Ensuring an adequate working definition of fairness that is commonly used (AI HLEG Ethics Guidelines, page 32).\\n11. **Fairness metrics**: Quantitative analysis or metrics to measure and test the applied definition of fairness (AI HLEG Ethics Guidelines, page 32).\\n12. **Robustness to attack**: Assessment of potential forms of attacks to which the AI system could be vulnerable (AI HLEG Ethics Guidelines, page 29).\\n13. **Resilience to attack**: Measures or systems in place to ensure the integrity and resilience of the AI system against potential attacks (AI HLEG Ethics Guidelines, page 29).\\n14. **Fallback plan**: Ensuring that the system has a sufficient fallback plan if it encounters adversarial attacks or other unexpected situations (AI HLEG Ethics Guidelines, page 29).\\n15. **Risk measurement**: Processes in place to measure and assess risks and safety (AI H\",\n",
       "  'chunks': [{'pdf': 'oecd_ai_classification_framework.pdf',\n",
       "    'pages': [],\n",
       "    'titles': [],\n",
       "    'chunk_index': 41,\n",
       "    'n_words': 300},\n",
       "   {'pdf': 'ai_hleg_ethics_guidelines.pdf',\n",
       "    'pages': [32],\n",
       "    'titles': ['6. Societal and environmental well-being'],\n",
       "    'chunk_index': 56,\n",
       "    'n_words': 300},\n",
       "   {'pdf': 'ai_hleg_ethics_guidelines.pdf',\n",
       "    'pages': [29],\n",
       "    'titles': ['2. Technical robustness and safety'],\n",
       "    'chunk_index': 51,\n",
       "    'n_words': 300}],\n",
       "  'dificultad': 'medium'},\n",
       " {'query': 'Describe how the OECD framework recommends assessing both the explainability and safety of an AI system throughout its lifecycle, and discuss why these factors are important for responsible AI deployment.',\n",
       "  'expected': 'The OECD framework suggests assessing explainability through questions about system objectives, transparency of outputs, traceability, and consistency of outcomes, while safety assessment involves safety metrics, adversarial testing, sensitivity to data variations, and validation/verification measures. These factors are important to ensure that AI systems are understandable, trustworthy, safe, and robust throughout their lifecycle, supporting responsible AI deployment.',\n",
       "  'generated': \"The OECD framework recommends assessing both the explainability and safety of an AI system throughout its lifecycle by considering the following key criteria:\\n\\n1. **Explainability** (Principle 1.3): The framework suggests asking questions such as:\\n\\t* Is it clear what the objectives of the AI system are?\\n\\t* Does the AI system provide useful and meaningful information for understanding its performance and outputs/decisions?\\n\\t* Can all of the AI system's outputs (both intermediary and final) be explained?\\n\\t* Can the determinant data or knowledge that an AI system uses to make decisions be identified?\\n\\t* Do two similar-looking cases verifiably result in similar outcomes?\\n2. **Safety, Security, and Robustness** (Principle 1.4): The framework suggests asking questions such as:\\n\\t* Do safety metrics exist that can evaluate the safety of an AI system for a given use case?\\n\\t* How does the entity deploying the AI system test for safety during development?\\n\\t* What measures has the entity deploying the AI system taken to do an adversarial evaluation?\\n\\t* Does the AI system change significantly if it is trained with variations of the data available?\\n\\t* Are there measures in place to validate and verify the AI system's outcomes?\\n\\nThese factors are important for responsible AI deployment because they ensure that AI systems are transparent, accountable, and safe for users and impacted stakeholders. Explainability is crucial for understanding how AI systems make decisions and for identifying potential biases or errors. Safety, security, and robustness are essential for preventing harm to individuals and society, particularly in high-stakes applications such as healthcare, finance, and transportation.\\n\\nThe OECD framework emphasizes the importance of considering these factors throughout the AI system's lifecycle, from design and development to deployment and maintenance. By doing so, policymakers and developers can ensure that AI systems are designed and deployed in a way that respects human rights and well-being.\\n\\nReferences:\\n[Doc: oecd_ai_classification_framework.pdf, page: 3, 21]\",\n",
       "  'chunks': [{'pdf': 'oecd_ai_classification_framework.pdf',\n",
       "    'pages': [],\n",
       "    'titles': [],\n",
       "    'chunk_index': 14,\n",
       "    'n_words': 300},\n",
       "   {'pdf': 'oecd_ai_classification_framework.pdf',\n",
       "    'pages': [],\n",
       "    'titles': [],\n",
       "    'chunk_index': 41,\n",
       "    'n_words': 300},\n",
       "   {'pdf': 'oecd_ai_classification_framework.pdf',\n",
       "    'pages': [21],\n",
       "    'titles': ['OECD FRAMEWORK FOR THE CLASSIFICATION OF AI SYSTEMS   21'],\n",
       "    'chunk_index': 8,\n",
       "    'n_words': 300}],\n",
       "  'dificultad': 'hard'},\n",
       " {'query': \"What are the three pillars of the European Commission's vision for artificial intelligence described in the introduction?\",\n",
       "  'expected': 'The three pillars are: (i) increasing public and private investments in AI, (ii) preparing for socio-economic changes, and (iii) ensuring an appropriate ethical and legal framework to strengthen European values.',\n",
       "  'generated': \"According to the provided context, the three pillars of the European Commission's vision for artificial intelligence are described in the introduction as:\\n\\n(i) increasing public and private investments in AI to boost its uptake,\\n(ii) preparing for socio-economic changes, and\\n(iii) ensuring an appropriate ethical and legal framework to strengthen European values.\\n\\nReference: (Doc: ai_hleg_ethics_guidelines.pdf, page: 6)\",\n",
       "  'chunks': [{'pdf': 'ai_hleg_ethics_guidelines.pdf',\n",
       "    'pages': [6],\n",
       "    'titles': ['A. INTRODUCTION'],\n",
       "    'chunk_index': 5,\n",
       "    'n_words': 300},\n",
       "   {'pdf': 'eu_ai_act_regulation.pdf',\n",
       "    'pages': [19],\n",
       "    'titles': ['2020/2012(INL).'],\n",
       "    'chunk_index': 31,\n",
       "    'n_words': 300},\n",
       "   {'pdf': 'eu_ai_act_regulation.pdf',\n",
       "    'pages': [],\n",
       "    'titles': [],\n",
       "    'chunk_index': 9,\n",
       "    'n_words': 300}],\n",
       "  'dificultad': 'easy'}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "def evaluate_manual(qa_eval_set, output_file=\"../results/rag_generation_manual.csv\", max_queries=10):\n",
    "    results = []\n",
    "\n",
    "    for i, item in enumerate(qa_eval_set):\n",
    "        if max_queries and i >= max_queries:\n",
    "            break\n",
    "\n",
    "        query = item[\"pregunta\"]\n",
    "        expected = item[\"respuesta_esperada\"]\n",
    "\n",
    "        chunks = hybrid_retrieval(query, alpha=0.3, top_k=3)\n",
    "        prompt = build_prompt(query, chunks)\n",
    "        response = generate_response(prompt)\n",
    "\n",
    "        results.append({\n",
    "            \"query\": query,\n",
    "            \"expected\": expected,\n",
    "            \"generated\": response,\n",
    "            \"chunks\": [c[\"meta\"] for c in chunks],\n",
    "            \"dificultad\": item[\"dificultad\"]\n",
    "        })\n",
    "\n",
    "        print(f\"[{i+1}] {query}\")\n",
    "        print(\"Generated:\", response[:150], \"...\\n\")\n",
    "\n",
    "    # Guardar en CSV\n",
    "    with open(output_file, \"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
    "        fieldnames = [\"query\", \"expected\", \"generated\", \"chunks\", \"dificultad\", \"exactitud\", \"completitud\", \"estilo\"]\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for r in results:\n",
    "            writer.writerow({\n",
    "                \"query\": r[\"query\"],\n",
    "                \"expected\": r[\"expected\"],\n",
    "                \"generated\": r[\"generated\"],\n",
    "                \"chunks\": r[\"chunks\"],\n",
    "                \"dificultad\": r[\"dificultad\"],\n",
    "                \"exactitud\": \"\",\n",
    "                \"completitud\": \"\",\n",
    "                \"estilo\": \"\"\n",
    "            })\n",
    "\n",
    "    print(f\"\\nResultados guardados en {output_file}\")\n",
    "    return results\n",
    "\n",
    "\n",
    "\n",
    "# Test rápido\n",
    "evaluate_manual(qa_eval_set, max_queries=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2466102",
   "metadata": {},
   "source": [
    "### 4.2. Evaluación automática (BERTScore y opcionalmente métricas RAGAS simples)\n",
    "\n",
    "Para complementar la evaluación manual, se utilizan métricas automáticas que comparan las respuestas generadas con las respuestas esperadas del benchmark.\n",
    "\n",
    "- **BERTScore:** mide la similitud semántica entre la respuesta generada y la respuesta esperada, usando embeddings de un modelo pre-entrenado.  \n",
    "  A diferencia de BLEU o ROUGE, es más robusto frente a paráfrasis.\n",
    "\n",
    "- **RAGAS (opcional):** framework de métricas específicas para RAG, que evalúa aspectos como *faithfulness* y *answer relevance*.  \n",
    "  Solo se explorará si el coste computacional y de dependencias lo permite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "80ad13d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bert-score in d:\\tfm_rag_nor\\venv\\lib\\site-packages (0.3.13)\n",
      "Requirement already satisfied: torch>=1.0.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from bert-score) (2.7.1)\n",
      "Requirement already satisfied: pandas>=1.0.1 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from bert-score) (2.3.1)\n",
      "Requirement already satisfied: transformers>=3.0.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from bert-score) (4.54.0)\n",
      "Requirement already satisfied: numpy in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from bert-score) (2.3.2)\n",
      "Requirement already satisfied: requests in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from bert-score) (2.32.5)\n",
      "Requirement already satisfied: tqdm>=4.31.1 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from bert-score) (4.67.1)\n",
      "Requirement already satisfied: matplotlib in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from bert-score) (3.10.5)\n",
      "Requirement already satisfied: packaging>=20.9 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from bert-score) (25.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from pandas>=1.0.1->bert-score) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from pandas>=1.0.1->bert-score) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from pandas>=1.0.1->bert-score) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert-score) (1.17.0)\n",
      "Requirement already satisfied: filelock in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from torch>=1.0.0->bert-score) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from torch>=1.0.0->bert-score) (4.14.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from torch>=1.0.0->bert-score) (1.14.0)\n",
      "Requirement already satisfied: networkx in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from torch>=1.0.0->bert-score) (3.5)\n",
      "Requirement already satisfied: jinja2 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from torch>=1.0.0->bert-score) (3.1.6)\n",
      "Requirement already satisfied: fsspec in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from torch>=1.0.0->bert-score) (2025.3.0)\n",
      "Requirement already satisfied: setuptools in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from torch>=1.0.0->bert-score) (80.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from sympy>=1.13.3->torch>=1.0.0->bert-score) (1.3.0)\n",
      "Requirement already satisfied: colorama in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from tqdm>=4.31.1->bert-score) (0.4.6)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from transformers>=3.0.0->bert-score) (0.34.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from transformers>=3.0.0->bert-score) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from transformers>=3.0.0->bert-score) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from transformers>=3.0.0->bert-score) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from transformers>=3.0.0->bert-score) (0.5.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from jinja2->torch>=1.0.0->bert-score) (3.0.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from matplotlib->bert-score) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from matplotlib->bert-score) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from matplotlib->bert-score) (4.59.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from matplotlib->bert-score) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from matplotlib->bert-score) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from matplotlib->bert-score) (3.2.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from requests->bert-score) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from requests->bert-score) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from requests->bert-score) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from requests->bert-score) (2025.7.14)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install bert-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a50b5587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] What is the main advisory responsibility of the European Artificial Intelligence Board according to the regulation?\n",
      "Generated: The main advisory responsibility of the European Artificial Intelligence Board according to the regulation is not explicitly stated in the provided do ...\n",
      "\n",
      "[2] Which requirement is imposed on providers of high-risk AI systems regarding post-market activities?\n",
      "Generated: The requirement imposed on providers of high-risk AI systems regarding post-market activities is to establish and document a post-market monitoring sy ...\n",
      "\n",
      "[3] How do the roles and interactions of national competent authorities, national supervisory authorities, and the European Artificial Intelligence Board contribute to the harmonised implementation and enforcement of the regulation across Member States?\n",
      "Generated: The roles and interactions of national competent authorities, national supervisory authorities, and the European Artificial Intelligence Board contrib ...\n",
      "\n",
      "[4] What are the three components that Trustworthy AI should meet throughout its entire life cycle according to the guidelines?\n",
      "Generated: According to the guidelines, Trustworthy AI should meet the following three components throughout its entire life cycle:\n",
      "\n",
      "1. It should be lawful, comp ...\n",
      "\n",
      "[5] Why does the document emphasize a holistic and systemic approach to achieving Trustworthy AI?\n",
      "Generated: The document emphasizes a holistic and systemic approach to achieving Trustworthy AI because it concerns not only the trustworthiness of the AI system ...\n",
      "\n",
      "[6] Explain how the concept of Trustworthy AI in these guidelines draws parallels with public trust in other domains, and describe how this informs the approach recommended for AI systems.\n",
      "Generated: The concept of Trustworthy AI in these guidelines draws parallels with public trust in other domains by emphasizing the importance of accountability,  ...\n",
      "\n",
      "[7] What are some example questions that help determine the transparency and explainability of an AI system according to the OECD framework?\n",
      "Generated: According to the OECD framework, the following are example questions that help determine the transparency and explainability of an AI system:\n",
      "\n",
      "1. Is i ...\n",
      "\n",
      "[8] According to the OECD framework, what aspects should policy makers consider to assess the safety, security, and robustness of AI systems?\n",
      "Generated: According to the OECD framework and the AI HLEG Ethics Guidelines, policy makers should consider the following aspects to assess the safety, security, ...\n",
      "\n",
      "[9] Describe how the OECD framework recommends assessing both the explainability and safety of an AI system throughout its lifecycle, and discuss why these factors are important for responsible AI deployment.\n",
      "Generated: The OECD framework recommends assessing both the explainability and safety of an AI system throughout its lifecycle by considering the following key c ...\n",
      "\n",
      "[10] What are the three pillars of the European Commission's vision for artificial intelligence described in the introduction?\n",
      "Generated: According to the provided context, the three pillars of the European Commission's vision for artificial intelligence are described in the introduction ...\n",
      "\n",
      "\n",
      "Resultados guardados en ../results/rag_generation_manual.csv\n",
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb424d277fc648adbaff8b6dadb58365",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "152d813ed1c241edb0d2ef3b36f8b995",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 11.67 seconds, 0.86 sentences/sec\n",
      "\n",
      "Resultados guardados en ../results/rag_generation_bertscore.csv\n",
      "What is the main advisory responsibility of the European Art ... | F1: 0.745\n",
      "Which requirement is imposed on providers of high-risk AI sy ... | F1: 0.743\n",
      "How do the roles and interactions of national competent auth ... | F1: 0.73\n",
      "What are the three components that Trustworthy AI should mee ... | F1: 0.82\n",
      "Why does the document emphasize a holistic and systemic appr ... | F1: 0.822\n",
      "Explain how the concept of Trustworthy AI in these guideline ... | F1: 0.759\n",
      "What are some example questions that help determine the tran ... | F1: 0.785\n",
      "According to the OECD framework, what aspects should policy  ... | F1: 0.732\n",
      "Describe how the OECD framework recommends assessing both th ... | F1: 0.8\n",
      "What are the three pillars of the European Commission's visi ... | F1: 0.89\n"
     ]
    }
   ],
   "source": [
    "from bert_score import score\n",
    "import csv\n",
    "\n",
    "def evaluate_bertscore(results, lang=\"en\", model_type=\"distilbert-base-uncased\", output_file=\"../results/rag_generation_bertscore.csv\"):\n",
    "    \"\"\"\n",
    "    Calcula BERTScore con un modelo más ligero y guarda los resultados en CSV.\n",
    "    \"\"\"\n",
    "    expected_answers = [r[\"expected\"] for r in results]\n",
    "    generated_answers = [r[\"generated\"] for r in results]\n",
    "\n",
    "    # Calcular BERTScore con modelo pequeño\n",
    "    P, R, F1 = score(generated_answers, expected_answers, lang=lang, model_type=model_type, verbose=True)\n",
    "\n",
    "    # Añadir a resultados\n",
    "    for i, r in enumerate(results):\n",
    "        r[\"bertscore_precision\"] = float(P[i])\n",
    "        r[\"bertscore_recall\"] = float(R[i])\n",
    "        r[\"bertscore_f1\"] = float(F1[i])\n",
    "\n",
    "    # Guardar en CSV\n",
    "    with open(output_file, \"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
    "        fieldnames = [\"query\", \"expected\", \"generated\", \"dificultad\", \"bertscore_precision\", \"bertscore_recall\", \"bertscore_f1\"]\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for r in results:\n",
    "            writer.writerow({\n",
    "                \"query\": r[\"query\"],\n",
    "                \"expected\": r[\"expected\"],\n",
    "                \"generated\": r[\"generated\"],\n",
    "                \"dificultad\": r[\"dificultad\"],\n",
    "                \"bertscore_precision\": r[\"bertscore_precision\"],\n",
    "                \"bertscore_recall\": r[\"bertscore_recall\"],\n",
    "                \"bertscore_f1\": r[\"bertscore_f1\"]\n",
    "            })\n",
    "\n",
    "    print(f\"\\nResultados guardados en {output_file}\")\n",
    "    return results\n",
    "\n",
    "# === Test breve con tus 10 resultados ===\n",
    "results = evaluate_manual(qa_eval_set, max_queries=10)\n",
    "results_with_scores = evaluate_bertscore(results, lang=\"en\")\n",
    "\n",
    "# Resumen en consola (solo query y F1)\n",
    "for r in results_with_scores:\n",
    "    print(r[\"query\"][:60], \"... | F1:\", round(r[\"bertscore_f1\"], 3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c7fffdff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERTScore F1 promedio: 0.783\n"
     ]
    }
   ],
   "source": [
    "f1_scores = [r[\"bertscore_f1\"] for r in results_with_scores]\n",
    "print(\"BERTScore F1 promedio:\", round(sum(f1_scores)/len(f1_scores), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "73863b15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Query ===\n",
      "What are the three pillars of the European Commission's vision on AI? \n",
      "\n",
      "=== Answer ===\n",
      "The three pillars of the European Commission's vision on AI are:\n",
      "\n",
      "1. Increasing public and private investments in AI to boost its uptake. \n",
      "2. Preparing for socio-economic changes.\n",
      "3. Ensuring an appropriate ethical and legal framework to strengthen European values.\n",
      "\n",
      "Reference: Doc: ai_hleg_ethics_guidelines.pdf, page: [6] \n",
      "\n",
      "=== Chunks usados ===\n",
      "- Doc: ai_hleg_ethics_guidelines.pdf | Page: [] | Title: []\n",
      "  Text: are trustworthy. When drafting these Guidelines, Trustworthy AI has, therefore, been our foundational ambition. Trustworthy AI has three components: (1) it should be lawful, ensuring compliance with a...\n",
      "\n",
      "- Doc: eu_ai_act_regulation.pdf | Page: [] | Title: []\n",
      "  Text: examined in the White Paper on AI. Consistency and complementarity is therefore ensured with other ongoing or planned initiatives of the Commission that also aim to address those problems, including t...\n",
      "\n",
      "- Doc: ai_hleg_ethics_guidelines.pdf | Page: [6] | Title: ['A. INTRODUCTION']\n",
      "  Text: in December 2018 by the Commission and Member States. A. INTRODUCTION In its Communication of 25 April 2018 and 7 December 2018, the European Commission set out its vision for artificial intelligence ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_query = \"What are the three pillars of the European Commission's vision on AI?\"\n",
    "chunks = hybrid_retrieval(user_query, alpha=0.3, top_k=3)\n",
    "prompt = build_prompt(user_query, chunks)\n",
    "response = generate_response(prompt)\n",
    "\n",
    "display_result(user_query, response, chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e04be0",
   "metadata": {},
   "source": [
    "### 4.3. Evaluación automática con métricas RAGAS\n",
    "\n",
    "Además de BERTScore, se exploran métricas específicas para sistemas RAG utilizando la librería **RAGAS**.  \n",
    "\n",
    "- **Faithfulness**: mide si la respuesta está respaldada por el contexto proporcionado.  \n",
    "- **Answer relevance**: mide si la respuesta realmente responde a la pregunta.  \n",
    "- **Context recall**: mide si los chunks recuperados contienen la información necesaria.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e32f21f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ragas in d:\\tfm_rag_nor\\venv\\lib\\site-packages (0.3.2)\n",
      "Requirement already satisfied: numpy in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from ragas) (2.3.2)\n",
      "Requirement already satisfied: datasets in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from ragas) (4.0.0)\n",
      "Requirement already satisfied: tiktoken in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from ragas) (0.11.0)\n",
      "Requirement already satisfied: pydantic>=2.0.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from ragas) (2.11.7)\n",
      "Requirement already satisfied: nest-asyncio in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from ragas) (1.6.0)\n",
      "Requirement already satisfied: appdirs in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from ragas) (1.4.4)\n",
      "Requirement already satisfied: diskcache>=5.6.3 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from ragas) (5.6.3)\n",
      "Requirement already satisfied: langchain in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from ragas) (0.3.27)\n",
      "Requirement already satisfied: langchain-core in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from ragas) (0.3.75)\n",
      "Requirement already satisfied: langchain-community in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from ragas) (0.3.28)\n",
      "Requirement already satisfied: langchain_openai in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from ragas) (0.3.32)\n",
      "Requirement already satisfied: typer in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from ragas) (0.16.0)\n",
      "Requirement already satisfied: rich in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from ragas) (14.1.0)\n",
      "Requirement already satisfied: openai>=1.0.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from ragas) (1.101.0)\n",
      "Requirement already satisfied: tqdm in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from ragas) (4.67.1)\n",
      "Requirement already satisfied: instructor in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from ragas) (1.10.0)\n",
      "Requirement already satisfied: gitpython in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from ragas) (3.1.45)\n",
      "Requirement already satisfied: pillow>=10.4.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from ragas) (11.3.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from openai>=1.0.0->ragas) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from openai>=1.0.0->ragas) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from openai>=1.0.0->ragas) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from openai>=1.0.0->ragas) (0.10.0)\n",
      "Requirement already satisfied: sniffio in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from openai>=1.0.0->ragas) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from openai>=1.0.0->ragas) (4.14.1)\n",
      "Requirement already satisfied: idna>=2.8 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from anyio<5,>=3.5.0->openai>=1.0.0->ragas) (3.10)\n",
      "Requirement already satisfied: certifi in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai>=1.0.0->ragas) (2025.7.14)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai>=1.0.0->ragas) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.0.0->ragas) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from pydantic>=2.0.0->ragas) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from pydantic>=2.0.0->ragas) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from pydantic>=2.0.0->ragas) (0.4.1)\n",
      "Requirement already satisfied: colorama in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from tqdm->ragas) (0.4.6)\n",
      "Requirement already satisfied: filelock in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from datasets->ragas) (3.18.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from datasets->ragas) (21.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from datasets->ragas) (0.3.8)\n",
      "Requirement already satisfied: pandas in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from datasets->ragas) (2.3.1)\n",
      "Requirement already satisfied: requests>=2.32.2 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from datasets->ragas) (2.32.5)\n",
      "Requirement already satisfied: xxhash in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from datasets->ragas) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from datasets->ragas) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets->ragas) (2025.3.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from datasets->ragas) (0.34.1)\n",
      "Requirement already satisfied: packaging in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from datasets->ragas) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from datasets->ragas) (6.0.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets->ragas) (3.12.15)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->ragas) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->ragas) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->ragas) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->ragas) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->ragas) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->ragas) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->ragas) (1.20.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from requests>=2.32.2->datasets->ragas) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from requests>=2.32.2->datasets->ragas) (2.5.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from gitpython->ragas) (4.0.12)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython->ragas) (5.0.2)\n",
      "Requirement already satisfied: docstring-parser<1.0,>=0.16 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from instructor->ragas) (0.17.0)\n",
      "Requirement already satisfied: jinja2<4.0.0,>=3.1.4 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from instructor->ragas) (3.1.6)\n",
      "Requirement already satisfied: tenacity<10.0.0,>=8.2.3 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from instructor->ragas) (9.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from jinja2<4.0.0,>=3.1.4->instructor->ragas) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from rich->ragas) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from rich->ragas) (2.19.2)\n",
      "Requirement already satisfied: click>=8.0.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from typer->ragas) (8.2.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from typer->ragas) (1.5.4)\n",
      "Requirement already satisfied: mdurl~=0.1 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->ragas) (0.1.2)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from langchain->ragas) (0.3.9)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from langchain->ragas) (0.4.18)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from langchain->ragas) (2.0.43)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from langchain-core->ragas) (1.33)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core->ragas) (3.0.0)\n",
      "Requirement already satisfied: greenlet>=1 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain->ragas) (3.2.4)\n",
      "Requirement already satisfied: orjson>=3.9.14 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from langsmith>=0.1.17->langchain->ragas) (3.11.1)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from langsmith>=0.1.17->langchain->ragas) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from langsmith>=0.1.17->langchain->ragas) (0.24.0)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.6.7 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from langchain-community->ragas) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from langchain-community->ragas) (2.10.1)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from langchain-community->ragas) (0.4.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from dataclasses-json<0.7,>=0.6.7->langchain-community->ragas) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from dataclasses-json<0.7,>=0.6.7->langchain-community->ragas) (0.9.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community->ragas) (1.1.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.6.7->langchain-community->ragas) (1.1.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from tiktoken->ragas) (2024.11.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from pandas->datasets->ragas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from pandas->datasets->ragas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from pandas->datasets->ragas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets->ragas) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install ragas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "72a256b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ragas in d:\\tfm_rag_nor\\venv\\lib\\site-packages (0.3.2)\n",
      "Requirement already satisfied: langchain_openai in d:\\tfm_rag_nor\\venv\\lib\\site-packages (0.3.32)\n",
      "Requirement already satisfied: numpy in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from ragas) (2.3.2)\n",
      "Requirement already satisfied: datasets in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from ragas) (4.0.0)\n",
      "Requirement already satisfied: tiktoken in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from ragas) (0.11.0)\n",
      "Requirement already satisfied: pydantic>=2.0.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from ragas) (2.11.7)\n",
      "Requirement already satisfied: nest-asyncio in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from ragas) (1.6.0)\n",
      "Requirement already satisfied: appdirs in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from ragas) (1.4.4)\n",
      "Requirement already satisfied: diskcache>=5.6.3 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from ragas) (5.6.3)\n",
      "Requirement already satisfied: langchain in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from ragas) (0.3.27)\n",
      "Requirement already satisfied: langchain-core in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from ragas) (0.3.75)\n",
      "Requirement already satisfied: langchain-community in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from ragas) (0.3.28)\n",
      "Requirement already satisfied: typer in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from ragas) (0.16.0)\n",
      "Requirement already satisfied: rich in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from ragas) (14.1.0)\n",
      "Requirement already satisfied: openai>=1.0.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from ragas) (1.101.0)\n",
      "Requirement already satisfied: tqdm in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from ragas) (4.67.1)\n",
      "Requirement already satisfied: instructor in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from ragas) (1.10.0)\n",
      "Requirement already satisfied: gitpython in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from ragas) (3.1.45)\n",
      "Requirement already satisfied: pillow>=10.4.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from ragas) (11.3.0)\n",
      "Requirement already satisfied: langsmith>=0.3.45 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from langchain-core->ragas) (0.4.18)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from langchain-core->ragas) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from langchain-core->ragas) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from langchain-core->ragas) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from langchain-core->ragas) (4.14.1)\n",
      "Requirement already satisfied: packaging>=23.2 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from langchain-core->ragas) (25.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core->ragas) (3.0.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from openai>=1.0.0->ragas) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from openai>=1.0.0->ragas) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from openai>=1.0.0->ragas) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from openai>=1.0.0->ragas) (0.10.0)\n",
      "Requirement already satisfied: sniffio in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from openai>=1.0.0->ragas) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from anyio<5,>=3.5.0->openai>=1.0.0->ragas) (3.10)\n",
      "Requirement already satisfied: certifi in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai>=1.0.0->ragas) (2025.7.14)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai>=1.0.0->ragas) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.0.0->ragas) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from pydantic>=2.0.0->ragas) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from pydantic>=2.0.0->ragas) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from pydantic>=2.0.0->ragas) (0.4.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from tiktoken->ragas) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from tiktoken->ragas) (2.32.5)\n",
      "Requirement already satisfied: orjson>=3.9.14 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from langsmith>=0.3.45->langchain-core->ragas) (3.11.1)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from langsmith>=0.3.45->langchain-core->ragas) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from langsmith>=0.3.45->langchain-core->ragas) (0.24.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from requests>=2.26.0->tiktoken->ragas) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from requests>=2.26.0->tiktoken->ragas) (2.5.0)\n",
      "Requirement already satisfied: colorama in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from tqdm->ragas) (0.4.6)\n",
      "Requirement already satisfied: filelock in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from datasets->ragas) (3.18.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from datasets->ragas) (21.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from datasets->ragas) (0.3.8)\n",
      "Requirement already satisfied: pandas in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from datasets->ragas) (2.3.1)\n",
      "Requirement already satisfied: xxhash in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from datasets->ragas) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from datasets->ragas) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets->ragas) (2025.3.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from datasets->ragas) (0.34.1)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets->ragas) (3.12.15)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->ragas) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->ragas) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->ragas) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->ragas) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->ragas) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->ragas) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->ragas) (1.20.1)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from gitpython->ragas) (4.0.12)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython->ragas) (5.0.2)\n",
      "Requirement already satisfied: docstring-parser<1.0,>=0.16 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from instructor->ragas) (0.17.0)\n",
      "Requirement already satisfied: jinja2<4.0.0,>=3.1.4 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from instructor->ragas) (3.1.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from jinja2<4.0.0,>=3.1.4->instructor->ragas) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from rich->ragas) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from rich->ragas) (2.19.2)\n",
      "Requirement already satisfied: click>=8.0.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from typer->ragas) (8.2.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from typer->ragas) (1.5.4)\n",
      "Requirement already satisfied: mdurl~=0.1 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->ragas) (0.1.2)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from langchain->ragas) (0.3.9)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from langchain->ragas) (2.0.43)\n",
      "Requirement already satisfied: greenlet>=1 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain->ragas) (3.2.4)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.6.7 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from langchain-community->ragas) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from langchain-community->ragas) (2.10.1)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from langchain-community->ragas) (0.4.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from dataclasses-json<0.7,>=0.6.7->langchain-community->ragas) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from dataclasses-json<0.7,>=0.6.7->langchain-community->ragas) (0.9.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community->ragas) (1.1.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.6.7->langchain-community->ragas) (1.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from pandas->datasets->ragas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from pandas->datasets->ragas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from pandas->datasets->ragas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets->ragas) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install ragas langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f526014c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71c7f8ee39be4e26919b886f11a8926c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception raised in Job[7]: AttributeError('InferenceClient' object has no attribute 'post')\n",
      "Exception raised in Job[13]: AttributeError('InferenceClient' object has no attribute 'post')\n",
      "Exception raised in Job[8]: AttributeError('InferenceClient' object has no attribute 'post')\n",
      "Exception raised in Job[6]: AttributeError('InferenceClient' object has no attribute 'post')\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[40]\u001b[39m\u001b[32m, line 38\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[38;5;66;03m# Evaluación con métricas RAGAS\u001b[39;00m\n\u001b[32m     37\u001b[39m metrics = [faithfulness, answer_relevancy, context_recall]\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m ragas_results = \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mragas_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mllm\u001b[49m\u001b[43m=\u001b[49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mResultados RAGAS:\u001b[39m\u001b[33m\"\u001b[39m, ragas_results)\n\u001b[32m     42\u001b[39m df_ragas = pd.DataFrame([ragas_results])\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\TFM_RAG_NOR\\venv\\Lib\\site-packages\\ragas\\_analytics.py:227\u001b[39m, in \u001b[36mtrack_was_completed.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    224\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[32m    225\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args: P.args, **kwargs: P.kwargs) -> t.Any:\n\u001b[32m    226\u001b[39m     track(IsCompleteEvent(event_type=func.\u001b[34m__name__\u001b[39m, is_completed=\u001b[38;5;28;01mFalse\u001b[39;00m))\n\u001b[32m--> \u001b[39m\u001b[32m227\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    228\u001b[39m     track(IsCompleteEvent(event_type=func.\u001b[34m__name__\u001b[39m, is_completed=\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[32m    230\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\TFM_RAG_NOR\\venv\\Lib\\site-packages\\ragas\\evaluation.py:294\u001b[39m, in \u001b[36mevaluate\u001b[39m\u001b[34m(dataset, metrics, llm, embeddings, experiment_name, callbacks, run_config, token_usage_parser, raise_exceptions, column_map, show_progress, batch_size, _run_id, _pbar)\u001b[39m\n\u001b[32m    291\u001b[39m scores: t.List[t.Dict[\u001b[38;5;28mstr\u001b[39m, t.Any]] = []\n\u001b[32m    292\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    293\u001b[39m     \u001b[38;5;66;03m# get the results\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m294\u001b[39m     results = \u001b[43mexecutor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    295\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m results == []:\n\u001b[32m    296\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m ExceptionInRunner()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\TFM_RAG_NOR\\venv\\Lib\\site-packages\\ragas\\executor.py:213\u001b[39m, in \u001b[36mExecutor.results\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    210\u001b[39m             nest_asyncio.apply()\n\u001b[32m    211\u001b[39m             \u001b[38;5;28mself\u001b[39m._nest_asyncio_applied = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m213\u001b[39m results = \u001b[43masyncio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_process_jobs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    214\u001b[39m sorted_results = \u001b[38;5;28msorted\u001b[39m(results, key=\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[32m0\u001b[39m])\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m [r[\u001b[32m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m sorted_results]\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\TFM_RAG_NOR\\venv\\Lib\\site-packages\\nest_asyncio.py:30\u001b[39m, in \u001b[36m_patch_asyncio.<locals>.run\u001b[39m\u001b[34m(main, debug)\u001b[39m\n\u001b[32m     28\u001b[39m task = asyncio.ensure_future(main)\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     32\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m task.done():\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\TFM_RAG_NOR\\venv\\Lib\\site-packages\\nest_asyncio.py:92\u001b[39m, in \u001b[36m_patch_loop.<locals>.run_until_complete\u001b[39m\u001b[34m(self, future)\u001b[39m\n\u001b[32m     90\u001b[39m     f._log_destroy_pending = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f.done():\n\u001b[32m---> \u001b[39m\u001b[32m92\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     93\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._stopping:\n\u001b[32m     94\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\TFM_RAG_NOR\\venv\\Lib\\site-packages\\nest_asyncio.py:115\u001b[39m, in \u001b[36m_patch_loop.<locals>._run_once\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    108\u001b[39m     heappop(scheduled)\n\u001b[32m    110\u001b[39m timeout = (\n\u001b[32m    111\u001b[39m     \u001b[32m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ready \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._stopping\n\u001b[32m    112\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mmax\u001b[39m(\n\u001b[32m    113\u001b[39m         scheduled[\u001b[32m0\u001b[39m]._when - \u001b[38;5;28mself\u001b[39m.time(), \u001b[32m0\u001b[39m), \u001b[32m86400\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m scheduled\n\u001b[32m    114\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m event_list = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_selector\u001b[49m\u001b[43m.\u001b[49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    116\u001b[39m \u001b[38;5;28mself\u001b[39m._process_events(event_list)\n\u001b[32m    118\u001b[39m end_time = \u001b[38;5;28mself\u001b[39m.time() + \u001b[38;5;28mself\u001b[39m._clock_resolution\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\selectors.py:314\u001b[39m, in \u001b[36mSelectSelector.select\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    312\u001b[39m ready = []\n\u001b[32m    313\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m314\u001b[39m     r, w, _ = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_select\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_readers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_writers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    315\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[32m    316\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\selectors.py:305\u001b[39m, in \u001b[36mSelectSelector._select\u001b[39m\u001b[34m(self, r, w, _, timeout)\u001b[39m\n\u001b[32m    304\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_select\u001b[39m(\u001b[38;5;28mself\u001b[39m, r, w, _, timeout=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m305\u001b[39m     r, w, x = \u001b[43mselect\u001b[49m\u001b[43m.\u001b[49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    306\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m r, w + x, []\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception raised in Job[9]: AttributeError('InferenceClient' object has no attribute 'post')\n",
      "Exception raised in Job[20]: AssertionError(set LLM before use)\n",
      "Exception raised in Job[21]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[22]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[23]: AssertionError(set LLM before use)\n",
      "Exception raised in Job[24]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[25]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[26]: AssertionError(set LLM before use)\n",
      "Exception raised in Job[27]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[28]: AssertionError(LLM is not set)\n",
      "Exception raised in Job[29]: AssertionError(set LLM before use)\n",
      "Exception raised in Job[10]: AttributeError('InferenceClient' object has no attribute 'post')\n",
      "Exception raised in Job[5]: AttributeError('InferenceClient' object has no attribute 'post')\n",
      "Exception raised in Job[15]: AttributeError('InferenceClient' object has no attribute 'post')\n",
      "Exception raised in Job[4]: AttributeError('InferenceClient' object has no attribute 'post')\n",
      "Exception raised in Job[3]: AttributeError('InferenceClient' object has no attribute 'post')\n",
      "Exception raised in Job[1]: AttributeError('InferenceClient' object has no attribute 'post')\n",
      "Exception raised in Job[2]: AttributeError('InferenceClient' object has no attribute 'post')\n",
      "Exception raised in Job[12]: AttributeError('InferenceClient' object has no attribute 'post')\n",
      "Exception raised in Job[0]: AttributeError('InferenceClient' object has no attribute 'post')\n",
      "Exception raised in Job[11]: AttributeError('InferenceClient' object has no attribute 'post')\n",
      "Exception raised in Job[14]: AttributeError('InferenceClient' object has no attribute 'post')\n",
      "Exception raised in Job[16]: AttributeError('InferenceClient' object has no attribute 'post')\n",
      "Exception raised in Job[19]: AttributeError('InferenceClient' object has no attribute 'post')\n",
      "Exception raised in Job[17]: AttributeError('InferenceClient' object has no attribute 'post')\n",
      "Exception raised in Job[18]: AttributeError('InferenceClient' object has no attribute 'post')\n"
     ]
    }
   ],
   "source": [
    "from ragas.metrics import faithfulness, answer_relevancy, context_recall\n",
    "from ragas import evaluate\n",
    "from datasets import Dataset\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "import pandas as pd\n",
    "\n",
    "def prepare_ragas_dataset(results):\n",
    "    \"\"\"\n",
    "    Convierte los resultados del pipeline a un Dataset de HuggingFace\n",
    "    en el formato esperado por RAGAS.\n",
    "    \"\"\"\n",
    "    ragas_data = {\n",
    "        \"question\": [],\n",
    "        \"answer\": [],\n",
    "        \"contexts\": [],\n",
    "        \"ground_truth\": []\n",
    "    }\n",
    "\n",
    "    for r in results:\n",
    "        ragas_data[\"question\"].append(r[\"query\"])\n",
    "        ragas_data[\"answer\"].append(r[\"generated\"])\n",
    "        ragas_data[\"contexts\"].append([c if isinstance(c, str) else str(c) for c in r[\"chunks\"]])\n",
    "        ragas_data[\"ground_truth\"].append(r[\"expected\"])\n",
    "\n",
    "    return Dataset.from_dict(ragas_data)\n",
    "\n",
    "\n",
    "# Crear dataset con resultados\n",
    "ragas_dataset = prepare_ragas_dataset(results_with_scores)\n",
    "\n",
    "# Configurar Groq LLaMA-3 como LLM backend\n",
    "llm = ChatOpenAI(\n",
    "    model=\"llama-3.1-8b-instant\",\n",
    "    api_key=\"api_key\",\n",
    "    base_url=\"https://api.groq.com/openai/v1\"\n",
    ")\n",
    "\n",
    "# Configurar embeddings HuggingFace (MPNet)\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
    "\n",
    "# Evaluación con métricas RAGAS\n",
    "metrics = [faithfulness, answer_relevancy, context_recall]\n",
    "ragas_results = evaluate(ragas_dataset, metrics=metrics, llm=llm, embeddings=embeddings)\n",
    "\n",
    "print(\"Resultados RAGAS:\", ragas_results)\n",
    "\n",
    "df_ragas = pd.DataFrame([ragas_results])\n",
    "df_ragas.to_csv(\"../results/rag_generation_ragas.csv\", index=False)\n",
    "print(\"Resultados guardados en ../results/rag_generation_ragas.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d7429133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[np.float64(nan), np.float64(nan), np.float64(nan)]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "vals = [\n",
    "    round(np.mean(ragas_results[\"faithfulness\"]), 3),\n",
    "    round(np.mean(ragas_results[\"answer_relevancy\"]), 3),\n",
    "    round(np.mean(ragas_results[\"context_recall\"]), 3)\n",
    "]\n",
    "\n",
    "print(vals)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04dd16af",
   "metadata": {},
   "source": [
    "## 5. Demo tester\n",
    "\n",
    "En esta sección se incluye una demostración práctica del sistema RAG desarrollado.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "455c7513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Query ===\n",
      "How does an AI-based system differ from a non-AI-based system? \n",
      "\n",
      "=== Answer ===\n",
      "Based on the provided context, the main differences between an AI-based system and a non-AI-based system are:\n",
      "\n",
      "1. **Machine-based system**: An AI system is a machine-based system that is capable of influencing the environment by producing recommendations, predictions, or other outcomes for a given set of objectives (Box 1, Doc: oecd_ai_classification_framework.pdf, page: [23]).\n",
      "\n",
      "2. **Use of machine and/or human-based inputs/data**: AI systems use machine and/or human-based inputs/data to perceive environments, abstract these perceptions into models, and use the models to formulate decisions or actions (Box 1, Doc: oecd_ai_classification_framework.pdf, page: [23]).\n",
      "\n",
      "3. **Lifecycles and actors**: AI systems have different lifecycles and actors, including People & Planet, Economic Context, Data & Input, AI Model, and Task & Output (Figure 4, Doc: oecd_ai_classification_framework.pdf, page: [23]).\n",
      "\n",
      "4. **Technical robustness and safety**: AI systems require specific considerations for technical robustness and safety, including resilience to attack and security, fallback plans, and general safety (Doc: ai_hleg_ethics_guidelines.pdf, page: [29]).\n",
      "\n",
      "5. **Fairness and bias**: AI systems require specific considerations for fairness and bias, including procedures to avoid creating or reinforcing unfair bias, testing for bias, and monitoring for potential biases (Doc: ai_hleg_ethics_guidelines.pdf, page: [32]).\n",
      "\n",
      "6. **Accessibility and universal design**: AI systems require specific considerations for accessibility and universal design, including ensuring that the AI system accommodates a wide range of users (Doc: ai_hleg_ethics_guidelines.pdf, page: [32]).\n",
      "\n",
      "These differences highlight the unique characteristics and requirements of AI-based systems compared to non-AI-based systems. \n",
      "\n",
      "=== Chunks usados ===\n",
      "- Doc: oecd_ai_classification_framework.pdf | Page: [23] | Title: ['OECD FRAMEWORK FOR THE CLASSIFICATION OF AI SYSTEMS   23']\n",
      "  Text: dimension, which matters for accountability and risk management measures (OECD, 2019d[1]).4 AI actors are those who play an active role throughout the AI system lifecycle and can include organisations...\n",
      "\n",
      "- Doc: ai_hleg_ethics_guidelines.pdf | Page: [29] | Title: ['2. Technical robustness and safety']\n",
      "  Text: whether something could go wrong? Did you ensure a stop button or procedure to safely abort an operation where needed? Does this procedure abort the process entirely, in part, or delegate control to a...\n",
      "\n",
      "- Doc: ai_hleg_ethics_guidelines.pdf | Page: [32] | Title: ['6. Societal and environmental well-being']\n",
      "  Text: a set of procedures to avoid creating or reinforcing unfair bias in the AI system, both regarding the use of input data as well as for the algorithm design? Did you assess and acknowledge the possible...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Demo interactiva en el notebook\n",
    "\n",
    "while True:\n",
    "    user_query = input(\"Escribe tu pregunta (o 'exit' para salir): \")\n",
    "    if user_query.lower() == \"exit\":\n",
    "        break\n",
    "    \n",
    "    chunks = hybrid_retrieval(user_query, alpha=0.3, top_k=3)\n",
    "    prompt = build_prompt(user_query, chunks)\n",
    "    response = generate_response(prompt)\n",
    "    \n",
    "    display_result(user_query, response, chunks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27876ee9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab439515",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Bloque de inicialización para la Demo interactiva ===\n",
    "\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from openai import OpenAI\n",
    "\n",
    "# --- Rutas de datos ---\n",
    "DATA_PATH = \"../data/\"\n",
    "\n",
    "# --- Cliente Groq (API key desde variable de entorno o hardcodeada en caso de emergencia) ---\n",
    "client = OpenAI(\n",
    "    api_key=\"api_key\",\n",
    "    base_url=\"https://api.groq.com/openai/v1\"\n",
    ")\n",
    "\n",
    "# --- Cargar índice BM25 ---\n",
    "with open(os.path.join(DATA_PATH, \"bm25\", \"bm25_index.pkl\"), \"rb\") as f:\n",
    "    bm25 = pickle.load(f)\n",
    "\n",
    "# --- Cargar índice FAISS (MPNet) ---\n",
    "faiss_index = faiss.read_index(os.path.join(DATA_PATH, \"faiss_index\", \"faiss_index_mpnet.faiss\"))\n",
    "\n",
    "# --- Cargar corpus y metadatos ---\n",
    "with open(os.path.join(DATA_PATH, \"chunks\", \"texts.json\"), \"r\", encoding=\"utf-8\") as f:\n",
    "    texts = json.load(f)\n",
    "\n",
    "with open(os.path.join(DATA_PATH, \"chunks\", \"metadata.json\"), \"r\", encoding=\"utf-8\") as f:\n",
    "    metadata = json.load(f)\n",
    "\n",
    "# --- Modelo embeddings MPNet ---\n",
    "mpnet_model = SentenceTransformer(\"sentence-transformers/all-mpnet-base-v2\")\n",
    "\n",
    "# --- Funciones mínimas ---\n",
    "def preprocess(text):\n",
    "    return text.lower().strip()\n",
    "\n",
    "def hybrid_retrieval(query, alpha=0.3, top_k=3):\n",
    "    q = preprocess(query)\n",
    "\n",
    "    # BM25\n",
    "    tokenized_q = q.split()\n",
    "    bm25_scores = bm25.get_scores(tokenized_q)\n",
    "\n",
    "    # MPNet\n",
    "    q_emb = mpnet_model.encode([q])\n",
    "    D, I = faiss_index.search(q_emb, len(texts))\n",
    "\n",
    "    mpnet_scores = [0] * len(texts)\n",
    "    for idx, score in zip(I[0], D[0]):\n",
    "        mpnet_scores[idx] = float(score)\n",
    "\n",
    "    # Híbrido\n",
    "    hybrid_scores = [\n",
    "        alpha * mpnet_scores[i] + (1 - alpha) * bm25_scores[i]\n",
    "        for i in range(len(texts))\n",
    "    ]\n",
    "\n",
    "    # Top-k\n",
    "    ranked = sorted(enumerate(hybrid_scores), key=lambda x: x[1], reverse=True)[:top_k]\n",
    "\n",
    "    results = []\n",
    "    for idx, score in ranked:\n",
    "        results.append({\n",
    "            \"chunk\": texts[idx],\n",
    "            \"meta\": metadata[idx],\n",
    "            \"score\": score\n",
    "        })\n",
    "    return results\n",
    "\n",
    "def build_prompt(query, chunks):\n",
    "    context_parts = []\n",
    "    for c in chunks:\n",
    "        ref = f\"[Doc: {c['meta']['pdf']}, page: {c['meta']['pages']}]\"\n",
    "        text = c[\"chunk\"]\n",
    "        context_parts.append(f\"{ref}\\n{text}\")\n",
    "\n",
    "    context = \"\\n\\n\".join(context_parts)\n",
    "    prompt = f\"\"\"\n",
    "Question: {query}\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Instruction:\n",
    "Answer the question using only the context above.\n",
    "If the answer is not in the documents, say clearly that it is not found.\n",
    "Always include the reference (Doc and page).\n",
    "\"\"\"\n",
    "    return prompt.strip()\n",
    "\n",
    "def generate_response(prompt, model=\"llama-3.1-8b-instant\"):\n",
    "    completion = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an assistant specialized in AI ethics and governance.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=0.2,\n",
    "        max_tokens=512\n",
    "    )\n",
    "    return completion.choices[0].message.content.strip()\n",
    "\n",
    "def display_result(query, response, chunks):\n",
    "    print(\"=== Query ===\")\n",
    "    print(query, \"\\n\")\n",
    "\n",
    "    print(\"=== Answer ===\")\n",
    "    print(response, \"\\n\")\n",
    "\n",
    "    print(\"=== Chunks usados ===\")\n",
    "    for c in chunks:\n",
    "        meta = c[\"meta\"]\n",
    "        doc = meta.get(\"pdf\", \"N/A\")\n",
    "        pages = meta.get(\"pages\", [])\n",
    "        title = meta.get(\"titles\", [])\n",
    "        print(f\"- Doc: {doc} | Page: {pages} | Title: {title}\")\n",
    "        print(f\"  Text: {c['chunk'][:200]}...\\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "54f53610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Query ===\n",
      "How does an AI-based system differ from a non-AI-based system? \n",
      "\n",
      "=== Answer ===\n",
      "Based on the provided context, an AI-based system differs from a non-AI-based system in the following ways:\n",
      "\n",
      "1. **Machine-based system**: An AI system is a machine-based system that is capable of influencing the environment by producing recommendations, predictions, or other outcomes for a given set of objectives (Box 1, Doc: oecd_ai_classification_framework.pdf, page: [23]).\n",
      "\n",
      "2. **Use of machine and/or human-based inputs/data**: AI systems use machine and/or human-based inputs/data to perceive environments, abstract these perceptions into models, and use the models to formulate outcomes (Box 1, Doc: oecd_ai_classification_framework.pdf, page: [23]).\n",
      "\n",
      "3. **Lifecycles and actors**: AI systems have different lifecycles and actors, including People & Planet, Economic Context, Data & Input, AI Model, and Task & Output (Figure 4, Doc: oecd_ai_classification_framework.pdf, page: [23]).\n",
      "\n",
      "4. **Technical robustness and safety**: AI systems require assessments of potential attacks, vulnerabilities, and resilience to ensure the integrity and safety of the system (Doc: ai_hleg_ethics_guidelines.pdf, page: [29]).\n",
      "\n",
      "5. **Bias and fairness**: AI systems require procedures to avoid creating or reinforcing unfair bias, including assessing data limitations, diversity, and representativeness (Doc: ai_hleg_ethics_guidelines.pdf, page: [32]).\n",
      "\n",
      "6. **Accessibility and universal design**: AI systems should accommodate a wide range of users, including those with disabilities, and ensure universal design (Doc: ai_hleg_ethics_guidelines.pdf, page: [32]).\n",
      "\n",
      "These differences highlight the unique characteristics and requirements of AI-based systems compared to non-AI-based systems. \n",
      "\n",
      "=== Chunks usados ===\n",
      "- Doc: oecd_ai_classification_framework.pdf | Page: [23] | Title: ['OECD FRAMEWORK FOR THE CLASSIFICATION OF AI SYSTEMS   23']\n",
      "  Text: dimension, which matters for accountability and risk management measures (OECD, 2019d[1]).4 AI actors are those who play an active role throughout the AI system lifecycle and can include organisations...\n",
      "\n",
      "- Doc: ai_hleg_ethics_guidelines.pdf | Page: [29] | Title: ['2. Technical robustness and safety']\n",
      "  Text: whether something could go wrong? Did you ensure a stop button or procedure to safely abort an operation where needed? Does this procedure abort the process entirely, in part, or delegate control to a...\n",
      "\n",
      "- Doc: ai_hleg_ethics_guidelines.pdf | Page: [32] | Title: ['6. Societal and environmental well-being']\n",
      "  Text: a set of procedures to avoid creating or reinforcing unfair bias in the AI system, both regarding the use of input data as well as for the algorithm design? Did you assess and acknowledge the possible...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Demo interactiva en el notebook\n",
    "\n",
    "while True:\n",
    "    user_query = input(\"Escribe tu pregunta (o 'exit' para salir): \")\n",
    "    if user_query.lower() == \"exit\":\n",
    "        break\n",
    "    \n",
    "    chunks = hybrid_retrieval(user_query, alpha=0.3, top_k=3)\n",
    "    prompt = build_prompt(user_query, chunks)\n",
    "    response = generate_response(prompt)\n",
    "    \n",
    "    display_result(user_query, response, chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48726d8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Extensión con modelos entrenados\n",
    "\n",
    "Hasta aquí hemos montado el sistema RAG base: recuperación híbrida (BM25 + embeddings), selección de los mejores chunks, generación con LLaMA-3 y demo interactiva.  \n",
    "Funciona bien, pero todo está apoyado en modelos ya entrenados. Para completar la fase 2 vamos a añadir **dos mejoras con modelos propios**:\n",
    "\n",
    "### 6.1 Re-ranker (Opción A)  \n",
    "Entrenamos un modelo que aprende a ordenar mejor los candidatos recuperados.  \n",
    "La idea es: dentro del *top-k* de chunks recuperados, calcular varias características (scores, similitudes, longitudes, etc.), y entrenar el modelo para que dé más probabilidad al chunk realmente relevante.  \n",
    "En el pipeline, este re-ranker se aplica antes de la generación, para que el modelo generativo reciba un *top-3* más limpio y relevante.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "36ef822e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@1: 0.433\n",
      "Recall@3: 0.580\n",
      "Recall@10: 0.733\n",
      "Recall@20: 0.807\n",
      "Recall@25: 0.847\n",
      "Recall@50: 0.913\n",
      "Recall@100: 0.947\n",
      "Recall@200: 0.993\n",
      "\n",
      "Total sin aparecer en top-200: 1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np, pandas as pd\n",
    "\n",
    "results = []\n",
    "TOP_MAX = 200\n",
    "ALPHA = 0.3\n",
    "\n",
    "for i, entry in enumerate(qa_eval_set, start=1):\n",
    "    qid = f\"q{i}\"\n",
    "    query_text = entry[\"pregunta\"]\n",
    "    relevant = entry[\"relevant_chunks\"]\n",
    "\n",
    "    # Recuperar con IDs corregidos (idx)\n",
    "    q = preprocess(query_text)\n",
    "    bm25_scores = bm25.get_scores(q.split())\n",
    "    q_emb = mpnet_model.encode([q])\n",
    "    D, I = faiss_index.search(q_emb, len(texts))\n",
    "    mpnet_scores = np.zeros(len(texts))\n",
    "    for idx, score in zip(I[0], D[0]):\n",
    "        mpnet_scores[idx] = float(score)\n",
    "    hybrid_scores = ALPHA * mpnet_scores + (1-ALPHA) * bm25_scores\n",
    "    ranked = np.argsort(-hybrid_scores)[:TOP_MAX]\n",
    "\n",
    "    # Guardar posición del relevante\n",
    "    rank_pos = None\n",
    "    for rc in relevant:\n",
    "        if rc in ranked:\n",
    "            rank_pos = np.where(ranked == rc)[0][0] + 1\n",
    "            break\n",
    "    results.append({\"query_id\": qid, \"rank_pos\": rank_pos})\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "def recall_at_k(df, k):\n",
    "    hits = df[\"rank_pos\"].apply(lambda x: x is not None and x <= k).sum()\n",
    "    return hits / len(df)\n",
    "\n",
    "for k in [1, 3, 10, 20, 25, 50, 100, 200]:\n",
    "    print(f\"Recall@{k}: {recall_at_k(df,k):.3f}\")\n",
    "\n",
    "print(\"\\nTotal sin aparecer en top-200:\", df[\"rank_pos\"].isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d8844a90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.style.use(\"seaborn-v0_8-whitegrid\")\n",
    "\n",
    "recall_values = {\n",
    "    1: 0.433,\n",
    "    3: 0.580,\n",
    "    10: 0.733,\n",
    "    20: 0.807,\n",
    "    25: 0.847,\n",
    "    50: 0.913,\n",
    "    100: 0.947,\n",
    "    200: 0.993,\n",
    "}\n",
    "\n",
    "ks = list(recall_values.keys())\n",
    "vals = list(recall_values.values())\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.plot(ks, vals, marker=\"o\", linewidth=2, markersize=7, color=\"#2E86AB\", label=\"Baseline híbrido\")\n",
    "plt.fill_between(ks, vals, alpha=0.1, color=\"#2E86AB\")\n",
    "plt.title(\"Curva de Recall@k\", fontsize=14, fontweight=\"bold\")\n",
    "plt.xlabel(\"k\", fontsize=12)\n",
    "plt.ylabel(\"Recall\", fontsize=12)\n",
    "plt.xticks(ks, fontsize=10)\n",
    "plt.yticks(np.linspace(0,1,11), fontsize=10)\n",
    "plt.ylim(0,1.05)\n",
    "plt.legend(frameon=False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "30821ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset generado: (3750, 11)\n",
      "Columnas: ['query_id', 'chunk_id', 'bm25_score', 'cosine_qc', 'hybrid_score', 'rank', 'gap_top1_top2', 'lexical_overlap', 'tokens_count_q', 'tokens_count_c', 'label_relevance']\n",
      "Queries sin positivo en top-25: 23 de 150\n",
      "Ejemplos: ['q14', 'q29', 'q43', 'q47', 'q48', 'q50', 'q69', 'q71', 'q73', 'q74']\n"
     ]
    }
   ],
   "source": [
    "import os, json\n",
    "\n",
    "DATA_PATH = \"../data/eval\"\n",
    "TOPK_PATH = \"../data/normative/topk\"\n",
    "os.makedirs(TOPK_PATH, exist_ok=True)\n",
    "\n",
    "TOP_K = 25\n",
    "ALPHA = 0.3\n",
    "\n",
    "with open(os.path.join(DATA_PATH, \"qa_eval_set.json\"), \"r\", encoding=\"utf-8\") as f:\n",
    "    qa_eval_set = json.load(f)\n",
    "\n",
    "queries_dict, gold_labels = {}, {}\n",
    "for i, entry in enumerate(qa_eval_set, start=1):\n",
    "    qid = f\"q{i}\"\n",
    "    queries_dict[qid] = entry[\"pregunta\"]\n",
    "    gold_labels[qid] = entry[\"relevant_chunks\"]\n",
    "\n",
    "def lexical_overlap(query, chunk):\n",
    "    q_tokens, c_tokens = set(query.lower().split()), set(chunk.lower().split())\n",
    "    return len(q_tokens & c_tokens) / len(q_tokens) if q_tokens else 0.0\n",
    "\n",
    "rows, queries_missing = [], []\n",
    "\n",
    "for query_id, query_text in queries_dict.items():\n",
    "    relevant_chunks = gold_labels[query_id]\n",
    "\n",
    "    q = preprocess(query_text)\n",
    "    bm25_scores = bm25.get_scores(q.split())\n",
    "    q_emb = mpnet_model.encode([q])\n",
    "    D, I = faiss_index.search(q_emb, len(texts))\n",
    "    mpnet_scores = np.zeros(len(texts))\n",
    "    for idx, score in zip(I[0], D[0]):\n",
    "        mpnet_scores[idx] = float(score)\n",
    "    hybrid_scores = ALPHA * mpnet_scores + (1-ALPHA) * bm25_scores\n",
    "    ranked = np.argsort(-hybrid_scores)[:TOP_K]\n",
    "\n",
    "    if not any(rc in ranked for rc in relevant_chunks):\n",
    "        queries_missing.append(query_id)\n",
    "\n",
    "    gap_top1_top2 = hybrid_scores[ranked[0]] - hybrid_scores[ranked[1]] if len(ranked) >= 2 else hybrid_scores[ranked[0]]\n",
    "\n",
    "    for rank, idx in enumerate(ranked, start=1):\n",
    "        rows.append({\n",
    "            \"query_id\": query_id,\n",
    "            \"chunk_id\": idx,\n",
    "            \"bm25_score\": bm25_scores[idx],\n",
    "            \"cosine_qc\": mpnet_scores[idx],\n",
    "            \"hybrid_score\": hybrid_scores[idx],\n",
    "            \"rank\": rank,\n",
    "            \"gap_top1_top2\": gap_top1_top2,\n",
    "            \"lexical_overlap\": lexical_overlap(query_text, texts[idx]),\n",
    "            \"tokens_count_q\": len(query_text.split()),\n",
    "            \"tokens_count_c\": len(texts[idx].split()),\n",
    "            \"label_relevance\": 1 if idx in relevant_chunks else 0\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "out_path = os.path.join(TOPK_PATH, \"topk_candidates.csv\")\n",
    "df.to_csv(out_path, index=False)\n",
    "\n",
    "print(\"Dataset generado:\", df.shape)\n",
    "print(\"Columnas:\", df.columns.tolist())\n",
    "print(f\"Queries sin positivo en top-{TOP_K}: {len(queries_missing)} de {len(queries_dict)}\")\n",
    "print(\"Ejemplos:\", queries_missing[:10])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "53e999e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: (3750, 11)\n",
      "\n",
      "--- Resultados en test (20%) ---\n",
      "K=3\n",
      "  precision: 0.800\n",
      "  recall: 0.800\n",
      "  ndcg: 0.742\n",
      "  map: 0.743\n",
      "  mrr: 0.743\n",
      "  pdf_match: 1.000\n",
      "Fold 1 → P=0.800, Rec=0.800, nDCG=0.742, MAP=0.743, MRR=0.743, PDF=1.000\n",
      "Fold 2 → P=0.700, Rec=0.700, nDCG=0.646, MAP=0.637, MRR=0.637, PDF=1.000\n",
      "Fold 3 → P=0.733, Rec=0.733, nDCG=0.630, MAP=0.622, MRR=0.622, PDF=1.000\n",
      "Fold 4 → P=0.667, Rec=0.667, nDCG=0.609, MAP=0.615, MRR=0.615, PDF=1.000\n",
      "Fold 5 → P=0.433, Rec=0.433, nDCG=0.367, MAP=0.387, MRR=0.387, PDF=1.000\n",
      "\n",
      "--- Resultados medios (5-Fold) ---\n",
      "K=3\n",
      "  precision: 0.667\n",
      "  recall: 0.667\n",
      "  ndcg: 0.599\n",
      "  map: 0.601\n",
      "  mrr: 0.601\n",
      "  pdf_match: 1.000\n",
      "\n",
      "Modelo final entrenado y guardado en ../models/reranker\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd, numpy as np, os, pickle, json\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "CSV_PATH = \"../data/normative/topk/topk_candidates.csv\"\n",
    "EVAL_PATH = \"../data/eval/qa_eval_set.json\"\n",
    "CHUNKS_META_PATH = \"../data/chunks/metadata.json\"\n",
    "MODELS_PATH = \"../models/reranker\"\n",
    "os.makedirs(MODELS_PATH, exist_ok=True)\n",
    "\n",
    "# Cargar datos\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "print(\"Dataset:\", df.shape)\n",
    "\n",
    "with open(EVAL_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    qa_eval_set = json.load(f)\n",
    "with open(CHUNKS_META_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    chunk_metadata = json.load(f)\n",
    "\n",
    "feature_cols = [\n",
    "    \"bm25_score\",\"cosine_qc\",\"hybrid_score\",\"rank\",\n",
    "    \"gap_top1_top2\",\"lexical_overlap\",\"tokens_count_q\",\"tokens_count_c\"\n",
    "]\n",
    "X, y, qids = df[feature_cols].values, df[\"label_relevance\"].values, df[\"query_id\"].values\n",
    "\n",
    "# Train/Test split\n",
    "unique_qids = np.unique(qids)\n",
    "train_qids, test_qids = train_test_split(unique_qids, test_size=0.2, random_state=42)\n",
    "train_mask, test_mask = np.isin(qids, train_qids), np.isin(qids, test_qids)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train, y_train = X[train_mask], y[train_mask]\n",
    "X_test, y_test, qids_test = X[test_mask], y[test_mask], qids[test_mask]\n",
    "\n",
    "X_train_s, X_test_s = scaler.fit_transform(X_train), scaler.transform(X_test)\n",
    "\n",
    "clf = LogisticRegression(class_weight=\"balanced\", max_iter=200, random_state=42)\n",
    "clf.fit(X_train_s, y_train)\n",
    "\n",
    "#  Evaluación\n",
    "def evaluate_split(X_test_s, y_test, qids_test, clf, k=3):\n",
    "    results = []\n",
    "    for q in np.unique(qids_test):\n",
    "        mask = qids_test == q\n",
    "        y_true_q, y_scores_q = y_test[mask], clf.predict_proba(X_test_s[mask])[:,1]\n",
    "        ranked = np.argsort(-y_scores_q)\n",
    "\n",
    "        precision = 1 if any(y_true_q[i] == 1 for i in ranked[:k]) else 0\n",
    "        recall = precision\n",
    "\n",
    "        mrr = next((1.0/r for r,i in enumerate(ranked,1) if y_true_q[i]==1), 0.0)\n",
    "\n",
    "        gains = y_true_q[ranked[:k]]\n",
    "        ideal_gains = sorted(y_true_q, reverse=True)[:k]\n",
    "        dcg = sum(g/np.log2(i+2) for i,g in enumerate(gains))\n",
    "        idcg = sum(g/np.log2(i+2) for i,g in enumerate(ideal_gains))\n",
    "        ndcg = dcg / idcg if idcg > 0 else 0.0\n",
    "\n",
    "        map_score = average_precision_score(y_true_q, y_scores_q) if 1 in y_true_q else 0.0\n",
    "\n",
    "        df_q = df[df[\"query_id\"] == q]\n",
    "        df_q = df_q.reset_index(drop=True)\n",
    "        topk_idx = ranked[:k]\n",
    "        pdfs_topk = set(chunk_metadata[df_q.iloc[i][\"chunk_id\"]][\"pdf\"] for i in topk_idx)\n",
    "\n",
    "        pdfs_relevant = {qa_eval_set[int(q[1:])-1][\"pdf\"]}\n",
    "        pdf_match = int(len(pdfs_topk & pdfs_relevant) > 0)\n",
    "\n",
    "        results.append((precision, recall, ndcg, map_score, mrr, pdf_match))\n",
    "    return np.mean(results, axis=0)\n",
    "\n",
    "\n",
    "prec, rec, ndcg, map_score, mrr_score, pdf_match = evaluate_split(X_test_s, y_test, qids_test, clf, k=3)\n",
    "print(\"\\n--- Resultados en test (20%) ---\")\n",
    "print(f\"K=3\\n  precision: {prec:.3f}\\n  recall: {rec:.3f}\\n  ndcg: {ndcg:.3f}\\n  map: {map_score:.3f}\\n  mrr: {mrr_score:.3f}\\n  pdf_match: {pdf_match:.3f}\")\n",
    "\n",
    "#  K-Fold\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "metrics = []\n",
    "for fold,(train_idx,test_idx) in enumerate(kf.split(unique_qids), start=1):\n",
    "    train_q, test_q = unique_qids[train_idx], unique_qids[test_idx]\n",
    "    train_mask, test_mask = np.isin(qids, train_q), np.isin(qids, test_q)\n",
    "\n",
    "    X_train,y_train = X[train_mask],y[train_mask]\n",
    "    X_test,y_test,qids_val = X[test_mask],y[test_mask],qids[test_mask]\n",
    "    X_train_s,X_test_s = scaler.fit_transform(X_train),scaler.transform(X_test)\n",
    "\n",
    "    clf_cv = LogisticRegression(class_weight=\"balanced\", max_iter=200).fit(X_train_s,y_train)\n",
    "    fold_scores = evaluate_split(X_test_s, y_test, qids_val, clf_cv, k=3)\n",
    "    metrics.append(fold_scores)\n",
    "\n",
    "    print(f\"Fold {fold} → P={fold_scores[0]:.3f}, Rec={fold_scores[1]:.3f}, nDCG={fold_scores[2]:.3f}, MAP={fold_scores[3]:.3f}, MRR={fold_scores[4]:.3f}, PDF={fold_scores[5]:.3f}\")\n",
    "\n",
    "metrics = np.mean(metrics,axis=0)\n",
    "print(\"\\n--- Resultados medios (5-Fold) ---\")\n",
    "print(f\"K=3\\n  precision: {metrics[0]:.3f}\\n  recall: {metrics[1]:.3f}\\n  ndcg: {metrics[2]:.3f}\\n  map: {metrics[3]:.3f}\\n  mrr: {metrics[4]:.3f}\\n  pdf_match: {metrics[5]:.3f}\")\n",
    "\n",
    "# entreno\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "final_clf = LogisticRegression(class_weight=\"balanced\", max_iter=200).fit(X_scaled, y)\n",
    "\n",
    "with open(os.path.join(MODELS_PATH,\"reranker.pkl\"),\"wb\") as f: pickle.dump(final_clf,f)\n",
    "with open(os.path.join(MODELS_PATH,\"scaler.pkl\"),\"wb\") as f: pickle.dump(scaler,f)\n",
    "with open(os.path.join(MODELS_PATH,\"features_schema.json\"),\"w\") as f: json.dump(feature_cols,f)\n",
    "\n",
    "print(f\"\\nModelo final entrenado y guardado en {MODELS_PATH}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afb5869",
   "metadata": {},
   "source": [
    "#### Comparación baseline híbrido vs. re-ranker (K=3)\n",
    "\n",
    "| Sistema             | Precision | Recall | nDCG  | MAP   | MRR   | PDF Match |\n",
    "|---------------------|-----------|--------|-------|-------|-------|-----------|\n",
    "| Híbrido (baseline)  | 0.667 | 0.667  | 0.582 | 0.553 | 0.553 | 0.993 |\n",
    "| Re-ranker           | **0.800**     | **0.800**  | **0.742** | **0.743** | **0.743** | **1.000**  |\n",
    "\n",
    "\n",
    "Al comparar el baseline híbrido con el re-ranker:\n",
    "\n",
    "- Mejoran mucho el **recall** (0.667 → 0.800) y el resto de métricas como nDCG, MAP y MRR.  \n",
    "- Esto significa que el re-ranker consigue traer más veces el chunk correcto dentro del top-3, aunque no siempre lo priorice en primer lugar.\n",
    "\n",
    "El re-ranker es una capa extra que hace el sistema más **robusto y fiable** (menos riesgo de perder el relevante).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91e0e79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1100x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "resultados = {\n",
    "    \"BM25\":      {\"recall\":0.620, \"ndcg\":0.531, \"map\":0.500},\n",
    "    \"MiniLM\":    {\"recall\":0.380, \"ndcg\":0.315, \"map\":0.293},\n",
    "    \"MPNet\":     {\"recall\":0.493, \"ndcg\":0.416, \"map\":0.389},\n",
    "    \"Híbrido Lin (α=0.3)\": {\"recall\":0.647, \"ndcg\":0.568, \"map\":0.541},\n",
    "    \"Híbrido Log (α=0.3)\": {\"recall\":0.667, \"ndcg\":0.582, \"map\":0.553},\n",
    "    \"Re-ranker\": {\"recall\":0.800, \"ndcg\":0.742, \"map\":0.743}\n",
    "}\n",
    "\n",
    "metricas = [\"recall\", \"ndcg\", \"map\"]\n",
    "x = np.arange(len(metricas))\n",
    "bar_width = 0.12\n",
    "\n",
    "plt.figure(figsize=(11,6))\n",
    "\n",
    "for i, (sistema, vals) in enumerate(resultados.items()):\n",
    "    valores = [vals[m] for m in metricas]\n",
    "    plt.bar(x + i*bar_width, valores, width=bar_width, label=sistema)\n",
    "\n",
    "plt.xticks(x + bar_width*2.5, [m.upper()+\"@3\" for m in metricas])\n",
    "plt.ylabel('Score')\n",
    "plt.ylim(0, 1)\n",
    "plt.title('Comparativa de métricas en K=3')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0889a64d",
   "metadata": {},
   "source": [
    "### 6.2 Calibrador de confianza (Opción C)  \n",
    "Aquí entrenamos otro modelo ligero que decide si la respuesta generada es fiable o no.  \n",
    "Si el calibrador estima que la respuesta es buena, la mostramos. Si no, el sistema se abstiene y devuelve un mensaje estándar, indicando que no hay evidencia suficiente en las fuentes.  \n",
    "Esto añade una capa de seguridad y transparencia: no siempre es mejor responder, a veces es mejor reconocer la incertidumbre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcdaae3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generando respuestas:   0%|          | 0/150 [00:00<?, ?it/s]Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf71c359e37c4ba680477eaca2e43c33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:  15%|#4        | 241M/1.66G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\TFM_RAG_NOR\\venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\aalex\\.cache\\huggingface\\hub\\models--roberta-large. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "d:\\TFM_RAG_NOR\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `RobertaSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "Generando respuestas:   1%|          | 1/150 [01:52<4:40:34, 112.98s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:   1%|▏         | 2/150 [01:59<2:04:06, 50.31s/it] Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:   2%|▏         | 3/150 [02:08<1:17:25, 31.60s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:   3%|▎         | 4/150 [02:13<50:55, 20.93s/it]  Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:   3%|▎         | 5/150 [02:18<36:59, 15.30s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:   4%|▍         | 6/150 [02:28<32:02, 13.35s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:   5%|▍         | 7/150 [02:35<27:11, 11.41s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:   5%|▌         | 8/150 [02:52<31:07, 13.15s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:   6%|▌         | 9/150 [03:10<34:17, 14.59s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:   7%|▋         | 10/150 [03:20<30:42, 13.16s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:   7%|▋         | 11/150 [03:33<30:27, 13.15s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:   8%|▊         | 12/150 [03:53<34:50, 15.15s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:   9%|▊         | 13/150 [04:05<33:02, 14.47s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:   9%|▉         | 14/150 [04:20<33:00, 14.57s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  10%|█         | 15/150 [04:37<34:12, 15.21s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  11%|█         | 16/150 [04:50<32:44, 14.66s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  11%|█▏        | 17/150 [05:06<33:25, 15.08s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  12%|█▏        | 18/150 [05:22<33:33, 15.26s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  13%|█▎        | 19/150 [05:33<30:23, 13.92s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  13%|█▎        | 20/150 [05:47<30:00, 13.85s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  14%|█▍        | 21/150 [06:04<32:15, 15.00s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  15%|█▍        | 22/150 [06:18<31:24, 14.72s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  15%|█▌        | 23/150 [06:31<29:47, 14.08s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  16%|█▌        | 24/150 [06:48<31:26, 14.98s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  17%|█▋        | 25/150 [07:02<30:23, 14.59s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  17%|█▋        | 26/150 [07:20<32:25, 15.69s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  18%|█▊        | 27/150 [07:35<31:40, 15.45s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  19%|█▊        | 28/150 [07:48<30:03, 14.78s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  19%|█▉        | 29/150 [08:03<29:45, 14.76s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  20%|██        | 30/150 [08:22<32:06, 16.06s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  21%|██        | 31/150 [08:39<32:23, 16.33s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  21%|██▏       | 32/150 [08:52<30:14, 15.37s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  22%|██▏       | 33/150 [09:10<31:23, 16.10s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  23%|██▎       | 34/150 [09:26<31:19, 16.20s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  23%|██▎       | 35/150 [09:41<30:02, 15.67s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  24%|██▍       | 36/150 [09:58<30:39, 16.13s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  25%|██▍       | 37/150 [10:11<28:35, 15.18s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  25%|██▌       | 38/150 [10:25<28:04, 15.04s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  26%|██▌       | 39/150 [10:41<28:10, 15.23s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  27%|██▋       | 40/150 [10:54<26:34, 14.50s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  27%|██▋       | 41/150 [11:10<27:12, 14.98s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  28%|██▊       | 42/150 [11:24<26:20, 14.63s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  29%|██▊       | 43/150 [11:41<27:23, 15.36s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  29%|██▉       | 44/150 [11:59<28:21, 16.05s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  30%|███       | 45/150 [12:15<28:08, 16.08s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  31%|███       | 46/150 [12:25<24:43, 14.27s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  31%|███▏      | 47/150 [12:38<24:01, 14.00s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  32%|███▏      | 48/150 [12:58<26:49, 15.78s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  33%|███▎      | 49/150 [13:11<24:53, 14.79s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  33%|███▎      | 50/150 [13:27<25:42, 15.42s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  34%|███▍      | 51/150 [13:44<26:11, 15.87s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  35%|███▍      | 52/150 [13:57<24:10, 14.80s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  35%|███▌      | 53/150 [14:15<25:42, 15.90s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  36%|███▌      | 54/150 [14:30<25:07, 15.70s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  37%|███▋      | 55/150 [14:44<24:02, 15.18s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  37%|███▋      | 56/150 [14:59<23:19, 14.89s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  38%|███▊      | 57/150 [15:15<23:44, 15.31s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  39%|███▊      | 58/150 [15:29<23:09, 15.10s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  39%|███▉      | 59/150 [15:44<22:31, 14.85s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  40%|████      | 60/150 [16:00<23:00, 15.34s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  41%|████      | 61/150 [16:14<22:09, 14.94s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  41%|████▏     | 62/150 [16:29<21:39, 14.77s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  42%|████▏     | 63/150 [16:45<21:59, 15.17s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  43%|████▎     | 64/150 [16:56<19:55, 13.90s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  43%|████▎     | 65/150 [17:11<20:08, 14.22s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  44%|████▍     | 66/150 [17:29<21:34, 15.41s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  45%|████▍     | 67/150 [17:51<24:00, 17.35s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  45%|████▌     | 68/150 [18:05<22:35, 16.53s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  46%|████▌     | 69/150 [18:23<22:58, 17.02s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  47%|████▋     | 70/150 [18:34<20:13, 15.17s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  47%|████▋     | 71/150 [18:49<19:37, 14.90s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  48%|████▊     | 72/150 [19:05<20:03, 15.43s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  49%|████▊     | 73/150 [19:23<20:33, 16.02s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  49%|████▉     | 74/150 [19:35<18:45, 14.81s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  50%|█████     | 75/150 [19:53<19:40, 15.74s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  51%|█████     | 76/150 [20:09<19:44, 16.01s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  51%|█████▏    | 77/150 [20:27<20:09, 16.57s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  52%|█████▏    | 78/150 [20:44<20:05, 16.74s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  53%|█████▎    | 79/150 [21:00<19:33, 16.53s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  53%|█████▎    | 80/150 [21:12<17:41, 15.17s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  54%|█████▍    | 81/150 [21:28<17:42, 15.39s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  55%|█████▍    | 82/150 [21:44<17:36, 15.54s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  55%|█████▌    | 83/150 [21:57<16:28, 14.76s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  56%|█████▌    | 84/150 [22:13<16:47, 15.27s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  57%|█████▋    | 85/150 [22:29<16:44, 15.46s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  57%|█████▋    | 86/150 [22:44<16:06, 15.09s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Warning: Empty reference sentence detected; setting raw BERTScores to 0.\n",
      "Generando respuestas:  58%|█████▊    | 87/150 [22:59<15:55, 15.17s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  59%|█████▊    | 88/150 [23:16<16:10, 15.66s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  59%|█████▉    | 89/150 [23:33<16:28, 16.20s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  60%|██████    | 90/150 [23:51<16:43, 16.73s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  61%|██████    | 91/150 [24:06<15:50, 16.11s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  61%|██████▏   | 92/150 [24:17<14:14, 14.73s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  62%|██████▏   | 93/150 [24:36<15:00, 15.80s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  63%|██████▎   | 94/150 [24:49<14:00, 15.01s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  63%|██████▎   | 95/150 [25:01<13:04, 14.26s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  64%|██████▍   | 96/150 [25:18<13:32, 15.05s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  65%|██████▍   | 97/150 [25:37<14:12, 16.08s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  65%|██████▌   | 98/150 [25:53<14:04, 16.24s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  66%|██████▌   | 99/150 [26:10<13:54, 16.37s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  67%|██████▋   | 100/150 [26:22<12:28, 14.97s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  67%|██████▋   | 101/150 [26:38<12:30, 15.32s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  68%|██████▊   | 102/150 [26:54<12:22, 15.48s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  69%|██████▊   | 103/150 [27:07<11:43, 14.97s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  69%|██████▉   | 104/150 [27:22<11:28, 14.98s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  70%|███████   | 105/150 [27:39<11:40, 15.57s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  71%|███████   | 106/150 [27:54<11:09, 15.22s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  71%|███████▏  | 107/150 [28:07<10:27, 14.60s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  72%|███████▏  | 108/150 [28:26<11:07, 15.89s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  73%|███████▎  | 109/150 [28:41<10:48, 15.81s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  73%|███████▎  | 110/150 [28:59<10:55, 16.38s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  74%|███████▍  | 111/150 [29:14<10:24, 16.01s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  75%|███████▍  | 112/150 [29:29<09:55, 15.68s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  75%|███████▌  | 113/150 [29:46<09:55, 16.09s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  76%|███████▌  | 114/150 [30:11<11:09, 18.60s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  77%|███████▋  | 115/150 [30:17<08:40, 14.87s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  77%|███████▋  | 116/150 [30:32<08:29, 14.98s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  78%|███████▊  | 117/150 [30:50<08:43, 15.87s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  79%|███████▊  | 118/150 [31:00<07:27, 14.00s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  79%|███████▉  | 119/150 [31:15<07:30, 14.53s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  80%|████████  | 120/150 [31:29<07:02, 14.09s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  81%|████████  | 121/150 [31:44<06:57, 14.41s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  81%|████████▏ | 122/150 [31:59<06:48, 14.57s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  82%|████████▏ | 123/150 [32:16<06:55, 15.38s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  83%|████████▎ | 124/150 [32:30<06:28, 14.94s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  83%|████████▎ | 125/150 [32:45<06:12, 14.92s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  84%|████████▍ | 126/150 [33:04<06:31, 16.32s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  85%|████████▍ | 127/150 [33:16<05:44, 14.99s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  85%|████████▌ | 128/150 [33:32<05:33, 15.15s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  86%|████████▌ | 129/150 [33:52<05:50, 16.67s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  87%|████████▋ | 130/150 [34:10<05:42, 17.13s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  87%|████████▋ | 131/150 [34:21<04:52, 15.38s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  88%|████████▊ | 132/150 [34:39<04:47, 15.96s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  89%|████████▊ | 133/150 [34:50<04:08, 14.62s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  89%|████████▉ | 134/150 [35:05<03:56, 14.77s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  90%|█████████ | 135/150 [35:21<03:46, 15.11s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  91%|█████████ | 136/150 [35:33<03:18, 14.20s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  91%|█████████▏| 137/150 [35:50<03:14, 14.93s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  92%|█████████▏| 138/150 [36:07<03:06, 15.54s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  93%|█████████▎| 139/150 [36:27<03:05, 16.91s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  93%|█████████▎| 140/150 [36:38<02:31, 15.11s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  94%|█████████▍| 141/150 [36:57<02:25, 16.20s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  95%|█████████▍| 142/150 [37:08<01:57, 14.67s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  95%|█████████▌| 143/150 [37:23<01:44, 14.86s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  96%|█████████▌| 144/150 [37:37<01:28, 14.70s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  97%|█████████▋| 145/150 [37:50<01:10, 14.09s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  97%|█████████▋| 146/150 [38:05<00:56, 14.23s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  98%|█████████▊| 147/150 [38:25<00:48, 16.05s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  99%|█████████▊| 148/150 [38:38<00:30, 15.14s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas:  99%|█████████▉| 149/150 [38:52<00:14, 14.83s/it]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Generando respuestas: 100%|██████████| 150/150 [39:08<00:00, 15.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log guardado en ../data/normative/generations\\generations_log.csv, con 150 respuestas\n",
      "Distribución BUENA/MALA:\n",
      " label_quality\n",
      "1    131\n",
      "0     19\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import os, json, pandas as pd\n",
    "from tqdm import tqdm\n",
    "from bert_score import score as bertscore\n",
    "\n",
    "GEN_PATH = \"../data/normative/generations\"\n",
    "os.makedirs(GEN_PATH, exist_ok=True)\n",
    "\n",
    "with open(\"../data/eval/qa_eval_set.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    qa_eval_set = json.load(f)\n",
    "\n",
    "rows = []\n",
    "for i, entry in enumerate(tqdm(qa_eval_set, desc=\"Generando respuestas\")):\n",
    "    qid = f\"q{i+1}\"\n",
    "    query_text = entry[\"pregunta\"]\n",
    "    gold = entry[\"respuesta_esperada\"]\n",
    "    relevant_chunks = entry[\"relevant_chunks\"]\n",
    "    pdf_gold = entry[\"pdf\"]\n",
    "\n",
    "    # Recuperar top-3\n",
    "    cands = hybrid_retrieval(query_text, alpha=0.3, top_k=3)\n",
    "    top1, top2 = cands[0], cands[1] if len(cands) > 1 else (cands[0], None)\n",
    "\n",
    "    max_hybrid_score = top1[\"score\"]\n",
    "    gap_top1_top2 = max_hybrid_score - (top2[\"score\"] if top2 else 0)\n",
    "    cosine_top1 = top1[\"meta\"].get(\"cosine_score\", 0.0)\n",
    "\n",
    "    # Prompt y generación\n",
    "    prompt = build_prompt(query_text, cands)\n",
    "    response = generate_response(prompt)\n",
    "\n",
    "    # Features del prompt\n",
    "    k_in_prompt = len(cands)\n",
    "    prompt_tokens = len(prompt.split())\n",
    "\n",
    "    # PDF match (si el pdf de top-1 coincide con el gold)\n",
    "    has_pdf_match = 1 if top1[\"meta\"][\"pdf\"] == pdf_gold else 0\n",
    "\n",
    "    P, R, F1 = bertscore([response], [gold], lang=\"en\")\n",
    "    bert_f1 = float(F1[0])\n",
    "\n",
    "    #  BUENA/MALA\n",
    "    label_quality = 1 if (has_pdf_match == 1 and bert_f1 >= 0.7) else 0\n",
    "\n",
    "    rows.append({\n",
    "        \"query_id\": qid,\n",
    "        \"query\": query_text,\n",
    "        \"response\": response,\n",
    "        \"gold\": gold,\n",
    "        \"max_hybrid_score\": max_hybrid_score,\n",
    "        \"gap_top1_top2\": gap_top1_top2,\n",
    "        \"cosine_top1\": cosine_top1,\n",
    "        \"k_in_prompt\": k_in_prompt,\n",
    "        \"prompt_tokens\": prompt_tokens,\n",
    "        \"has_pdf_match\": has_pdf_match,\n",
    "        \"bertscore_f1\": bert_f1,\n",
    "        \"label_quality\": label_quality\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "out_path = os.path.join(GEN_PATH, \"generations_log.csv\")\n",
    "df.to_csv(out_path, index=False)\n",
    "print(f\"Log guardado en {out_path}, con {len(df)} respuestas\")\n",
    "print(\"Distribución BUENA/MALA:\\n\", df[\"label_quality\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c99fbe1",
   "metadata": {},
   "source": [
    "#### El dataset está desbalanceado (131 buenas vs 19 malas). Para solventarlo añadimos manualmente algunos ejemplos fuera de dominio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "969deb16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribución original:\n",
      " label_quality\n",
      "1    131\n",
      "0     19\n",
      "Name: count, dtype: int64\n",
      "Tras undersampling:\n",
      " label_quality\n",
      "1    100\n",
      "0     19\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generando respuestas extra: 100%|██████████| 50/50 [09:52<00:00, 11.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset balanceado guardado en ../data/normative/generations/generations_log_balanced.csv\n",
      "Distribución final:\n",
      " label_quality\n",
      "1    100\n",
      "0     69\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd, os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Cargar dataset original\n",
    "df = pd.read_csv(\"../data/normative/generations/generations_log.csv\")\n",
    "print(\"Distribución original:\\n\", df[\"label_quality\"].value_counts())\n",
    "\n",
    "# Submuestreo de BUENAS a 100\n",
    "df_good = df[df[\"label_quality\"] == 1].sample(n=100, random_state=42)\n",
    "df_bad = df[df[\"label_quality\"] == 0]\n",
    "df_base = pd.concat([df_good, df_bad], ignore_index=True)\n",
    "\n",
    "print(\"Tras undersampling:\\n\", df_base[\"label_quality\"].value_counts())\n",
    "\n",
    "# Queries manuales\n",
    "extra_queries = [\n",
    "    \"What is the capital of Mars?\",\n",
    "    \"Give me the recipe for Spanish paella\",\n",
    "    \"Who won the FIFA World Cup in 1998?\",\n",
    "    \"What is the square root of 12345?\",\n",
    "    \"Tell me about the movie Titanic\",\n",
    "    \"Translate 'hello' into Japanese\",\n",
    "    \"How do you bake a chocolate cake?\",\n",
    "    \"What is the weather in New York tomorrow?\",\n",
    "    \"Explain quantum physics to a child\",\n",
    "    \"List the planets in the Solar System\",\n",
    "    \"How tall is Mount Everest?\",\n",
    "    \"Who discovered penicillin?\",\n",
    "    \"Play me a song by The Beatles\",\n",
    "    \"What time is it in Tokyo right now?\",\n",
    "    \"Give me the history of Minecraft\",\n",
    "    \"Who painted the Mona Lisa?\",\n",
    "    \"Write a haiku about pizza\",\n",
    "    \"Name the main characters in Harry Potter\",\n",
    "    \"What is the formula for water?\",\n",
    "    \"Show me the stock price of Apple\",\n",
    "    \"Tell me a joke about computers\",\n",
    "    \"When was the first iPhone released?\",\n",
    "    \"Who is the current US president?\",\n",
    "    \"What does CPU stand for?\",\n",
    "    \"How many continents are there?\",\n",
    "    \"Recite the alphabet backwards\",\n",
    "    \"What is the national dish of Italy?\",\n",
    "    \"When is Christmas celebrated?\",\n",
    "    \"Who invented the airplane?\",\n",
    "    \"How far is the Moon from Earth?\",\n",
    "    \"Who is the best football player in history?\",\n",
    "    \"What is the boiling point of gold?\",\n",
    "    \"Sing me a lullaby\",\n",
    "    \"What is the meaning of life?\",\n",
    "    \"Write me a poem about dragons\",\n",
    "    \"How to fix a leaking faucet?\",\n",
    "    \"Give me the lyrics of a Beatles song\",\n",
    "    \"What is the capital of Wakanda?\",\n",
    "    \"Show me pictures of cats\",\n",
    "    \"Who directed the movie Avatar?\",\n",
    "    \"What is 12345 multiplied by 6789?\",\n",
    "    \"What is the currency of Middle Earth?\",\n",
    "    \"Give me the horoscope for tomorrow\",\n",
    "    \"What is the color of happiness?\",\n",
    "    \"How many letters are in the alphabet?\",\n",
    "    \"What is the oldest city in the world?\",\n",
    "    \"How do you make sushi?\",\n",
    "    \"Who wrote Don Quixote?\",\n",
    "    \"Explain black holes to a 5-year-old\",\n",
    "    \"Give me the current Bitcoin price\"\n",
    "]\n",
    "\n",
    "rows_extra = []\n",
    "for i, query_text in enumerate(tqdm(extra_queries, desc=\"Generando respuestas extra\")):\n",
    "    cands = hybrid_retrieval(query_text, alpha=0.3, top_k=3)\n",
    "    top1, top2 = cands[0], cands[1] if len(cands) > 1 else (cands[0], None)\n",
    "\n",
    "    max_hybrid_score = top1[\"score\"]\n",
    "    gap_top1_top2 = max_hybrid_score - (top2[\"score\"] if top2 else 0)\n",
    "    cosine_top1 = top1[\"meta\"].get(\"cosine_score\", 0.0)\n",
    "\n",
    "    prompt = build_prompt(query_text, cands)\n",
    "    response = generate_response(prompt)\n",
    "\n",
    "    k_in_prompt = len(cands)\n",
    "    prompt_tokens = len(prompt.split())\n",
    "    has_pdf_match = 0\n",
    "    bert_f1 = 0.0\n",
    "    label_quality = 0\n",
    "\n",
    "    rows_extra.append({\n",
    "        \"query_id\": f\"extra_{i+1}\",\n",
    "        \"query\": query_text,\n",
    "        \"response\": response,\n",
    "        \"gold\": \"N/A\",\n",
    "        \"max_hybrid_score\": max_hybrid_score,\n",
    "        \"gap_top1_top2\": gap_top1_top2,\n",
    "        \"cosine_top1\": cosine_top1,\n",
    "        \"k_in_prompt\": k_in_prompt,\n",
    "        \"prompt_tokens\": prompt_tokens,\n",
    "        \"has_pdf_match\": has_pdf_match,\n",
    "        \"bertscore_f1\": bert_f1,\n",
    "        \"label_quality\": label_quality\n",
    "    })\n",
    "\n",
    "df_extra = pd.DataFrame(rows_extra)\n",
    "\n",
    "df_final = pd.concat([df_base, df_extra], ignore_index=True)\n",
    "\n",
    "out_path = \"../data/normative/generations/generations_log_balanced.csv\"\n",
    "df_final.to_csv(out_path, index=False)\n",
    "\n",
    "print(f\"Dataset balanceado guardado en {out_path}\")\n",
    "print(\"Distribución final:\\n\", df_final['label_quality'].value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "cef04cfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlaciones con label_quality:\n",
      "cosine_top1: nan\n",
      "k_in_prompt: nan\n",
      "has_pdf_match: 0.988\n",
      "bertscore_f1: 0.789\n",
      "max_hybrid_score: 0.746\n",
      "gap_top1_top2: 0.376\n",
      "prompt_tokens: 0.200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\TFM_RAG_NOR\\venv\\Lib\\site-packages\\numpy\\lib\\_function_base_impl.py:3065: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "d:\\TFM_RAG_NOR\\venv\\Lib\\site-packages\\numpy\\lib\\_function_base_impl.py:3066: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/normative/generations/generations_log_balanced.csv\")\n",
    "\n",
    "# Seleccionar features y label\n",
    "feature_cols = [\n",
    "    \"max_hybrid_score\",\"gap_top1_top2\",\"cosine_top1\",\n",
    "    \"k_in_prompt\",\"prompt_tokens\",\"has_pdf_match\",\"bertscore_f1\"\n",
    "]\n",
    "\n",
    "corrs = {}\n",
    "for col in feature_cols:\n",
    "    corr = df[col].corr(df[\"label_quality\"])\n",
    "    corrs[col] = corr\n",
    "\n",
    "# correlaciones ordenadas\n",
    "corrs_sorted = dict(sorted(corrs.items(), key=lambda x: abs(x[1]), reverse=True))\n",
    "print(\"Correlaciones con label_quality:\")\n",
    "for k, v in corrs_sorted.items():\n",
    "    print(f\"{k}: {v:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "9fb554ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset balanceado: (169, 12)\n",
      "Distribución:\n",
      " label_quality\n",
      "1    100\n",
      "0     69\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- Resultados en test (20%) ---\n",
      "Acc=0.912\n",
      "Prec=0.905\n",
      "Rec=0.950\n",
      "F1=0.927\n",
      "AUC=0.954\n",
      "Fold 1 → Acc=0.882, Prec=0.909, Rec=0.909, F1=0.909, AUC=0.898\n",
      "Fold 2 → Acc=0.882, Prec=0.905, Rec=0.905, F1=0.905, AUC=0.956\n",
      "Fold 3 → Acc=0.824, Prec=0.810, Rec=0.895, F1=0.850, AUC=0.930\n",
      "Fold 4 → Acc=0.882, Prec=0.900, Rec=0.900, F1=0.900, AUC=0.954\n",
      "Fold 5 → Acc=0.848, Prec=0.810, Rec=0.944, F1=0.872, AUC=0.926\n",
      "\n",
      "--- Resultados medios (5-Fold) ---\n",
      "Acc=0.864, Prec=0.867, Rec=0.911, F1=0.887, AUC=0.933\n",
      "\n",
      "Calibrador entrenado y guardado en ../models/calibrator\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "CSV_PATH = \"../data/normative/generations/generations_log_balanced.csv\"\n",
    "MODELS_PATH = \"../models/calibrator\"\n",
    "os.makedirs(MODELS_PATH, exist_ok=True)\n",
    "\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "print(\"Dataset balanceado:\", df.shape)\n",
    "print(\"Distribución:\\n\", df[\"label_quality\"].value_counts())\n",
    "\n",
    "feature_cols = [\n",
    "    \"max_hybrid_score\",\"gap_top1_top2\",\n",
    "    \"k_in_prompt\",\"prompt_tokens\"\n",
    "]\n",
    "X, y = df[feature_cols].values, df[\"label_quality\"].values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "#  Train/Test split (80/20 estratificado)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "X_train_s, X_test_s = scaler.fit_transform(X_train), scaler.transform(X_test)\n",
    "\n",
    "clf = LogisticRegression(class_weight=\"balanced\", max_iter=500, random_state=42)\n",
    "clf.fit(X_train_s, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test_s)\n",
    "y_proba = clf.predict_proba(X_test_s)[:,1]\n",
    "\n",
    "print(\"\\n--- Resultados en test (20%) ---\")\n",
    "print(f\"Acc={accuracy_score(y_test,y_pred):.3f}\")\n",
    "print(f\"Prec={precision_score(y_test,y_pred,zero_division=0):.3f}\")\n",
    "print(f\"Rec={recall_score(y_test,y_pred,zero_division=0):.3f}\")\n",
    "print(f\"F1={f1_score(y_test,y_pred,zero_division=0):.3f}\")\n",
    "print(f\"AUC={roc_auc_score(y_test,y_proba):.3f}\")\n",
    "\n",
    "# Kfolds\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "metrics = []\n",
    "\n",
    "for fold,(train_idx,test_idx) in enumerate(kf.split(X), start=1):\n",
    "    X_tr, X_val = X[train_idx], X[test_idx]\n",
    "    y_tr, y_val = y[train_idx], y[test_idx]\n",
    "    X_tr_s, X_val_s = scaler.fit_transform(X_tr), scaler.transform(X_val)\n",
    "\n",
    "    clf_cv = LogisticRegression(class_weight=\"balanced\", max_iter=500, random_state=42)\n",
    "    clf_cv.fit(X_tr_s, y_tr)\n",
    "\n",
    "    y_val_pred = clf_cv.predict(X_val_s)\n",
    "    y_val_proba = clf_cv.predict_proba(X_val_s)[:,1]\n",
    "\n",
    "    acc = accuracy_score(y_val,y_val_pred)\n",
    "    prec = precision_score(y_val,y_val_pred,zero_division=0)\n",
    "    rec = recall_score(y_val,y_val_pred,zero_division=0)\n",
    "    f1 = f1_score(y_val,y_val_pred,zero_division=0)\n",
    "    auc = roc_auc_score(y_val,y_val_proba)\n",
    "\n",
    "    metrics.append((acc,prec,rec,f1,auc))\n",
    "    print(f\"Fold {fold} → Acc={acc:.3f}, Prec={prec:.3f}, Rec={rec:.3f}, F1={f1:.3f}, AUC={auc:.3f}\")\n",
    "\n",
    "metrics = np.mean(metrics,axis=0)\n",
    "print(\"\\n--- Resultados medios (5-Fold) ---\")\n",
    "print(f\"Acc={metrics[0]:.3f}, Prec={metrics[1]:.3f}, Rec={metrics[2]:.3f}, F1={metrics[3]:.3f}, AUC={metrics[4]:.3f}\")\n",
    "\n",
    "# Enteno\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "final_clf = LogisticRegression(class_weight=\"balanced\", max_iter=500, random_state=42)\n",
    "final_clf.fit(X_scaled,y)\n",
    "\n",
    "with open(os.path.join(MODELS_PATH,\"calibrator.pkl\"),\"wb\") as f: pickle.dump(final_clf,f)\n",
    "with open(os.path.join(MODELS_PATH,\"scaler.pkl\"),\"wb\") as f: pickle.dump(scaler,f)\n",
    "with open(os.path.join(MODELS_PATH,\"features_schema.json\"),\"w\") as f: json.dump(feature_cols,f)\n",
    "\n",
    "print(f\"\\nCalibrador entrenado y guardado en {MODELS_PATH}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "dd8c03b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Pesos del calibrador\n",
      "max_hybrid_score: 2.583\n",
      "gap_top1_top2: 0.548\n",
      "k_in_prompt: 0.000\n",
      "prompt_tokens: -0.105\n",
      "\n",
      "Ejemplos de predicciones\n",
      "Query 1: Proba=0.233, Pred=0, Real=0\n",
      "Query 2: Proba=0.986, Pred=1, Real=1\n",
      "Query 3: Proba=0.938, Pred=1, Real=1\n",
      "Query 4: Proba=0.108, Pred=0, Real=0\n",
      "Query 5: Proba=0.024, Pred=0, Real=0\n",
      "Query 6: Proba=0.042, Pred=0, Real=0\n",
      "Query 7: Proba=0.770, Pred=1, Real=1\n",
      "Query 8: Proba=0.851, Pred=1, Real=1\n",
      "Query 9: Proba=0.640, Pred=1, Real=1\n",
      "Query 10: Proba=0.895, Pred=1, Real=1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\" Pesos del calibrador\")\n",
    "for f, w in zip(feature_cols, final_clf.coef_[0]):\n",
    "    print(f\"{f}: {w:.3f}\")\n",
    "\n",
    "print(\"\\nEjemplos de predicciones\")\n",
    "for i in range(10):\n",
    "    x = X_test_s[i].reshape(1, -1)\n",
    "    proba = final_clf.predict_proba(x)[0,1]\n",
    "    pred = final_clf.predict(x)[0]\n",
    "    print(f\"Query {i+1}: Proba={proba:.3f}, Pred={pred}, Real={y_test[i]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "8a6f5b9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Umbral óptimo τ (según F1): 0.25\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "y_proba = clf.predict_proba(X_test_s)[:,1]\n",
    "\n",
    "taus = np.linspace(0, 1, 21)  # umbrales de 0 a 1 en pasos de 0.05\n",
    "coverage, quality, f1_scores = [], [], []\n",
    "\n",
    "for tau in taus:\n",
    "    preds = (y_proba >= tau).astype(int)\n",
    "    \n",
    "    # Cobertura: % de respuestas que se muestran\n",
    "    cov = (preds == 1).mean()\n",
    "    \n",
    "    # Calidad: precisión entre las respuestas que sí se muestran\n",
    "    if preds.sum() > 0:\n",
    "        q = (y_test[preds == 1] == 1).mean()\n",
    "    else:\n",
    "        q = 0.0\n",
    "    \n",
    "    f1 = f1_score(y_test, preds, zero_division=0)\n",
    "    \n",
    "    coverage.append(cov)\n",
    "    quality.append(q)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.plot(coverage, quality, marker=\"o\")\n",
    "for t,c,q in zip(taus, coverage, quality):\n",
    "    plt.text(c, q, f\"{t:.2f}\", fontsize=8)\n",
    "plt.xlabel(\"Cobertura (porcentaje de respuestas mostradas)\")\n",
    "plt.ylabel(\"Calidad (precisión en respondidas)\")\n",
    "plt.title(\"Trade-off Cobertura vs Calidad según umbral τ\")\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "plt.show()\n",
    "\n",
    "#  τ / F1\n",
    "best_tau = taus[np.argmax(f1_scores)]\n",
    "print(f\"Umbral óptimo τ (según F1): {best_tau:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3340af14",
   "metadata": {},
   "source": [
    "### 6.3 Demo + calibrador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "61610374",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8838094869c84ea4b393afb95770d447",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: (357, 768)\n"
     ]
    }
   ],
   "source": [
    "# build_chunk_embeddings.py\n",
    "import os, json, numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "DATA_PATH = \"../data\"\n",
    "EMB_DIR = os.path.join(DATA_PATH, \"embeddings\")\n",
    "os.makedirs(EMB_DIR, exist_ok=True)\n",
    "\n",
    "MODEL_NAME = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "\n",
    "with open(os.path.join(DATA_PATH, \"chunks\", \"texts.json\"), \"r\", encoding=\"utf-8\") as f:\n",
    "    texts = json.load(f)\n",
    "\n",
    "model = SentenceTransformer(MODEL_NAME)\n",
    "embs = model.encode(texts, batch_size=128, convert_to_numpy=True, normalize_embeddings=True, show_progress_bar=True)\n",
    "np.save(os.path.join(EMB_DIR, \"mpnet_embeddings.npy\"), embs)\n",
    "print(\"Saved:\", embs.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "2fdc7a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === SETUP RAG + RE-RANKER + CALIBRADOR ===\n",
    "import os, json, pickle, faiss, numpy as np\n",
    "from typing import List, Dict, Any\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from openai import OpenAI\n",
    "\n",
    "DATA_PATH   = \"../data\"\n",
    "MODELS_PATH = \"../models\"\n",
    "EMB_DIR     = os.path.join(DATA_PATH, \"embeddings\")\n",
    "\n",
    "HYBRID_ALPHA   = 0.3\n",
    "POOL_K         = 25\n",
    "TOP_K          = 3\n",
    "CALIBRATOR_TAU = 0.25\n",
    "GEN_MODEL      = \"llama-3.1-8b-instant\"\n",
    "\n",
    "# corpus / indices\n",
    "with open(os.path.join(DATA_PATH, \"bm25\", \"bm25_index.pkl\"), \"rb\") as f:\n",
    "    bm25 = pickle.load(f)\n",
    "faiss_index = faiss.read_index(os.path.join(DATA_PATH, \"faiss_index\", \"faiss_index_mpnet.faiss\"))\n",
    "with open(os.path.join(DATA_PATH, \"chunks\", \"texts.json\"), \"r\", encoding=\"utf-8\") as f:\n",
    "    texts: List[str] = json.load(f)\n",
    "with open(os.path.join(DATA_PATH, \"chunks\", \"metadata.json\"), \"r\", encoding=\"utf-8\") as f:\n",
    "    metadata: List[Dict[str, Any]] = json.load(f)\n",
    "chunk_embs = np.load(os.path.join(EMB_DIR, \"mpnet_embeddings.npy\"))\n",
    "\n",
    "# modelos\n",
    "mpnet_model = SentenceTransformer(\"sentence-transformers/all-mpnet-base-v2\")\n",
    "client = OpenAI(api_key=\"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\", base_url=\"https://api.groq.com/openai/v1\")\n",
    "\n",
    "with open(os.path.join(MODELS_PATH, \"reranker\", \"reranker.pkl\"), \"rb\") as f:\n",
    "    reranker = pickle.load(f)\n",
    "with open(os.path.join(MODELS_PATH, \"reranker\", \"scaler.pkl\"), \"rb\") as f:\n",
    "    rr_scaler: StandardScaler = pickle.load(f)\n",
    "with open(os.path.join(MODELS_PATH, \"reranker\", \"features_schema.json\"), \"r\", encoding=\"utf-8\") as f:\n",
    "    rr_feature_cols: List[str] = json.load(f)\n",
    "\n",
    "with open(os.path.join(MODELS_PATH, \"calibrator\", \"calibrator.pkl\"), \"rb\") as f:\n",
    "    calibrator = pickle.load(f)\n",
    "with open(os.path.join(MODELS_PATH, \"calibrator\", \"scaler.pkl\"), \"rb\") as f:\n",
    "    cal_scaler: StandardScaler = pickle.load(f)\n",
    "with open(os.path.join(MODELS_PATH, \"calibrator\", \"features_schema.json\"), \"r\", encoding=\"utf-8\") as f:\n",
    "    cal_feature_cols: List[str] = json.load(f)\n",
    "\n",
    "# utils\n",
    "def preprocess(s: str): return s.lower().strip()\n",
    "def tokenize_simple(s: str): return [t for t in preprocess(s).split() if t.isalpha()]\n",
    "def lexical_overlap(q, c):\n",
    "    qs, cs = set(tokenize_simple(q)), set(tokenize_simple(c))\n",
    "    return 0.0 if not qs or not cs else len(qs & cs) / len(qs | cs)\n",
    "\n",
    "# retrieval pool\n",
    "def hybrid_candidate_pool(query, alpha=HYBRID_ALPHA, pool_k=POOL_K):\n",
    "    q = preprocess(query)\n",
    "    bm25_scores = bm25.get_scores(q.split()).astype(np.float32)\n",
    "    q_emb = mpnet_model.encode([q], convert_to_numpy=True, normalize_embeddings=True)\n",
    "    D, I = faiss_index.search(q_emb, len(texts))\n",
    "    mpnet_scores = np.zeros(len(texts), dtype=np.float32)\n",
    "    mpnet_scores[I[0]] = D[0].astype(np.float32)\n",
    "    hybrid_scores = alpha * mpnet_scores + (1.0 - alpha) * bm25_scores\n",
    "    ranked = np.argsort(-hybrid_scores)[:pool_k]\n",
    "    return ranked, bm25_scores, mpnet_scores, hybrid_scores, q_emb\n",
    "\n",
    "# re-ranker\n",
    "def build_reranker_features(query, cand_idx, bm25_s, mpnet_s, q_emb, alpha=HYBRID_ALPHA):\n",
    "    cos_qc = (q_emb @ chunk_embs[cand_idx].T)[0].astype(np.float32)\n",
    "    hybrid_vals = alpha * mpnet_s[cand_idx] + (1.0 - alpha) * bm25_s[cand_idx]\n",
    "    gap = float(hybrid_vals[0] - hybrid_vals[1]) if len(cand_idx) > 1 else float(hybrid_vals[0])\n",
    "    feats = []\n",
    "    for r, (idx, cosv, hv) in enumerate(zip(cand_idx, cos_qc, hybrid_vals)):\n",
    "        feats.append({\n",
    "            \"bm25_score\": float(bm25_s[idx]),\n",
    "            \"cosine_qc\": float(cosv),\n",
    "            \"hybrid_score\": float(hv),\n",
    "            \"rank\": r + 1,\n",
    "            \"gap_top1_top2\": gap if r == 0 else 0.0,\n",
    "            \"lexical_overlap\": lexical_overlap(query, texts[int(idx)]),\n",
    "            \"tokens_count_q\": len(tokenize_simple(query)),\n",
    "            \"tokens_count_c\": len(tokenize_simple(texts[int(idx)])),\n",
    "            \"_idx\": int(idx)\n",
    "        })\n",
    "    X = np.array([[f[c] for c in rr_feature_cols] for f in feats], dtype=np.float32)\n",
    "    return X, feats\n",
    "\n",
    "def retrieve_then_rerank(query, alpha=HYBRID_ALPHA, pool_k=POOL_K, top_k=TOP_K):\n",
    "    cand_idx, bm25_s, mpnet_s, hybrid_s, q_emb = hybrid_candidate_pool(query, alpha=alpha, pool_k=pool_k)\n",
    "    X, feats = build_reranker_features(query, cand_idx, bm25_s, mpnet_s, q_emb, alpha=alpha)\n",
    "    probs = reranker.predict_proba(rr_scaler.transform(X))[:, 1]\n",
    "    order = np.argsort(-probs)[:top_k]\n",
    "    selected = []\n",
    "    for j in order:\n",
    "        idx = feats[j][\"_idx\"]\n",
    "        selected.append({\"_idx\": idx, \"chunk\": texts[idx], \"meta\": metadata[idx], \"rerank_score\": float(probs[j])})\n",
    "    hybrid_selected = [float(hybrid_s[s[\"_idx\"]]) for s in selected]\n",
    "    return selected, hybrid_selected\n",
    "\n",
    "# prompt / generación\n",
    "def build_prompt(query, chunks):\n",
    "    ctx = \"\\n\\n\".join([f\"[Doc: {c['meta'].get('pdf','N/A')}, pages: {c['meta'].get('pages','?')}]\\n{c['chunk']}\" for c in chunks])\n",
    "    return f\"Question: {query}\\n\\nContext:\\n{ctx}\\n\\nInstruction:\\nAnswer the question using only the context above. If the answer is not in the documents, say clearly that it is not found.\"\n",
    "\n",
    "def generate_response(prompt, model=GEN_MODEL, temperature=0.2, max_tokens=512):\n",
    "    out = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\":\"system\",\"content\":\"You are an assistant specialized in AI ethics and governance.\"},\n",
    "                  {\"role\":\"user\",\"content\":prompt}],\n",
    "        temperature=temperature,\n",
    "        max_tokens=max_tokens\n",
    "    )\n",
    "    return out.choices[0].message.content.strip()\n",
    "\n",
    "# calibrador\n",
    "def build_calibrator_features(chunks, prompt, hybrid_top):\n",
    "    max_h = float(max(hybrid_top)) if hybrid_top else 0.0\n",
    "    gap   = float(hybrid_top[0] - hybrid_top[1]) if len(hybrid_top) > 1 else max_h\n",
    "    feats = {\"max_hybrid_score\": max_h, \"gap_top1_top2\": gap, \"k_in_prompt\": len(chunks), \"prompt_tokens\": len(prompt.split())}\n",
    "    return np.array([[feats[c] for c in cal_feature_cols]], dtype=np.float32)\n",
    "\n",
    "def calibrate(chunks, prompt, hybrid_top, tau=CALIBRATOR_TAU):\n",
    "    Xs = cal_scaler.transform(build_calibrator_features(chunks, prompt, hybrid_top))\n",
    "    p = float(calibrator.predict_proba(Xs)[:, 1][0])\n",
    "    return (p >= tau), p\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "a95aac1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Query ===\n",
      "What is the main advisory responsibility of the European Artificial Intelligence Board according to the regulation?\n",
      "\n",
      "=== Chunks seleccionados ===\n",
      "01) Doc: eu_ai_act_regulation.pdf | Pages: [2] | rerank_score: 0.1465\n",
      "02) Doc: eu_ai_act_regulation.pdf | Pages: [37] | rerank_score: 0.1162\n",
      "03) Doc: eu_ai_act_regulation.pdf | Pages: [] | rerank_score: 0.0951\n",
      "\n",
      "=== Respuesta generada ===\n",
      "According to the provided context, the main advisory responsibility of the European Artificial Intelligence Board is to issue opinions, recommendations, advice or guidance on matters related to the implementation of the Regulation, including on technical specifications or existing standards regarding the requirements established in this Regulation, and to provide advice to and assist the Commission on specific questions related to artificial intelligence.\n",
      "\n",
      "=== Calibrador ===\n",
      "✔ Mostrar (p=0.70)\n",
      "\n",
      "============================================================\n",
      "\n",
      "\n",
      "=== Query ===\n",
      "Why does the document emphasize a holistic and systemic approach to achieving Trustworthy AI?\n",
      "\n",
      "=== Chunks seleccionados ===\n",
      "01) Doc: ai_hleg_ethics_guidelines.pdf | Pages: [7] | rerank_score: 0.1488\n",
      "02) Doc: ai_hleg_ethics_guidelines.pdf | Pages: [] | rerank_score: 0.1028\n",
      "03) Doc: ai_hleg_ethics_guidelines.pdf | Pages: [] | rerank_score: 0.0990\n",
      "\n",
      "=== Respuesta generada ===\n",
      "The document emphasizes a holistic and systemic approach to achieving Trustworthy AI because it concerns not only the trustworthiness of the AI system itself, but also the trustworthiness of all actors and processes that are part of the system's socio-technical context throughout its entire life cycle. This approach is necessary because trust in AI systems is not solely dependent on the technology's inherent properties, but also on the qualities of the socio-technical systems involving AI applications.\n",
      "\n",
      "According to the document, a holistic and systemic approach to achieving Trustworthy AI requires considering the trustworthiness of all actors and processes that are part of the system's socio-technical context, including the system's entire life cycle. This approach is necessary to ensure that AI systems are lawful, ethical, and robust, and that they meet the three components of Trustworthy AI: (1) lawfulness, (2) ethics, and (3) robustness.\n",
      "\n",
      "The document also mentions that a sectorial approach may be needed, given the context-specificity of AI systems, but this is not the primary reason for emphasizing a holistic and systemic approach. The primary reason is to ensure that AI systems are trustworthy and meet the three components of Trustworthy AI throughout their entire life cycle.\n",
      "\n",
      "=== Calibrador ===\n",
      "✔ Mostrar (p=0.83)\n",
      "\n",
      "============================================================\n",
      "\n",
      "\n",
      "=== Query ===\n",
      "What principles does UNESCO establish on AI ethics?\n",
      "\n",
      "=== Chunks seleccionados ===\n",
      "01) Doc: ai_hleg_ethics_guidelines.pdf | Pages: [14] | rerank_score: 0.0882\n",
      "02) Doc: ai_hleg_ethics_guidelines.pdf | Pages: [] | rerank_score: 0.0560\n",
      "03) Doc: ai_hleg_ethics_guidelines.pdf | Pages: [4] | rerank_score: 0.0541\n",
      "\n",
      "=== Respuesta generada ===\n",
      "According to the provided context, UNESCO establishes the following principles on AI ethics, which are based on the EU Charter and the AI4People taskforce's survey of existing ethical principles:\n",
      "\n",
      "1. **Respect for human autonomy**: This principle is strongly associated with the right to human dignity and liberty (reflected in Articles 1 and 6 of the Charter).\n",
      "2. **Prevention of harm**: This principle is strongly linked to the protection of physical or mental integrity (reflected in Article 3).\n",
      "3. **Fairness**: This principle is not explicitly linked to a specific article in the provided context, but it is mentioned as one of the four overarching principles.\n",
      "4. **Explicability**: This principle is also mentioned as one of the four overarching principles.\n",
      "\n",
      "These principles are not specific to AI systems and can be applied to the development, deployment, and use of other technologies.\n",
      "\n",
      "=== Calibrador ===\n",
      "✖ Abstener (p=0.04)\n",
      "\n",
      "============================================================\n",
      "\n",
      "\n",
      "=== Query ===\n",
      "Wich is the most relevant AI ethics document?\n",
      "\n",
      "=== Chunks seleccionados ===\n",
      "01) Doc: ai_hleg_ethics_guidelines.pdf | Pages: [11] | rerank_score: 0.1516\n",
      "02) Doc: ai_hleg_ethics_guidelines.pdf | Pages: [12] | rerank_score: 0.1203\n",
      "03) Doc: ai_hleg_ethics_guidelines.pdf | Pages: [25] | rerank_score: 0.0932\n",
      "\n",
      "=== Respuesta generada ===\n",
      "Based on the provided context, the most relevant AI ethics document is the \"EU High-Level Expert Group on Artificial Intelligence (HLEG AI) Ethics Guidelines for Trustworthy AI\" document, specifically the pages [11-25] of the document \"ai_hleg_ethics_guidelines.pdf\". \n",
      "\n",
      "This document outlines the foundations of Trustworthy AI, grounded in fundamental rights and reflected by four ethical principles that should be adhered to in order to ensure ethical and robust AI. It emphasizes the importance of respecting fundamental rights, building an ethical culture and mindset, and promoting a human-centric approach to AI development and deployment.\n",
      "\n",
      "=== Calibrador ===\n",
      "✖ Abstener (p=0.11)\n",
      "\n",
      "============================================================\n",
      "\n",
      "\n",
      "=== Query ===\n",
      "What is the recipe for Spanish paella?\n",
      "\n",
      "=== Chunks seleccionados ===\n",
      "01) Doc: ai_hleg_ethics_guidelines.pdf | Pages: [31] | rerank_score: 0.0004\n",
      "02) Doc: ai_hleg_ethics_guidelines.pdf | Pages: [30] | rerank_score: 0.0003\n",
      "03) Doc: oecd_ai_classification_framework.pdf | Pages: [] | rerank_score: 0.0003\n",
      "\n",
      "=== Respuesta generada ===\n",
      "The provided context does not contain information about the recipe for Spanish paella. It appears to be a collection of documents related to AI ethics and governance guidelines, including OECD AI Classification Framework and AI HLEG Ethics Guidelines. \n",
      "\n",
      "There is no mention of cooking or recipes in the provided context. Therefore, I must conclude that the recipe for Spanish paella is not found in the given documents.\n",
      "\n",
      "=== Calibrador ===\n",
      "✖ Abstener (p=0.07)\n",
      "\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# === DEMO ===\n",
    "while True:\n",
    "    try:\n",
    "        q = input(\"Escribe tu pregunta (o 'exit' para salir): \").strip()\n",
    "    except (EOFError, KeyboardInterrupt):\n",
    "        break\n",
    "    if q.lower() == \"exit\":\n",
    "        break\n",
    "    if not q:\n",
    "        continue\n",
    "\n",
    "    chunks, hybrid_selected = retrieve_then_rerank(q, alpha=HYBRID_ALPHA, pool_k=POOL_K, top_k=TOP_K)\n",
    "    prompt = build_prompt(q, chunks)\n",
    "    resp = generate_response(prompt)\n",
    "\n",
    "    ok, proba = calibrate(chunks, prompt, hybrid_selected, tau=CALIBRATOR_TAU)\n",
    "\n",
    "    print(\"\\n=== Query ===\")\n",
    "    print(q)\n",
    "\n",
    "    print(\"\\n=== Chunks seleccionados ===\")\n",
    "    for i, c in enumerate(chunks, 1):\n",
    "        m = c[\"meta\"]\n",
    "        print(f\"{i:02d}) Doc: {m.get('pdf','N/A')} | Pages: {m.get('pages','?')} | rerank_score: {c['rerank_score']:.4f}\")\n",
    "\n",
    "    print(\"\\n=== Respuesta generada ===\")\n",
    "    print(resp)\n",
    "\n",
    "    print(\"\\n=== Calibrador ===\")\n",
    "    print(f\"{'✔ Mostrar' if ok else '✖ Abstener'} (p={proba:.2f})\")\n",
    "    print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961795ea",
   "metadata": {},
   "source": [
    "### Conclusión sobre el calibrador\n",
    "\n",
    "El calibrador funciona como una capa adicional que ayuda a decidir si una respuesta generada es confiable o si conviene abstenerse.  \n",
    "En la práctica responde bien en casos literales o muy claros, y suele abstenerse cuando la pregunta está fuera de dominio.  \n",
    "\n",
    "Sin embargo, el dataset usado es pequeño y limitado, por lo que el calibrador no puede considerarse un modelo autónomo ni totalmente fiable.  \n",
    "Es útil como apoyo y filtro de seguridad, pero siempre requiere verificación adicional para garantizar la calidad de las respuestas.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
