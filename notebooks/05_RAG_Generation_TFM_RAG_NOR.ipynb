{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be7a6b7c",
   "metadata": {},
   "source": [
    "# RAG Generation en TFM_RAG_NOR\n",
    "\n",
    "## Índice\n",
    "\n",
    "\n",
    "1. [Introducción y objetivos](#1-introducción-y-objetivos)\n",
    "2. [Carga de datos y configuración](#2-carga-de-datos-y-configuración)\n",
    "3. [Pipeline RAG: Recuperación + Generación](#3-pipeline-rag-recuperación--generación)\n",
    "    - 3.1. Recuperación de chunks relevantes (Hybrid MPNet α=0.3)\n",
    "    - 3.2. Construcción del prompt\n",
    "    - 3.3. Generación de respuesta con LLM\n",
    "    - 3.4. Visualización de resultados (respuesta + chunks)\n",
    "4. [Evaluación de la generación](#4-evaluación-de-la-generación)\n",
    "    - 4.1. Evaluación manual (exactitud, completitud, estilo)\n",
    "    - 4.2. Evaluación automática (BERTScore y opcionalmente métricas RAGAS simples)\n",
    "5. [Demo tester](#5-demo-tester)  \n",
    "\n",
    "---\n",
    "\n",
    "## 1. Introducción y objetivos\n",
    "\n",
    "En este notebook se implementa la fase de generación del sistema RAG sobre el corpus de documentos normativos.  \n",
    "Hasta ahora se han preparado los datos, creado los índices y evaluado diferentes métodos de recuperación. El mejor rendimiento lo dio el método híbrido BM25 + MPNet (α=0.3), que será el que se use aquí como base.\n",
    "\n",
    "El objetivo es montar un pipeline completo de RAG (retrieval → generación), capaz de:\n",
    "- Recuperar los chunks más relevantes para una query.\n",
    "- Construir un prompt con esos chunks y la pregunta.\n",
    "- Enviar el prompt a un LLM open-source vía API gratuita.\n",
    "- Obtener una respuesta fundamentada en los documentos recuperados.\n",
    "- Guardar y evaluar las respuestas generadas.\n",
    "\n",
    "Este notebook servirá como prototipo mínimo viable de RAG, sobre el que se podrá analizar el alcance, limitaciones y posibles mejoras.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Carga de datos y configuración\n",
    "\n",
    "En esta parte se importan las librerías necesarias, se cargan los datos de soporte (benchmark de preguntas y respuestas) y se configuran las claves de acceso para el modelo de lenguaje.  \n",
    "\n",
    "También se definen las rutas de trabajo (`data/`, `results/`) y se cargan las funciones de recuperación que ya se usaron en la fase anterior para garantizar coherencia.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97554646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-1.101.0-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from openai) (4.9.0)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from openai) (0.28.1)\n",
      "Collecting jiter<1,>=0.4.0 (from openai)\n",
      "  Downloading jiter-0.10.0-cp313-cp313-win_amd64.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from openai) (2.11.7)\n",
      "Requirement already satisfied: sniffio in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from openai) (4.14.1)\n",
      "Requirement already satisfied: idna>=2.8 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2025.7.14)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
      "Requirement already satisfied: colorama in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Downloading openai-1.101.0-py3-none-any.whl (810 kB)\n",
      "   ---------------------------------------- 0.0/810.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 810.8/810.8 kB 7.8 MB/s eta 0:00:00\n",
      "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading jiter-0.10.0-cp313-cp313-win_amd64.whl (205 kB)\n",
      "Installing collected packages: jiter, distro, openai\n",
      "\n",
      "   ---------------------------------------- 0/3 [jiter]\n",
      "   ---------------------------------------- 0/3 [jiter]\n",
      "   ------------- -------------------------- 1/3 [distro]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   -------------------------- ------------- 2/3 [openai]\n",
      "   ---------------------------------------- 3/3 [openai]\n",
      "\n",
      "Successfully installed distro-1.9.0 jiter-0.10.0 openai-1.101.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621ad324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preguntas cargadas: 150\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from openai import OpenAI\n",
    "\n",
    "DATA_PATH = \"../data/\"\n",
    "RESULTS_PATH = \"../results/\"\n",
    "os.makedirs(RESULTS_PATH, exist_ok=True)\n",
    "\n",
    "with open(os.path.join(DATA_PATH, \"eval\", \"qa_eval_set.json\"), \"r\", encoding=\"utf-8\") as f:\n",
    "    qa_eval_set = json.load(f)\n",
    "\n",
    "print(\"Preguntas cargadas:\", len(qa_eval_set))\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=\"GROQ_API_KEY\",\n",
    "    base_url=\"https://api.groq.com/openai/v1\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084b7262",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Pipeline RAG: Recuperación + Generación\n",
    "\n",
    "### 3.1. Recuperación de chunks relevantes (Hybrid MPNet α=0.3)\n",
    "\n",
    "En esta parte se reutilizan los índices creados en la fase anterior para recuperar los chunks más relevantes a partir de una query.  \n",
    "Se aplicará el mismo pipeline de preprocesado y combinación híbrida (BM25 + MPNet con α=0.3) que dio los mejores resultados en la evaluación.  \n",
    "\n",
    "El objetivo es garantizar que cualquier nueva pregunta, ya sea escrita a mano o tomada del benchmark, pase por el mismo proceso de recuperación coherente antes de la generación de respuesta.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6dc6a92a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ipywidgets\n",
      "  Using cached ipywidgets-8.1.7-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: comm>=0.1.3 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from ipywidgets) (0.2.3)\n",
      "Requirement already satisfied: ipython>=6.1.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from ipywidgets) (9.4.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from ipywidgets) (5.14.3)\n",
      "Collecting widgetsnbextension~=4.0.14 (from ipywidgets)\n",
      "  Using cached widgetsnbextension-4.0.14-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting jupyterlab_widgets~=3.0.15 (from ipywidgets)\n",
      "  Using cached jupyterlab_widgets-3.0.15-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: colorama in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.4.6)\n",
      "Requirement already satisfied: decorator in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (3.0.51)\n",
      "Requirement already satisfied: pygments>=2.4.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (2.19.2)\n",
      "Requirement already satisfied: stack_data in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: wcwidth in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: executing>=1.2.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "Using cached ipywidgets-8.1.7-py3-none-any.whl (139 kB)\n",
      "Using cached jupyterlab_widgets-3.0.15-py3-none-any.whl (216 kB)\n",
      "Using cached widgetsnbextension-4.0.14-py3-none-any.whl (2.2 MB)\n",
      "Installing collected packages: widgetsnbextension, jupyterlab_widgets, ipywidgets\n",
      "\n",
      "   ---------------------------------------- 0/3 [widgetsnbextension]\n",
      "   ------------- -------------------------- 1/3 [jupyterlab_widgets]\n",
      "   -------------------------- ------------- 2/3 [ipywidgets]\n",
      "   -------------------------- ------------- 2/3 [ipywidgets]\n",
      "   -------------------------- ------------- 2/3 [ipywidgets]\n",
      "   -------------------------- ------------- 2/3 [ipywidgets]\n",
      "   -------------------------- ------------- 2/3 [ipywidgets]\n",
      "   -------------------------- ------------- 2/3 [ipywidgets]\n",
      "   -------------------------- ------------- 2/3 [ipywidgets]\n",
      "   -------------------------- ------------- 2/3 [ipywidgets]\n",
      "   -------------------------- ------------- 2/3 [ipywidgets]\n",
      "   -------------------------- ------------- 2/3 [ipywidgets]\n",
      "   -------------------------- ------------- 2/3 [ipywidgets]\n",
      "   ---------------------------------------- 3/3 [ipywidgets]\n",
      "\n",
      "Successfully installed ipywidgets-8.1.7 jupyterlab_widgets-3.0.15 widgetsnbextension-4.0.14\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "006e56dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pdf': 'ai_hleg_ethics_guidelines.pdf', 'pages': [], 'titles': [], 'chunk_index': 50, 'n_words': 300} Fundamental rights: Did you carry out a fundamental rights impact assessment where there could be a negative impact on fundamental rights? Did you identify and document potential trade-offs made betwe ...\n",
      "\n",
      "{'pdf': 'ai_hleg_ethics_guidelines.pdf', 'pages': [32], 'titles': ['6. Societal and environmental well-being'], 'chunk_index': 56, 'n_words': 300} a set of procedures to avoid creating or reinforcing unfair bias in the AI system, both regarding the use of input data as well as for the algorithm design? Did you assess and acknowledge the possible ...\n",
      "\n",
      "{'pdf': 'ai_hleg_ethics_guidelines.pdf', 'pages': [], 'titles': [], 'chunk_index': 55, 'n_words': 300} in mind from the start? Did you research and try to use the simplest and most interpretable model possible for the application in question? Did you assess whether you can analyse your training and tes ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import pickle\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import json\n",
    "\n",
    "# BM25\n",
    "with open(\"../data/bm25/bm25_index.pkl\", \"rb\") as f:\n",
    "    bm25 = pickle.load(f)\n",
    "\n",
    "# FAISS MPNet\n",
    "faiss_index = faiss.read_index(\"../data/faiss_index/faiss_index_mpnet.faiss\")\n",
    "\n",
    "# Cargar chunks y metadatos (listas)\n",
    "with open(\"../data/chunks/texts.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    texts = json.load(f)\n",
    "\n",
    "with open(\"../data/chunks/metadata.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    metadata = json.load(f)\n",
    "\n",
    "# Modelo embeddings MPNet\n",
    "mpnet_model = SentenceTransformer(\"sentence-transformers/all-mpnet-base-v2\")\n",
    "\n",
    "def preprocess(text):\n",
    "    return text.lower().strip()\n",
    "\n",
    "def hybrid_retrieval(query, alpha=0.3, top_k=3):\n",
    "    q = preprocess(query)\n",
    "\n",
    "    # BM25\n",
    "    tokenized_q = q.split()\n",
    "    bm25_scores = bm25.get_scores(tokenized_q)\n",
    "\n",
    "    # MPNet\n",
    "    q_emb = mpnet_model.encode([q])\n",
    "    D, I = faiss_index.search(q_emb, len(texts))\n",
    "    mpnet_scores = [0] * len(texts)\n",
    "    for idx, score in zip(I[0], D[0]):\n",
    "        mpnet_scores[idx] = float(score)\n",
    "\n",
    "    # Híbrido\n",
    "    hybrid_scores = [\n",
    "        alpha * mpnet_scores[i] + (1 - alpha) * bm25_scores[i]\n",
    "        for i in range(len(texts))\n",
    "    ]\n",
    "\n",
    "    # Top-k\n",
    "    ranked = sorted(enumerate(hybrid_scores), key=lambda x: x[1], reverse=True)[:top_k]\n",
    "\n",
    "    # Devolver chunks\n",
    "    results = []\n",
    "    for idx, score in ranked:\n",
    "        results.append({\n",
    "            \"chunk\": texts[idx],\n",
    "            \"meta\": metadata[idx],\n",
    "            \"score\": score\n",
    "        })\n",
    "    return results\n",
    "\n",
    "# Test\n",
    "test_query = \"What principles does UNESCO establish on AI ethics?\"\n",
    "chunks = hybrid_retrieval(test_query, alpha=0.3, top_k=3)\n",
    "for c in chunks:\n",
    "    print(c[\"meta\"], c[\"chunk\"][:200], \"...\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052e0919",
   "metadata": {},
   "source": [
    "### 3.2. Construcción del prompt\n",
    "\n",
    "Se genera un prompt que combina la pregunta del usuario con los chunks recuperados.  \n",
    "El prompt incluye referencias al documento y página de cada chunk, de forma que el modelo pueda usar esa información como contexto y devolver una respuesta fundamentada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a031dee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What principles does UNESCO establish on AI ethics?\n",
      "\n",
      "Context:\n",
      "[Doc: ai_hleg_ethics_guidelines.pdf, page: []]\n",
      "Fundamental rights: Did you carry out a fundamental rights impact assessment where there could be a negative impact on fundamental rights? Did you identify and document potential trade-offs made between the different principles and rights? Does the AI system interact with decisions by human (end) users (e.g. recommended actions or decisions to take, presenting of options)? Could the AI system affect human autonomy by interfering with the (end) user s decision-making process in an unintended way? Did you consider whether the AI system should communicate to (end) users that a decision, content, advice or outcome is the result of an algorithmic decision? In case of a chat bot ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def build_prompt(query, chunks):\n",
    "    context_parts = []\n",
    "    for c in chunks:\n",
    "        ref = f\"[Doc: {c['meta']['pdf']}, page: {c['meta']['pages']}]\"\n",
    "        text = c[\"chunk\"]\n",
    "        context_parts.append(f\"{ref}\\n{text}\")\n",
    "    \n",
    "    context = \"\\n\\n\".join(context_parts)\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "Question: {query}\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Instruction:\n",
    "Answer the question using only the context above.\n",
    "If the answer is not in the documents, say clearly that it is not found.\n",
    "Always include the reference (Doc and page).\n",
    "\"\"\"\n",
    "    return prompt.strip()\n",
    "\n",
    "# Test\n",
    "prompt_example = build_prompt(test_query, chunks)\n",
    "print(prompt_example[:800], \"...\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a351bcda",
   "metadata": {},
   "source": [
    "### 3.3. Generación de respuesta con LLM\n",
    "\n",
    "Se conecta con el modelo `llama-3-8b-instruct` servido por Groq a través de la API compatible con OpenAI.  \n",
    "Se envía el prompt generado y se obtiene como salida una respuesta en lenguaje natural, fundamentada en los documentos recuperados.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c8f3915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Answer ===\n",
      "\n",
      "According to the UNESCO AI Ethics Guidelines, the following principles are established:\n",
      "\n",
      "1. Human rights: The guidelines emphasize the importance of conducting a fundamental rights impact assessment to identify potential trade-offs between different principles and rights. It also highlights the need to consider whether the AI system interacts with human decisions and whether it affects human autonomy.\n",
      "\n",
      "2. Human agency: The guidelines stress the importance of considering the task allocation between the AI system and humans for meaningful interactions and appropriate human oversight and control. It also emphasizes the need to prevent overconfidence in or overreliance on the AI system.\n",
      "\n",
      "3. Human oversight: The guidelines recommend considering the appropriate level of human control for the particular AI system and use case. It also suggests establishing mechanisms and measures to ensure human control or oversight.\n",
      "\n",
      "4. Transparency: The guidelines emphasize the importance of communicating to end-users that they are interacting with an AI system and not with another human. It also recommends labeling the AI system as such and establishing mechanisms to inform end-users on the reasons and criteria behind the AI system's outcomes.\n",
      "\n",
      "5. Fairness: The guidelines recommend establishing a set of procedures to avoid creating or reinforcing unfair bias in the AI system. It also suggests assessing and acknowledging the possible limitations stemming from the composition of the used data sets and considering diversity and representativeness of users in the data.\n",
      "\n",
      "6. Accessibility and universal design: The guidelines recommend ensuring that the AI system accommodates diverse needs and abilities from the start.\n",
      "\n",
      "7. Communication: The guidelines emphasize the importance of communicating to end-users about the AI system's limitations, potential risks, and potential biases.\n",
      "\n",
      "These principles are established to ensure that AI systems are developed and deployed in a way that respects human rights, promotes human agency, and ensures transparency, fairness, and accessibility.\n"
     ]
    }
   ],
   "source": [
    "def generate_response(prompt, model=\"llama3-8b-8192\"):\n",
    "    completion = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an assistant specialized in AI ethics regulations.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=0.2,\n",
    "        max_tokens=512\n",
    "    )\n",
    "    return completion.choices[0].message.content.strip()\n",
    "\n",
    "# Test con el prompt de ejemplo\n",
    "response = generate_response(prompt_example)\n",
    "print(\"=== Answer ===\\n\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0308d8e9",
   "metadata": {},
   "source": [
    "### 3.4. Visualización de resultados (respuesta + chunks)\n",
    "\n",
    "Se muestra de forma ordenada la pregunta, la respuesta generada y los chunks usados, con sus metadatos (documento, página, título).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81b4be4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Query ===\n",
      "What principles does UNESCO establish on AI ethics? \n",
      "\n",
      "=== Answer ===\n",
      "According to the UNESCO AI Ethics Guidelines, the following principles are established:\n",
      "\n",
      "1. Human rights: The guidelines emphasize the importance of conducting a fundamental rights impact assessment to identify potential negative impacts on fundamental rights and to document potential trade-offs between different principles and rights.\n",
      "\n",
      "2. Human agency: The guidelines highlight the need to consider the task allocation between AI systems and humans for meaningful interactions and appropriate human oversight and control.\n",
      "\n",
      "3. Human oversight: The guidelines emphasize the importance of establishing mechanisms and measures to ensure human control or oversight, including audit and remedy mechanisms.\n",
      "\n",
      "4. Transparency: The guidelines recommend communicating to end-users that they are interacting with an AI system and not with another human, and establishing mechanisms to inform end-users on the reasons and criteria behind the AI system's outcomes.\n",
      "\n",
      "5. Fairness: The guidelines emphasize the importance of avoiding unfair bias in AI systems, including the use of input data and algorithm design. They recommend establishing processes to test and monitor for potential biases during the development, deployment, and use phase of the system.\n",
      "\n",
      "6. Accessibility and universal design: The guidelines recommend ensuring that AI systems accommodate diverse needs and abilities from the start, and using the simplest and most interpretable model possible for the application in question.\n",
      "\n",
      "7. Communication: The guidelines recommend communicating clearly and intelligibly to the intended audience, including potential or perceived risks, such as bias, and specifying usage scenarios for the product or service.\n",
      "\n",
      "These principles are established to ensure that AI systems are developed and deployed in a way that respects human rights, promotes fairness and transparency, and benefits society as a whole.\n",
      "\n",
      "References:\n",
      "[Doc: ai_hleg_ethics_guidelines.pdf, page: 32] \n",
      "\n",
      "=== Chunks usados ===\n",
      "- Doc: ai_hleg_ethics_guidelines.pdf | Page: [] | Title: []\n",
      "  Text: Fundamental rights: Did you carry out a fundamental rights impact assessment where there could be a negative impact on fundamental rights? Did you identify and document potential trade-offs made betwe...\n",
      "\n",
      "- Doc: ai_hleg_ethics_guidelines.pdf | Page: [32] | Title: ['6. Societal and environmental well-being']\n",
      "  Text: a set of procedures to avoid creating or reinforcing unfair bias in the AI system, both regarding the use of input data as well as for the algorithm design? Did you assess and acknowledge the possible...\n",
      "\n",
      "- Doc: ai_hleg_ethics_guidelines.pdf | Page: [] | Title: []\n",
      "  Text: in mind from the start? Did you research and try to use the simplest and most interpretable model possible for the application in question? Did you assess whether you can analyse your training and tes...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def display_result(query, response, chunks):\n",
    "    print(\"=== Query ===\")\n",
    "    print(query, \"\\n\")\n",
    "\n",
    "    print(\"=== Answer ===\")\n",
    "    print(response, \"\\n\")\n",
    "\n",
    "    print(\"=== Chunks usados ===\")\n",
    "    for c in chunks:\n",
    "        meta = c[\"meta\"]\n",
    "        doc = meta.get(\"pdf\", \"N/A\")\n",
    "        pages = meta.get(\"pages\", [])\n",
    "        title = meta.get(\"titles\", [])\n",
    "        print(f\"- Doc: {doc} | Page: {pages} | Title: {title}\")\n",
    "        print(f\"  Text: {c['chunk'][:200]}...\\n\")  # solo los primeros 200 chars\n",
    "\n",
    "\n",
    "# Ejemplo de flujo completo\n",
    "test_query = \"What principles does UNESCO establish on AI ethics?\"\n",
    "chunks = hybrid_retrieval(test_query, alpha=0.3, top_k=3)\n",
    "prompt_example = build_prompt(test_query, chunks)\n",
    "response = generate_response(prompt_example)\n",
    "\n",
    "display_result(test_query, response, chunks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d643d4c",
   "metadata": {},
   "source": [
    "## 4. Evaluación de la generación\n",
    "\n",
    "### 4.1. Evaluación manual (exactitud, completitud, estilo)\n",
    "\n",
    "La evaluación manual se centra en comprobar si las respuestas generadas cumplen con los siguientes criterios:\n",
    "\n",
    "- **Exactitud:** la respuesta es correcta según el benchmark.\n",
    "- **Completitud:** cubre todos los aspectos de la pregunta y no se queda a medias.\n",
    "- **Estilo:** la respuesta es clara, concisa y comprensible.\n",
    "\n",
    "Se utilizará una tabla con columnas para la query, la respuesta esperada, la respuesta generada y los tres criterios evaluados.  \n",
    "Esto permite tener una revisión cualitativa directa de la calidad del sistema.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f74d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] What is the main advisory responsibility of the European Artificial Intelligence Board according to the regulation?\n",
      "Generated: According to the European Artificial Intelligence Board, the main advisory responsibility is to provide guidance on the ethical and human-centric deve ...\n",
      "\n",
      "[2] Which requirement is imposed on providers of high-risk AI systems regarding post-market activities?\n",
      "Generated: According to the EU AI Act Regulation, the requirement imposed on providers of high-risk AI systems regarding post-market activities is to establish a ...\n",
      "\n",
      "[3] How do the roles and interactions of national competent authorities, national supervisory authorities, and the European Artificial Intelligence Board contribute to the harmonised implementation and enforcement of the regulation across Member States?\n",
      "Generated: According to the European Artificial Intelligence Act Regulation, the roles and interactions of national competent authorities, national supervisory a ...\n",
      "\n",
      "[4] What are the three components that Trustworthy AI should meet throughout its entire life cycle according to the guidelines?\n",
      "Generated: According to the guidelines, Trustworthy AI should meet three components throughout its entire life cycle:\n",
      "\n",
      "1. It should be lawful, complying with all ...\n",
      "\n",
      "[5] Why does the document emphasize a holistic and systemic approach to achieving Trustworthy AI?\n",
      "Generated: The document emphasizes a holistic and systemic approach to achieving Trustworthy AI because trust in AI systems concerns not only the technology's in ...\n",
      "\n",
      "[6] Explain how the concept of Trustworthy AI in these guidelines draws parallels with public trust in other domains, and describe how this informs the approach recommended for AI systems.\n",
      "Generated: The concept of Trustworthy AI in these guidelines draws parallels with public trust in other domains, such as healthcare, finance, and transportation. ...\n",
      "\n",
      "[7] What are some example questions that help determine the transparency and explainability of an AI system according to the OECD framework?\n",
      "Generated: According to the OECD framework, some example questions that help determine the transparency and explainability of an AI system are:\n",
      "\n",
      "1. Is it clear w ...\n",
      "\n",
      "[8] According to the OECD framework, what aspects should policy makers consider to assess the safety, security, and robustness of AI systems?\n",
      "Generated: According to the OECD framework, policy makers should consider the following aspects to assess the safety, security, and robustness of AI systems:\n",
      "\n",
      "1. ...\n",
      "\n",
      "[9] Describe how the OECD framework recommends assessing both the explainability and safety of an AI system throughout its lifecycle, and discuss why these factors are important for responsible AI deployment.\n",
      "Generated: According to the OECD framework, the explainability and safety of an AI system should be assessed throughout its lifecycle. This is because explainabi ...\n",
      "\n",
      "[10] What are the three pillars of the European Commission's vision for artificial intelligence described in the introduction?\n",
      "Generated: According to the introduction, the three pillars of the European Commission's vision for artificial intelligence are:\n",
      "\n",
      "(i) increasing public and priva ...\n",
      "\n",
      "\n",
      "Resultados guardados en ../results/rag_generation_manual.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'query': 'What is the main advisory responsibility of the European Artificial Intelligence Board according to the regulation?',\n",
       "  'expected': 'The Board is responsible for issuing opinions, recommendations, advice, or guidance on matters related to the implementation of the regulation, including technical specifications or existing standards.',\n",
       "  'generated': 'According to the European Artificial Intelligence Board, the main advisory responsibility is to provide guidance on the ethical and human-centric development and deployment of artificial intelligence (AI) systems. This is stated in the document \"AI HLEG Ethics Guidelines\" (page 27), which recommends that stakeholders consider implementing a process that involves all levels of an organization, including top management, to ensure the trustworthy development and deployment of AI systems.',\n",
       "  'chunks': [{'pdf': 'eu_ai_act_regulation.pdf',\n",
       "    'pages': [2],\n",
       "    'titles': ['EXPLANATORY MEMORANDUM'],\n",
       "    'chunk_index': 1,\n",
       "    'n_words': 300},\n",
       "   {'pdf': 'oecd_legal_0449_en.pdf',\n",
       "    'pages': [],\n",
       "    'titles': [],\n",
       "    'chunk_index': 6,\n",
       "    'n_words': 300},\n",
       "   {'pdf': 'ai_hleg_ethics_guidelines.pdf',\n",
       "    'pages': [27],\n",
       "    'titles': ['HR'],\n",
       "    'chunk_index': 47,\n",
       "    'n_words': 300}],\n",
       "  'dificultad': 'easy'},\n",
       " {'query': 'Which requirement is imposed on providers of high-risk AI systems regarding post-market activities?',\n",
       "  'expected': 'All providers of high-risk AI systems must have a post-market monitoring system in place to enable corrective actions and improvements based on experience from use.',\n",
       "  'generated': 'According to the EU AI Act Regulation, the requirement imposed on providers of high-risk AI systems regarding post-market activities is to establish and document a post-market monitoring system (Article 61) and to report any serious incident or malfunctioning of those systems (Article 62).',\n",
       "  'chunks': [{'pdf': 'eu_ai_act_regulation.pdf',\n",
       "    'pages': [76],\n",
       "    'titles': ['2.'],\n",
       "    'chunk_index': 124,\n",
       "    'n_words': 300},\n",
       "   {'pdf': 'eu_ai_act_regulation.pdf',\n",
       "    'pages': [37],\n",
       "    'titles': ['2013/36/EU of the European Parliament and of the Council56, it is also appropriate to'],\n",
       "    'chunk_index': 66,\n",
       "    'n_words': 300},\n",
       "   {'pdf': 'eu_ai_act_regulation.pdf',\n",
       "    'pages': [],\n",
       "    'titles': [],\n",
       "    'chunk_index': 28,\n",
       "    'n_words': 300}],\n",
       "  'dificultad': 'medium'},\n",
       " {'query': 'How do the roles and interactions of national competent authorities, national supervisory authorities, and the European Artificial Intelligence Board contribute to the harmonised implementation and enforcement of the regulation across Member States?',\n",
       "  'expected': \"Member States must designate one or more national competent authorities to supervise the regulation's application and implementation, including a national supervisory authority as the official point of contact. The European Artificial Intelligence Board provides advice, guidance, and recommendations to support harmonised and effective implementation of the regulation across the Union.\",\n",
       "  'generated': 'According to the European Artificial Intelligence Act Regulation, the roles and interactions of national competent authorities, national supervisory authorities, and the European Artificial Intelligence Board contribute to the harmonized implementation and enforcement of the regulation across Member States in the following ways:\\n\\n* National competent authorities are designated by each Member State to ensure the application and implementation of the regulation (Article 59). They are organized to safeguard objectivity and impartiality and are provided with adequate financial and human resources (Article 60).\\n* National supervisory authorities are designated among the national competent authorities and act as notifying authorities and market surveillance authorities (Article 59). They report to the Commission on an annual basis on the status of their financial and human resources (Article 60).\\n* The European Artificial Intelligence Board is composed of representatives from the Member States and the Commission (Article 57). It facilitates a smooth, effective, and harmonized implementation of the regulation by contributing to the effective cooperation of the national supervisory authorities and the Commission, providing advice and expertise to the Commission, and collecting and sharing best practices among the Member States (Article 56).\\n* The Board provides advice and assistance to the Commission in the context of Article 56(2) and collects and shares expertise and best practices among Member States, contributes to uniform administrative practices in the Member States, and provides opinions, recommendations, or written contributions on matters related to the implementation of the regulation (Article 58).\\n\\nThese roles and interactions enable the harmonized implementation and enforcement of the regulation across Member States, ensuring a consistent application of the regulation and promoting a smooth, effective, and harmonized functioning of the regulatory sandboxes referred to in Article 53.',\n",
       "  'chunks': [{'pdf': 'eu_ai_act_regulation.pdf',\n",
       "    'pages': [],\n",
       "    'titles': [],\n",
       "    'chunk_index': 122,\n",
       "    'n_words': 300},\n",
       "   {'pdf': 'eu_ai_act_regulation.pdf',\n",
       "    'pages': [16],\n",
       "    'titles': ['5.2.5.'],\n",
       "    'chunk_index': 27,\n",
       "    'n_words': 300},\n",
       "   {'pdf': 'eu_ai_act_regulation.pdf',\n",
       "    'pages': [74],\n",
       "    'titles': ['CHAPTER 2'],\n",
       "    'chunk_index': 121,\n",
       "    'n_words': 300}],\n",
       "  'dificultad': 'hard'},\n",
       " {'query': 'What are the three components that Trustworthy AI should meet throughout its entire life cycle according to the guidelines?',\n",
       "  'expected': 'Trustworthy AI should be lawful (complying with laws and regulations), ethical (adhering to ethical principles and values), and robust (both technically and socially).',\n",
       "  'generated': 'According to the guidelines, Trustworthy AI should meet three components throughout its entire life cycle:\\n\\n1. It should be lawful, complying with all applicable laws and regulations.\\n2. It should be ethical, ensuring adherence to ethical principles and values.\\n3. It should be robust, both from a technical and social perspective.\\n\\nThese components are mentioned on page 7 of the document [Doc: ai_hleg_ethics_guidelines.pdf, page: 7].',\n",
       "  'chunks': [{'pdf': 'ai_hleg_ethics_guidelines.pdf',\n",
       "    'pages': [7],\n",
       "    'titles': ['1. it should be lawful, complying with all applicable laws and regulations;'],\n",
       "    'chunk_index': 7,\n",
       "    'n_words': 300},\n",
       "   {'pdf': 'ai_hleg_ethics_guidelines.pdf',\n",
       "    'pages': [],\n",
       "    'titles': [],\n",
       "    'chunk_index': 12,\n",
       "    'n_words': 300},\n",
       "   {'pdf': 'ai_hleg_ethics_guidelines.pdf',\n",
       "    'pages': [17],\n",
       "    'titles': ['1.1 Human agency and oversight'],\n",
       "    'chunk_index': 26,\n",
       "    'n_words': 300}],\n",
       "  'dificultad': 'easy'},\n",
       " {'query': 'Why does the document emphasize a holistic and systemic approach to achieving Trustworthy AI?',\n",
       "  'expected': \"Because trust in AI concerns not only the inherent properties of the technology but also the qualities of the socio-technical systems involving AI. Therefore, achieving Trustworthy AI requires considering the trustworthiness of all actors and processes in the system's socio-technical context throughout its entire life cycle.\",\n",
       "  'generated': 'The document emphasizes a holistic and systemic approach to achieving Trustworthy AI because trust in AI systems concerns not only the technology\\'s inherent properties but also the qualities of the socio-technical systems involving AI applications. The document states that \"it is not simply components of the AI system but the system in its overall context that may or may not engender trust\" (Doc: ai_hleg_ethics_guidelines.pdf, page: 7). Therefore, a holistic and systemic approach is necessary to ensure that all actors and processes involved in the AI system\\'s life cycle are trustworthy.\\n\\nThis approach is further emphasized by the document\\'s definition of Trustworthy AI, which has three components: it should be lawful, ethical, and robust. The document also highlights the importance of considering the entire life cycle of the AI system, from development to deployment and use, to ensure that the system remains trustworthy throughout its existence.\\n\\nThe document also provides examples of how a holistic and systemic approach can be achieved, such as the sense-plan-act cycle, which requires the integration of requirements at all three steps of the cycle. Additionally, the document mentions the importance of ethics and rule of law by design, which involves implementing values and norms into the design of the AI system from the very start.',\n",
       "  'chunks': [{'pdf': 'ai_hleg_ethics_guidelines.pdf',\n",
       "    'pages': [7],\n",
       "    'titles': ['1. it should be lawful, complying with all applicable laws and regulations;'],\n",
       "    'chunk_index': 7,\n",
       "    'n_words': 300},\n",
       "   {'pdf': 'ai_hleg_ethics_guidelines.pdf',\n",
       "    'pages': [],\n",
       "    'titles': [],\n",
       "    'chunk_index': 4,\n",
       "    'n_words': 300},\n",
       "   {'pdf': 'ai_hleg_ethics_guidelines.pdf',\n",
       "    'pages': [],\n",
       "    'titles': [],\n",
       "    'chunk_index': 40,\n",
       "    'n_words': 300}],\n",
       "  'dificultad': 'medium'},\n",
       " {'query': 'Explain how the concept of Trustworthy AI in these guidelines draws parallels with public trust in other domains, and describe how this informs the approach recommended for AI systems.',\n",
       "  'expected': \"The guidelines draw an analogy between trust in AI and trust in fields like aviation, nuclear power, or food safety, arguing that trust is not just about system components but the broader socio-technical context. This perspective informs the recommendation for a systemic, holistic approach to ensure trustworthiness in AI, covering all actors and processes throughout the AI system's life cycle.\",\n",
       "  'generated': 'The concept of Trustworthy AI in these guidelines draws parallels with public trust in other domains, such as healthcare, finance, and transportation. In these domains, trust is built through a combination of transparency, accountability, and robustness. Similarly, Trustworthy AI requires a harmonious balance of three components: ethical norms, existing law, and technical robustness. This approach is informed by the understanding that even with good intentions, AI systems can cause unintentional harm, and that it is the individual and collective responsibility of society to ensure that these components work together to secure Trustworthy AI.\\n\\nJust as public trust in other domains is built through transparency, accountability, and robustness, Trustworthy AI requires transparency in the design, development, and deployment of AI systems, accountability for the potential risks and consequences, and robustness in the technical implementation. This approach enables responsible competitiveness and provides the foundation for individuals to trust that AI systems are lawful, ethical, and robust.\\n\\nThe guidelines also recognize that global solutions are required for the global opportunities and challenges posed by AI systems, and encourage international cooperation to develop a global framework for Trustworthy AI. This is reflected in the OECD Recommendation on Artificial Intelligence, which emphasizes the importance of international cooperation and the sharing of AI knowledge to advance the principles of trustworthy AI.\\n\\nReferences:\\n\\n* Doc: ai_hleg_ethics_guidelines.pdf, page: [insert page number]\\n* Doc: eu_ai_act_regulation.pdf, page: [31]\\n* Doc: oecd_legal_0449_en.pdf, page: [insert page number]',\n",
       "  'chunks': [{'pdf': 'ai_hleg_ethics_guidelines.pdf',\n",
       "    'pages': [],\n",
       "    'titles': [],\n",
       "    'chunk_index': 8,\n",
       "    'n_words': 300},\n",
       "   {'pdf': 'eu_ai_act_regulation.pdf',\n",
       "    'pages': [31],\n",
       "    'titles': [],\n",
       "    'chunk_index': 55,\n",
       "    'n_words': 300},\n",
       "   {'pdf': 'oecd_legal_0449_en.pdf',\n",
       "    'pages': [],\n",
       "    'titles': [],\n",
       "    'chunk_index': 11,\n",
       "    'n_words': 261}],\n",
       "  'dificultad': 'hard'},\n",
       " {'query': 'What are some example questions that help determine the transparency and explainability of an AI system according to the OECD framework?',\n",
       "  'expected': 'Examples include: Is it clear what the objectives of the AI system are? Does the system provide meaningful information for understanding its outputs? Can all outputs be explained? Can the determinant data or knowledge used for decisions be identified? Can the consistency and integrity of outcomes be verified?',\n",
       "  'generated': \"According to the OECD framework, some example questions that help determine the transparency and explainability of an AI system are:\\n\\n1. Is it clear what the objectives of the AI system are, i.e. is it possible to formalise the problem that the system is being asked to solve? (Doc: oecd_ai_classification_framework.pdf, page: [26])\\n2. Does the AI system provide useful and meaningful information for understanding its performance and outputs/decisions? (Doc: oecd_ai_classification_framework.pdf, page: [26])\\n3. Can all of the AI system's outputs both intermediary and final for achieving a given goal be explained? (Doc: oecd_ai_classification_framework.pdf, page: [26])\\n4. Can the determinant data or knowledge that an AI system uses to make decisions be identified? (Doc: oecd_ai_classification_framework.pdf, page: [26])\\n5. Do two similar-looking cases verifiably result in similar outcomes, i.e. can the consistency and integrity of AI system outcomes be verified? (Doc: oecd_ai_classification_framework.pdf, page: [26])\\n\\nThese questions help determine the transparency and explainability of an AI system by assessing whether the system's objectives are clear, whether it provides useful information, and whether its outputs and decisions can be explained and verified.\",\n",
       "  'chunks': [{'pdf': 'oecd_ai_classification_framework.pdf',\n",
       "    'pages': [],\n",
       "    'titles': [],\n",
       "    'chunk_index': 41,\n",
       "    'n_words': 300},\n",
       "   {'pdf': 'oecd_ai_classification_framework.pdf',\n",
       "    'pages': [26],\n",
       "    'titles': ['26     OECD FRAMEWORK FOR THE CLASSIFICATION OF AI SYSTEMS'],\n",
       "    'chunk_index': 15,\n",
       "    'n_words': 300},\n",
       "   {'pdf': 'oecd_ai_classification_framework.pdf',\n",
       "    'pages': [43],\n",
       "    'titles': ['OECD FRAMEWORK FOR THE CLASSIFICATION OF AI SYSTEMS   43'],\n",
       "    'chunk_index': 40,\n",
       "    'n_words': 300}],\n",
       "  'dificultad': 'easy'},\n",
       " {'query': 'According to the OECD framework, what aspects should policy makers consider to assess the safety, security, and robustness of AI systems?',\n",
       "  'expected': 'Policy makers should consider if safety metrics exist for the use case, how safety is tested during development, what adversarial evaluation measures are in place, if the system is sensitive to data variations, and if there are processes to validate, verify, and trace AI system outcomes and decisions.',\n",
       "  'generated': \"According to the OECD framework, policy makers should consider the following aspects to assess the safety, security, and robustness of AI systems:\\n\\n1. Do safety metrics exist that can evaluate the safety of an AI system for a given use case? (Doc: oecd_ai_classification_framework.pdf, page: [ ])\\n2. How does the entity deploying the AI system test for safety during development? (Doc: oecd_ai_classification_framework.pdf, page: [ ])\\n3. What measures has the entity deploying the AI system taken to do an adversarial evaluation that is, explore the AI system through the lens of being a bad actor and trying to break it? (Doc: oecd_ai_classification_framework.pdf, page: [ ])\\n4. Does the AI system change significantly if it is trained with variations of the data available? (Doc: oecd_ai_classification_framework.pdf, page: [ ])\\n5. Are there measures in place to validate and verify the AI system's outcomes? (Doc: oecd_ai_classification_framework.pdf, page: [ ])\\n6. What measures are in place to facilitate traceability in the AI system, including in relation to datasets, processes and decisions made during the AI system's development? (Doc: oecd_ai_classification_framework.pdf, page: [ ])\\n7. Did you assess and acknowledge the possible limitations stemming from the composition of the used data sets? (Doc: ai_hleg_ethics_guidelines.pdf, page: [32])\\n8. Did you consider diversity and representativeness of users in the data? (Doc: ai_hleg_ethics_guidelines.pdf, page: [32])\\n9. Did you test for specific populations or problematic use cases? (Doc: ai_hleg_ethics_guidelines.pdf, page: [32])\\n10. Did you research and use available technical tools to improve your understanding of the data, model and performance? (Doc: ai_hleg_ethics_guidelines.pdf, page: [32])\\n11. Did you put in place processes to test and monitor for potential biases during the development, deployment and use phase of the system? (Doc: ai_hleg_ethics_guidelines.pdf, page: [32])\\n12. Did you ensure a mechanism that allows others to flag issues related to bias, discrimination or poor performance of the AI system? (Doc: ai_hleg_ethics_guidelines.pdf, page: [32])\\n13. Did you establish clear steps and ways of communicating on how and to whom such issues can be raised? (Doc: ai_hleg_ethics\",\n",
       "  'chunks': [{'pdf': 'oecd_ai_classification_framework.pdf',\n",
       "    'pages': [],\n",
       "    'titles': [],\n",
       "    'chunk_index': 41,\n",
       "    'n_words': 300},\n",
       "   {'pdf': 'ai_hleg_ethics_guidelines.pdf',\n",
       "    'pages': [32],\n",
       "    'titles': ['6. Societal and environmental well-being'],\n",
       "    'chunk_index': 56,\n",
       "    'n_words': 300},\n",
       "   {'pdf': 'ai_hleg_ethics_guidelines.pdf',\n",
       "    'pages': [29],\n",
       "    'titles': ['2. Technical robustness and safety'],\n",
       "    'chunk_index': 51,\n",
       "    'n_words': 300}],\n",
       "  'dificultad': 'medium'},\n",
       " {'query': 'Describe how the OECD framework recommends assessing both the explainability and safety of an AI system throughout its lifecycle, and discuss why these factors are important for responsible AI deployment.',\n",
       "  'expected': 'The OECD framework suggests assessing explainability through questions about system objectives, transparency of outputs, traceability, and consistency of outcomes, while safety assessment involves safety metrics, adversarial testing, sensitivity to data variations, and validation/verification measures. These factors are important to ensure that AI systems are understandable, trustworthy, safe, and robust throughout their lifecycle, supporting responsible AI deployment.',\n",
       "  'generated': \"According to the OECD framework, the explainability and safety of an AI system should be assessed throughout its lifecycle. This is because explainability and safety are crucial factors for responsible AI deployment.\\n\\nThe framework recommends assessing explainability by asking questions such as: Is it clear what the objectives of the AI system are? Does the AI system provide useful and meaningful information for understanding its performance and outputs/decisions? Can all of the AI system's outputs be explained? (Doc: oecd_ai_classification_framework.pdf, page: [21])\\n\\nThe framework also recommends assessing safety by asking questions such as: Do safety metrics exist that can evaluate the safety of an AI system for a given use case? How does the entity deploying the AI system test for safety during development? What measures has the entity deploying the AI system taken to do an adversarial evaluation? (Doc: oecd_ai_classification_framework.pdf, page: [21])\\n\\nThese factors are important for responsible AI deployment because they ensure that AI systems are transparent, accountable, and reliable. Explainability enables users to understand how AI systems make decisions and outputs, which is essential for building trust and ensuring fairness. Safety ensures that AI systems do not cause harm or unintended consequences, which is critical for protecting human rights and well-being.\\n\\nIn summary, the OECD framework emphasizes the importance of assessing explainability and safety throughout the AI system's lifecycle to ensure responsible AI deployment.\",\n",
       "  'chunks': [{'pdf': 'oecd_ai_classification_framework.pdf',\n",
       "    'pages': [],\n",
       "    'titles': [],\n",
       "    'chunk_index': 14,\n",
       "    'n_words': 300},\n",
       "   {'pdf': 'oecd_ai_classification_framework.pdf',\n",
       "    'pages': [],\n",
       "    'titles': [],\n",
       "    'chunk_index': 41,\n",
       "    'n_words': 300},\n",
       "   {'pdf': 'oecd_ai_classification_framework.pdf',\n",
       "    'pages': [21],\n",
       "    'titles': ['OECD FRAMEWORK FOR THE CLASSIFICATION OF AI SYSTEMS   21'],\n",
       "    'chunk_index': 8,\n",
       "    'n_words': 300}],\n",
       "  'dificultad': 'hard'},\n",
       " {'query': \"What are the three pillars of the European Commission's vision for artificial intelligence described in the introduction?\",\n",
       "  'expected': 'The three pillars are: (i) increasing public and private investments in AI, (ii) preparing for socio-economic changes, and (iii) ensuring an appropriate ethical and legal framework to strengthen European values.',\n",
       "  'generated': 'According to the introduction, the three pillars of the European Commission\\'s vision for artificial intelligence are:\\n\\n(i) increasing public and private investments in AI to boost its uptake,\\n(ii) preparing for socio-economic changes, and\\n(iii) ensuring an appropriate ethical and legal framework to strengthen European values.\\n\\nThese pillars are mentioned on page 6 of the document \"ai_hleg_ethics_guidelines.pdf\".',\n",
       "  'chunks': [{'pdf': 'ai_hleg_ethics_guidelines.pdf',\n",
       "    'pages': [6],\n",
       "    'titles': ['A. INTRODUCTION'],\n",
       "    'chunk_index': 5,\n",
       "    'n_words': 300},\n",
       "   {'pdf': 'eu_ai_act_regulation.pdf',\n",
       "    'pages': [19],\n",
       "    'titles': ['2020/2012(INL).'],\n",
       "    'chunk_index': 31,\n",
       "    'n_words': 300},\n",
       "   {'pdf': 'eu_ai_act_regulation.pdf',\n",
       "    'pages': [],\n",
       "    'titles': [],\n",
       "    'chunk_index': 9,\n",
       "    'n_words': 300}],\n",
       "  'dificultad': 'easy'}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "def evaluate_manual(qa_eval_set, output_file=\"../results/rag_generation_manual.csv\", max_queries=10):\n",
    "    results = []\n",
    "\n",
    "    for i, item in enumerate(qa_eval_set):\n",
    "        if max_queries and i >= max_queries:\n",
    "            break\n",
    "\n",
    "        query = item[\"pregunta\"]\n",
    "        expected = item[\"respuesta_esperada\"]\n",
    "\n",
    "        chunks = hybrid_retrieval(query, alpha=0.3, top_k=3)\n",
    "        prompt = build_prompt(query, chunks)\n",
    "        response = generate_response(prompt)\n",
    "\n",
    "        results.append({\n",
    "            \"query\": query,\n",
    "            \"expected\": expected,\n",
    "            \"generated\": response,\n",
    "            \"chunks\": [c[\"meta\"] for c in chunks],\n",
    "            \"dificultad\": item[\"dificultad\"]\n",
    "        })\n",
    "\n",
    "        print(f\"[{i+1}] {query}\")\n",
    "        print(\"Generated:\", response[:150], \"...\\n\")\n",
    "\n",
    "    # Guardar en CSV\n",
    "    with open(output_file, \"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
    "        fieldnames = [\"query\", \"expected\", \"generated\", \"chunks\", \"dificultad\", \"exactitud\", \"completitud\", \"estilo\"]\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for r in results:\n",
    "            writer.writerow({\n",
    "                \"query\": r[\"query\"],\n",
    "                \"expected\": r[\"expected\"],\n",
    "                \"generated\": r[\"generated\"],\n",
    "                \"chunks\": r[\"chunks\"],\n",
    "                \"dificultad\": r[\"dificultad\"],\n",
    "                \"exactitud\": \"\",\n",
    "                \"completitud\": \"\",\n",
    "                \"estilo\": \"\"\n",
    "            })\n",
    "\n",
    "    print(f\"\\nResultados guardados en {output_file}\")\n",
    "    return results\n",
    "\n",
    "\n",
    "\n",
    "# Test rápido\n",
    "evaluate_manual(qa_eval_set, max_queries=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2466102",
   "metadata": {},
   "source": [
    "### 4.2. Evaluación automática (BERTScore y opcionalmente métricas RAGAS simples)\n",
    "\n",
    "Para complementar la evaluación manual, se utilizan métricas automáticas que comparan las respuestas generadas con las respuestas esperadas del benchmark.\n",
    "\n",
    "- **BERTScore:** mide la similitud semántica entre la respuesta generada y la respuesta esperada, usando embeddings de un modelo pre-entrenado.  \n",
    "  A diferencia de BLEU o ROUGE, es más robusto frente a paráfrasis.\n",
    "\n",
    "- **RAGAS (opcional):** framework de métricas específicas para RAG, que evalúa aspectos como *faithfulness* y *answer relevance*.  \n",
    "  Solo se explorará si el coste computacional y de dependencias lo permite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "80ad13d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bert-score\n",
      "  Downloading bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: torch>=1.0.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from bert-score) (2.7.1)\n",
      "Requirement already satisfied: pandas>=1.0.1 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from bert-score) (2.3.1)\n",
      "Requirement already satisfied: transformers>=3.0.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from bert-score) (4.54.0)\n",
      "Requirement already satisfied: numpy in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from bert-score) (2.3.2)\n",
      "Requirement already satisfied: requests in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from bert-score) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.31.1 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from bert-score) (4.67.1)\n",
      "Requirement already satisfied: matplotlib in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from bert-score) (3.10.5)\n",
      "Requirement already satisfied: packaging>=20.9 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from bert-score) (25.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from pandas>=1.0.1->bert-score) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from pandas>=1.0.1->bert-score) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from pandas>=1.0.1->bert-score) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert-score) (1.17.0)\n",
      "Requirement already satisfied: filelock in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from torch>=1.0.0->bert-score) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from torch>=1.0.0->bert-score) (4.14.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from torch>=1.0.0->bert-score) (1.14.0)\n",
      "Requirement already satisfied: networkx in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from torch>=1.0.0->bert-score) (3.5)\n",
      "Requirement already satisfied: jinja2 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from torch>=1.0.0->bert-score) (3.1.6)\n",
      "Requirement already satisfied: fsspec in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from torch>=1.0.0->bert-score) (2025.7.0)\n",
      "Requirement already satisfied: setuptools in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from torch>=1.0.0->bert-score) (80.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from sympy>=1.13.3->torch>=1.0.0->bert-score) (1.3.0)\n",
      "Requirement already satisfied: colorama in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from tqdm>=4.31.1->bert-score) (0.4.6)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from transformers>=3.0.0->bert-score) (0.34.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from transformers>=3.0.0->bert-score) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from transformers>=3.0.0->bert-score) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from transformers>=3.0.0->bert-score) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from transformers>=3.0.0->bert-score) (0.5.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from jinja2->torch>=1.0.0->bert-score) (3.0.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from matplotlib->bert-score) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from matplotlib->bert-score) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from matplotlib->bert-score) (4.59.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from matplotlib->bert-score) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from matplotlib->bert-score) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from matplotlib->bert-score) (3.2.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from requests->bert-score) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from requests->bert-score) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from requests->bert-score) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from requests->bert-score) (2025.7.14)\n",
      "Downloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n",
      "Installing collected packages: bert-score\n",
      "Successfully installed bert-score-0.3.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install bert-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a50b5587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] What is the main advisory responsibility of the European Artificial Intelligence Board according to the regulation?\n",
      "Generated: According to the European Artificial Intelligence Board's advisory responsibility, the main advisory responsibility is to provide guidance on the deve ...\n",
      "\n",
      "[2] Which requirement is imposed on providers of high-risk AI systems regarding post-market activities?\n",
      "Generated: According to the EU AI Act Regulation, the requirement imposed on providers of high-risk AI systems regarding post-market activities is to establish a ...\n",
      "\n",
      "[3] How do the roles and interactions of national competent authorities, national supervisory authorities, and the European Artificial Intelligence Board contribute to the harmonised implementation and enforcement of the regulation across Member States?\n",
      "Generated: According to the EU AI Act Regulation, the roles and interactions of national competent authorities, national supervisory authorities, and the Europea ...\n",
      "\n",
      "[4] What are the three components that Trustworthy AI should meet throughout its entire life cycle according to the guidelines?\n",
      "Generated: According to the guidelines, Trustworthy AI should meet three components throughout its entire life cycle:\n",
      "\n",
      "1. It should be lawful, complying with all ...\n",
      "\n",
      "[5] Why does the document emphasize a holistic and systemic approach to achieving Trustworthy AI?\n",
      "Generated: The document emphasizes a holistic and systemic approach to achieving Trustworthy AI because trust in AI systems concerns not only the technology's in ...\n",
      "\n",
      "[6] Explain how the concept of Trustworthy AI in these guidelines draws parallels with public trust in other domains, and describe how this informs the approach recommended for AI systems.\n",
      "Generated: The concept of Trustworthy AI in these guidelines draws parallels with public trust in other domains, such as healthcare, finance, and transportation, ...\n",
      "\n",
      "[7] What are some example questions that help determine the transparency and explainability of an AI system according to the OECD framework?\n",
      "Generated: According to the OECD framework, some example questions that help determine the transparency and explainability of an AI system are:\n",
      "\n",
      "1. Is it clear w ...\n",
      "\n",
      "[8] According to the OECD framework, what aspects should policy makers consider to assess the safety, security, and robustness of AI systems?\n",
      "Generated: According to the OECD framework, policy makers should consider the following aspects to assess the safety, security, and robustness of AI systems:\n",
      "\n",
      "1. ...\n",
      "\n",
      "[9] Describe how the OECD framework recommends assessing both the explainability and safety of an AI system throughout its lifecycle, and discuss why these factors are important for responsible AI deployment.\n",
      "Generated: According to the OECD framework, assessing both the explainability and safety of an AI system throughout its lifecycle is crucial for responsible AI d ...\n",
      "\n",
      "[10] What are the three pillars of the European Commission's vision for artificial intelligence described in the introduction?\n",
      "Generated: According to the introduction, the three pillars of the European Commission's vision for artificial intelligence are:\n",
      "\n",
      "(i) increasing public and priva ...\n",
      "\n",
      "\n",
      "Resultados guardados en ../results/rag_generation_manual.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\TFM_RAG_NOR\\venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\aalex\\.cache\\huggingface\\hub\\models--distilbert-base-uncased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Error while downloading from https://huggingface.co/distilbert-base-uncased/resolve/main/model.safetensors: HTTPSConnectionPool(host='cas-bridge.xethub.hf.co', port=443): Read timed out.\n",
      "Trying to resume download...\n",
      "Error while downloading from https://huggingface.co/distilbert-base-uncased/resolve/main/model.safetensors: HTTPSConnectionPool(host='cas-bridge.xethub.hf.co', port=443): Read timed out.\n",
      "Trying to resume download...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:10<00:00, 10.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  4.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 11.22 seconds, 0.89 sentences/sec\n",
      "\n",
      "Resultados guardados en ../results/rag_generation_bertscore.csv\n",
      "What is the main advisory responsibility of the European Art ... | F1: 0.762\n",
      "Which requirement is imposed on providers of high-risk AI sy ... | F1: 0.815\n",
      "How do the roles and interactions of national competent auth ... | F1: 0.8\n",
      "What are the three components that Trustworthy AI should mee ... | F1: 0.82\n",
      "Why does the document emphasize a holistic and systemic appr ... | F1: 0.875\n",
      "Explain how the concept of Trustworthy AI in these guideline ... | F1: 0.788\n",
      "What are some example questions that help determine the tran ... | F1: 0.792\n",
      "According to the OECD framework, what aspects should policy  ... | F1: 0.727\n",
      "Describe how the OECD framework recommends assessing both th ... | F1: 0.808\n",
      "What are the three pillars of the European Commission's visi ... | F1: 0.899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from bert_score import score\n",
    "import csv\n",
    "\n",
    "def evaluate_bertscore(results, lang=\"en\", model_type=\"distilbert-base-uncased\", output_file=\"../results/rag_generation_bertscore.csv\"):\n",
    "    \"\"\"\n",
    "    Calcula BERTScore con un modelo más ligero y guarda los resultados en CSV.\n",
    "    \"\"\"\n",
    "    expected_answers = [r[\"expected\"] for r in results]\n",
    "    generated_answers = [r[\"generated\"] for r in results]\n",
    "\n",
    "    # Calcular BERTScore con modelo pequeño\n",
    "    P, R, F1 = score(generated_answers, expected_answers, lang=lang, model_type=model_type, verbose=True)\n",
    "\n",
    "    # Añadir a resultados\n",
    "    for i, r in enumerate(results):\n",
    "        r[\"bertscore_precision\"] = float(P[i])\n",
    "        r[\"bertscore_recall\"] = float(R[i])\n",
    "        r[\"bertscore_f1\"] = float(F1[i])\n",
    "\n",
    "    # Guardar en CSV\n",
    "    with open(output_file, \"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
    "        fieldnames = [\"query\", \"expected\", \"generated\", \"dificultad\", \"bertscore_precision\", \"bertscore_recall\", \"bertscore_f1\"]\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for r in results:\n",
    "            writer.writerow({\n",
    "                \"query\": r[\"query\"],\n",
    "                \"expected\": r[\"expected\"],\n",
    "                \"generated\": r[\"generated\"],\n",
    "                \"dificultad\": r[\"dificultad\"],\n",
    "                \"bertscore_precision\": r[\"bertscore_precision\"],\n",
    "                \"bertscore_recall\": r[\"bertscore_recall\"],\n",
    "                \"bertscore_f1\": r[\"bertscore_f1\"]\n",
    "            })\n",
    "\n",
    "    print(f\"\\nResultados guardados en {output_file}\")\n",
    "    return results\n",
    "\n",
    "# === Test breve con tus 10 resultados ===\n",
    "results = evaluate_manual(qa_eval_set, max_queries=10)\n",
    "results_with_scores = evaluate_bertscore(results, lang=\"en\")\n",
    "\n",
    "# Resumen en consola (solo query y F1)\n",
    "for r in results_with_scores:\n",
    "    print(r[\"query\"][:60], \"... | F1:\", round(r[\"bertscore_f1\"], 3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c7fffdff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERTScore F1 promedio: 0.809\n"
     ]
    }
   ],
   "source": [
    "f1_scores = [r[\"bertscore_f1\"] for r in results_with_scores]\n",
    "print(\"BERTScore F1 promedio:\", round(sum(f1_scores)/len(f1_scores), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "73863b15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Query ===\n",
      "What are the three pillars of the European Commission's vision on AI? \n",
      "\n",
      "=== Answer ===\n",
      "The three pillars of the European Commission's vision on AI are:\n",
      "\n",
      "1. Increasing public and private investments in AI to boost its uptake.\n",
      "2. Preparing for socio-economic changes.\n",
      "3. Ensuring an appropriate ethical and legal framework to strengthen European values.\n",
      "\n",
      "These pillars are mentioned in the document \"AI Hleg Ethics Guidelines.pdf\", page [6]. \n",
      "\n",
      "=== Chunks usados ===\n",
      "- Doc: ai_hleg_ethics_guidelines.pdf | Page: [] | Title: []\n",
      "  Text: are trustworthy. When drafting these Guidelines, Trustworthy AI has, therefore, been our foundational ambition. Trustworthy AI has three components: (1) it should be lawful, ensuring compliance with a...\n",
      "\n",
      "- Doc: eu_ai_act_regulation.pdf | Page: [] | Title: []\n",
      "  Text: examined in the White Paper on AI. Consistency and complementarity is therefore ensured with other ongoing or planned initiatives of the Commission that also aim to address those problems, including t...\n",
      "\n",
      "- Doc: ai_hleg_ethics_guidelines.pdf | Page: [6] | Title: ['A. INTRODUCTION']\n",
      "  Text: in December 2018 by the Commission and Member States. A. INTRODUCTION In its Communication of 25 April 2018 and 7 December 2018, the European Commission set out its vision for artificial intelligence ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_query = \"What are the three pillars of the European Commission's vision on AI?\"\n",
    "chunks = hybrid_retrieval(user_query, alpha=0.3, top_k=3)\n",
    "prompt = build_prompt(user_query, chunks)\n",
    "response = generate_response(prompt)\n",
    "\n",
    "display_result(user_query, response, chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e04be0",
   "metadata": {},
   "source": [
    "### 4.3. Evaluación automática con métricas RAGAS\n",
    "\n",
    "Además de BERTScore, se exploran métricas específicas para sistemas RAG utilizando la librería **RAGAS**.  \n",
    "\n",
    "- **Faithfulness**: mide si la respuesta está respaldada por el contexto proporcionado.  \n",
    "- **Answer relevance**: mide si la respuesta realmente responde a la pregunta.  \n",
    "- **Context recall**: mide si los chunks recuperados contienen la información necesaria.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e32f21f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ragas\n",
      "  Downloading ragas-0.3.2-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: numpy in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from ragas) (2.3.2)\n",
      "Collecting datasets (from ragas)\n",
      "  Downloading datasets-4.0.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting tiktoken (from ragas)\n",
      "  Downloading tiktoken-0.11.0-cp313-cp313-win_amd64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pydantic>=2.0.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from ragas) (2.11.7)\n",
      "Requirement already satisfied: nest-asyncio in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from ragas) (1.6.0)\n",
      "Collecting appdirs (from ragas)\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting diskcache>=5.6.3 (from ragas)\n",
      "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting langchain (from ragas)\n",
      "  Downloading langchain-0.3.27-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting langchain-core (from ragas)\n",
      "  Downloading langchain_core-0.3.75-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting langchain-community (from ragas)\n",
      "  Downloading langchain_community-0.3.28-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting langchain_openai (from ragas)\n",
      "  Downloading langchain_openai-0.3.32-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: typer in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from ragas) (0.16.0)\n",
      "Requirement already satisfied: rich in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from ragas) (14.1.0)\n",
      "Requirement already satisfied: openai>=1.0.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from ragas) (1.101.0)\n",
      "Requirement already satisfied: tqdm in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from ragas) (4.67.1)\n",
      "Collecting instructor (from ragas)\n",
      "  Downloading instructor-1.10.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting gitpython (from ragas)\n",
      "  Downloading gitpython-3.1.45-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: pillow>=10.4.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from ragas) (11.3.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from openai>=1.0.0->ragas) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from openai>=1.0.0->ragas) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from openai>=1.0.0->ragas) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from openai>=1.0.0->ragas) (0.10.0)\n",
      "Requirement already satisfied: sniffio in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from openai>=1.0.0->ragas) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from openai>=1.0.0->ragas) (4.14.1)\n",
      "Requirement already satisfied: idna>=2.8 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from anyio<5,>=3.5.0->openai>=1.0.0->ragas) (3.10)\n",
      "Requirement already satisfied: certifi in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai>=1.0.0->ragas) (2025.7.14)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai>=1.0.0->ragas) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.0.0->ragas) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from pydantic>=2.0.0->ragas) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from pydantic>=2.0.0->ragas) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from pydantic>=2.0.0->ragas) (0.4.1)\n",
      "Requirement already satisfied: colorama in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from tqdm->ragas) (0.4.6)\n",
      "Requirement already satisfied: filelock in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from datasets->ragas) (3.18.0)\n",
      "Collecting pyarrow>=15.0.0 (from datasets->ragas)\n",
      "  Downloading pyarrow-21.0.0-cp313-cp313-win_amd64.whl.metadata (3.4 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets->ragas)\n",
      "  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from datasets->ragas) (2.3.1)\n",
      "Requirement already satisfied: requests>=2.32.2 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from datasets->ragas) (2.32.4)\n",
      "Collecting xxhash (from datasets->ragas)\n",
      "  Using cached xxhash-3.5.0-cp313-cp313-win_amd64.whl.metadata (13 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets->ragas)\n",
      "  Using cached multiprocess-0.70.16-py312-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets->ragas)\n",
      "  Using cached fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from datasets->ragas) (0.34.1)\n",
      "Requirement already satisfied: packaging in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from datasets->ragas) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from datasets->ragas) (6.0.2)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets->ragas)\n",
      "  Downloading aiohttp-3.12.15-cp313-cp313-win_amd64.whl.metadata (7.9 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->ragas)\n",
      "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->ragas)\n",
      "  Using cached aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->ragas)\n",
      "  Using cached attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->ragas)\n",
      "  Using cached frozenlist-1.7.0-cp313-cp313-win_amd64.whl.metadata (19 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->ragas)\n",
      "  Downloading multidict-6.6.4-cp313-cp313-win_amd64.whl.metadata (5.4 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->ragas)\n",
      "  Using cached propcache-0.3.2-cp313-cp313-win_amd64.whl.metadata (12 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->ragas)\n",
      "  Using cached yarl-1.20.1-cp313-cp313-win_amd64.whl.metadata (76 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from requests>=2.32.2->datasets->ragas) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from requests>=2.32.2->datasets->ragas) (2.5.0)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython->ragas)\n",
      "  Downloading gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython->ragas)\n",
      "  Downloading smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting docstring-parser<1.0,>=0.16 (from instructor->ragas)\n",
      "  Downloading docstring_parser-0.17.0-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: jinja2<4.0.0,>=3.1.4 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from instructor->ragas) (3.1.6)\n",
      "Collecting tenacity<10.0.0,>=8.2.3 (from instructor->ragas)\n",
      "  Downloading tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from jinja2<4.0.0,>=3.1.4->instructor->ragas) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from rich->ragas) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from rich->ragas) (2.19.2)\n",
      "Requirement already satisfied: click>=8.0.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from typer->ragas) (8.2.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from typer->ragas) (1.5.4)\n",
      "Requirement already satisfied: mdurl~=0.1 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->ragas) (0.1.2)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.9 (from langchain->ragas)\n",
      "  Downloading langchain_text_splitters-0.3.9-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting langsmith>=0.1.17 (from langchain->ragas)\n",
      "  Downloading langsmith-0.4.18-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain->ragas)\n",
      "  Downloading sqlalchemy-2.0.43-cp313-cp313-win_amd64.whl.metadata (9.8 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core->ragas)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core->ragas)\n",
      "  Using cached jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting greenlet>=1 (from SQLAlchemy<3,>=1.4->langchain->ragas)\n",
      "  Downloading greenlet-3.2.4-cp313-cp313-win_amd64.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: orjson>=3.9.14 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from langsmith>=0.1.17->langchain->ragas) (3.11.1)\n",
      "Collecting requests-toolbelt>=1.0.0 (from langsmith>=0.1.17->langchain->ragas)\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting zstandard>=0.23.0 (from langsmith>=0.1.17->langchain->ragas)\n",
      "  Downloading zstandard-0.24.0-cp313-cp313-win_amd64.whl.metadata (3.2 kB)\n",
      "Collecting requests>=2.32.2 (from datasets->ragas)\n",
      "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting dataclasses-json<0.7,>=0.6.7 (from langchain-community->ragas)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.10.1 (from langchain-community->ragas)\n",
      "  Downloading pydantic_settings-2.10.1-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community->ragas)\n",
      "  Downloading httpx_sse-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.6.7->langchain-community->ragas)\n",
      "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.6.7->langchain-community->ragas)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.10.1->langchain-community->ragas)\n",
      "  Using cached python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.6.7->langchain-community->ragas)\n",
      "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: regex>=2022.1.18 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from tiktoken->ragas) (2024.11.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from pandas->datasets->ragas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from pandas->datasets->ragas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from pandas->datasets->ragas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets->ragas) (1.17.0)\n",
      "Downloading ragas-0.3.2-py3-none-any.whl (277 kB)\n",
      "Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
      "Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Downloading datasets-4.0.0-py3-none-any.whl (494 kB)\n",
      "Using cached dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Using cached fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
      "Using cached multiprocess-0.70.16-py312-none-any.whl (146 kB)\n",
      "Downloading aiohttp-3.12.15-cp313-cp313-win_amd64.whl (449 kB)\n",
      "Downloading multidict-6.6.4-cp313-cp313-win_amd64.whl (45 kB)\n",
      "Using cached yarl-1.20.1-cp313-cp313-win_amd64.whl (86 kB)\n",
      "Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Using cached aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Using cached attrs-25.3.0-py3-none-any.whl (63 kB)\n",
      "Using cached frozenlist-1.7.0-cp313-cp313-win_amd64.whl (43 kB)\n",
      "Using cached propcache-0.3.2-cp313-cp313-win_amd64.whl (40 kB)\n",
      "Downloading pyarrow-21.0.0-cp313-cp313-win_amd64.whl (26.1 MB)\n",
      "   ---------------------------------------- 0.0/26.1 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 1.8/26.1 MB 8.1 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 3.4/26.1 MB 7.9 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 4.5/26.1 MB 6.9 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 5.2/26.1 MB 6.7 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 6.3/26.1 MB 6.2 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 7.6/26.1 MB 6.0 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 8.7/26.1 MB 5.9 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 10.2/26.1 MB 6.1 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 11.3/26.1 MB 6.0 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 12.6/26.1 MB 6.3 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 13.6/26.1 MB 6.0 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 15.2/26.1 MB 6.0 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 16.8/26.1 MB 6.2 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 19.1/26.1 MB 6.6 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 21.2/26.1 MB 6.8 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 22.5/26.1 MB 6.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 25.2/26.1 MB 7.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.0/26.1 MB 7.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 26.1/26.1 MB 6.8 MB/s eta 0:00:00\n",
      "Downloading gitpython-3.1.45-py3-none-any.whl (208 kB)\n",
      "Downloading gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
      "Downloading smmap-5.0.2-py3-none-any.whl (24 kB)\n",
      "Downloading instructor-1.10.0-py3-none-any.whl (119 kB)\n",
      "Downloading docstring_parser-0.17.0-py3-none-any.whl (36 kB)\n",
      "Downloading tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Downloading langchain-0.3.27-py3-none-any.whl (1.0 MB)\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.0/1.0 MB 11.2 MB/s eta 0:00:00\n",
      "Downloading langchain_core-0.3.75-py3-none-any.whl (443 kB)\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading langchain_text_splitters-0.3.9-py3-none-any.whl (33 kB)\n",
      "Downloading sqlalchemy-2.0.43-cp313-cp313-win_amd64.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ----------------------------- ---------- 1.6/2.1 MB 6.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.1/2.1 MB 6.5 MB/s eta 0:00:00\n",
      "Downloading greenlet-3.2.4-cp313-cp313-win_amd64.whl (299 kB)\n",
      "Using cached jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading langsmith-0.4.18-py3-none-any.whl (376 kB)\n",
      "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Downloading zstandard-0.24.0-cp313-cp313-win_amd64.whl (505 kB)\n",
      "Downloading langchain_community-0.3.28-py3-none-any.whl (2.5 MB)\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   ------------------------ --------------- 1.6/2.5 MB 8.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.5/2.5 MB 7.6 MB/s eta 0:00:00\n",
      "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading httpx_sse-0.4.1-py3-none-any.whl (8.1 kB)\n",
      "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "Downloading pydantic_settings-2.10.1-py3-none-any.whl (45 kB)\n",
      "Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
      "Using cached python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
      "Downloading langchain_openai-0.3.32-py3-none-any.whl (74 kB)\n",
      "Downloading tiktoken-0.11.0-cp313-cp313-win_amd64.whl (883 kB)\n",
      "   ---------------------------------------- 0.0/883.9 kB ? eta -:--:--\n",
      "   --------------------------------------- 883.9/883.9 kB 10.1 MB/s eta 0:00:00\n",
      "Using cached xxhash-3.5.0-cp313-cp313-win_amd64.whl (30 kB)\n",
      "Installing collected packages: appdirs, zstandard, xxhash, tenacity, smmap, requests, python-dotenv, pyarrow, propcache, mypy-extensions, multidict, marshmallow, jsonpointer, httpx-sse, greenlet, fsspec, frozenlist, docstring-parser, diskcache, dill, attrs, aiohappyeyeballs, yarl, typing-inspect, tiktoken, SQLAlchemy, requests-toolbelt, multiprocess, jsonpatch, gitdb, aiosignal, pydantic-settings, langsmith, gitpython, dataclasses-json, aiohttp, langchain-core, instructor, langchain-text-splitters, langchain_openai, datasets, langchain, langchain-community, ragas\n",
      "\n",
      "   ----------------------------------------  0/44 [appdirs]\n",
      "    ---------------------------------------  1/44 [zstandard]\n",
      "   - --------------------------------------  2/44 [xxhash]\n",
      "   -- -------------------------------------  3/44 [tenacity]\n",
      "   -- -------------------------------------  3/44 [tenacity]\n",
      "   --- ------------------------------------  4/44 [smmap]\n",
      "   --- ------------------------------------  4/44 [smmap]\n",
      "   --- ------------------------------------  4/44 [smmap]\n",
      "  Attempting uninstall: requests\n",
      "   --- ------------------------------------  4/44 [smmap]\n",
      "    Found existing installation: requests 2.32.4\n",
      "   --- ------------------------------------  4/44 [smmap]\n",
      "   ---- -----------------------------------  5/44 [requests]\n",
      "    Uninstalling requests-2.32.4:\n",
      "   ---- -----------------------------------  5/44 [requests]\n",
      "      Successfully uninstalled requests-2.32.4\n",
      "   ---- -----------------------------------  5/44 [requests]\n",
      "   ---- -----------------------------------  5/44 [requests]\n",
      "   ---- -----------------------------------  5/44 [requests]\n",
      "   ---- -----------------------------------  5/44 [requests]\n",
      "   ---- -----------------------------------  5/44 [requests]\n",
      "   ---- -----------------------------------  5/44 [requests]\n",
      "   ----- ----------------------------------  6/44 [python-dotenv]\n",
      "   ----- ----------------------------------  6/44 [python-dotenv]\n",
      "   ------ ---------------------------------  7/44 [pyarrow]\n",
      "   ------ ---------------------------------  7/44 [pyarrow]\n",
      "   ------ ---------------------------------  7/44 [pyarrow]\n",
      "   ------ ---------------------------------  7/44 [pyarrow]\n",
      "   ------ ---------------------------------  7/44 [pyarrow]\n",
      "   ------ ---------------------------------  7/44 [pyarrow]\n",
      "   ------ ---------------------------------  7/44 [pyarrow]\n",
      "   ------ ---------------------------------  7/44 [pyarrow]\n",
      "   ------ ---------------------------------  7/44 [pyarrow]\n",
      "   ------ ---------------------------------  7/44 [pyarrow]\n",
      "   ------ ---------------------------------  7/44 [pyarrow]\n",
      "   ------ ---------------------------------  7/44 [pyarrow]\n",
      "   ------ ---------------------------------  7/44 [pyarrow]\n",
      "   ------ ---------------------------------  7/44 [pyarrow]\n",
      "   ------ ---------------------------------  7/44 [pyarrow]\n",
      "   ------ ---------------------------------  7/44 [pyarrow]\n",
      "   ------ ---------------------------------  7/44 [pyarrow]\n",
      "   ------ ---------------------------------  7/44 [pyarrow]\n",
      "   ------ ---------------------------------  7/44 [pyarrow]\n",
      "   ------ ---------------------------------  7/44 [pyarrow]\n",
      "   ------ ---------------------------------  7/44 [pyarrow]\n",
      "   ------ ---------------------------------  7/44 [pyarrow]\n",
      "   ------ ---------------------------------  7/44 [pyarrow]\n",
      "   ------ ---------------------------------  7/44 [pyarrow]\n",
      "   ------ ---------------------------------  7/44 [pyarrow]\n",
      "   ------ ---------------------------------  7/44 [pyarrow]\n",
      "   ------ ---------------------------------  7/44 [pyarrow]\n",
      "   ------ ---------------------------------  7/44 [pyarrow]\n",
      "   ------ ---------------------------------  7/44 [pyarrow]\n",
      "   ------ ---------------------------------  7/44 [pyarrow]\n",
      "   ------ ---------------------------------  7/44 [pyarrow]\n",
      "   ------ ---------------------------------  7/44 [pyarrow]\n",
      "   ------ ---------------------------------  7/44 [pyarrow]\n",
      "   ------ ---------------------------------  7/44 [pyarrow]\n",
      "   ------ ---------------------------------  7/44 [pyarrow]\n",
      "   ------ ---------------------------------  7/44 [pyarrow]\n",
      "   ------- --------------------------------  8/44 [propcache]\n",
      "   -------- -------------------------------  9/44 [mypy-extensions]\n",
      "   --------- ------------------------------ 10/44 [multidict]\n",
      "   --------- ------------------------------ 10/44 [multidict]\n",
      "   ---------- ----------------------------- 11/44 [marshmallow]\n",
      "   ---------- ----------------------------- 11/44 [marshmallow]\n",
      "   ---------- ----------------------------- 11/44 [marshmallow]\n",
      "   ---------- ----------------------------- 12/44 [jsonpointer]\n",
      "   ----------- ---------------------------- 13/44 [httpx-sse]\n",
      "   ------------ --------------------------- 14/44 [greenlet]\n",
      "   ------------ --------------------------- 14/44 [greenlet]\n",
      "   ------------ --------------------------- 14/44 [greenlet]\n",
      "   ------------ --------------------------- 14/44 [greenlet]\n",
      "   ------------ --------------------------- 14/44 [greenlet]\n",
      "  Attempting uninstall: fsspec\n",
      "   ------------ --------------------------- 14/44 [greenlet]\n",
      "    Found existing installation: fsspec 2025.7.0\n",
      "   ------------ --------------------------- 14/44 [greenlet]\n",
      "    Uninstalling fsspec-2025.7.0:\n",
      "   ------------ --------------------------- 14/44 [greenlet]\n",
      "   ------------- -------------------------- 15/44 [fsspec]\n",
      "      Successfully uninstalled fsspec-2025.7.0\n",
      "   ------------- -------------------------- 15/44 [fsspec]\n",
      "   ------------- -------------------------- 15/44 [fsspec]\n",
      "   ------------- -------------------------- 15/44 [fsspec]\n",
      "   ------------- -------------------------- 15/44 [fsspec]\n",
      "   ------------- -------------------------- 15/44 [fsspec]\n",
      "   ------------- -------------------------- 15/44 [fsspec]\n",
      "   ------------- -------------------------- 15/44 [fsspec]\n",
      "   ------------- -------------------------- 15/44 [fsspec]\n",
      "   ------------- -------------------------- 15/44 [fsspec]\n",
      "   ------------- -------------------------- 15/44 [fsspec]\n",
      "   ------------- -------------------------- 15/44 [fsspec]\n",
      "   ------------- -------------------------- 15/44 [fsspec]\n",
      "   -------------- ------------------------- 16/44 [frozenlist]\n",
      "   --------------- ------------------------ 17/44 [docstring-parser]\n",
      "   --------------- ------------------------ 17/44 [docstring-parser]\n",
      "   --------------- ------------------------ 17/44 [docstring-parser]\n",
      "   --------------- ------------------------ 17/44 [docstring-parser]\n",
      "   ---------------- ----------------------- 18/44 [diskcache]\n",
      "   ---------------- ----------------------- 18/44 [diskcache]\n",
      "   ----------------- ---------------------- 19/44 [dill]\n",
      "   ----------------- ---------------------- 19/44 [dill]\n",
      "   ----------------- ---------------------- 19/44 [dill]\n",
      "   ----------------- ---------------------- 19/44 [dill]\n",
      "   ----------------- ---------------------- 19/44 [dill]\n",
      "   ----------------- ---------------------- 19/44 [dill]\n",
      "   ----------------- ---------------------- 19/44 [dill]\n",
      "   ------------------ --------------------- 20/44 [attrs]\n",
      "   ------------------ --------------------- 20/44 [attrs]\n",
      "   ------------------ --------------------- 20/44 [attrs]\n",
      "   ------------------ --------------------- 20/44 [attrs]\n",
      "   ------------------- -------------------- 21/44 [aiohappyeyeballs]\n",
      "   -------------------- ------------------- 22/44 [yarl]\n",
      "   -------------------- ------------------- 22/44 [yarl]\n",
      "   -------------------- ------------------- 23/44 [typing-inspect]\n",
      "   --------------------- ------------------ 24/44 [tiktoken]\n",
      "   --------------------- ------------------ 24/44 [tiktoken]\n",
      "   ---------------------- ----------------- 25/44 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 25/44 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 25/44 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 25/44 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 25/44 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 25/44 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 25/44 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 25/44 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 25/44 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 25/44 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 25/44 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 25/44 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 25/44 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 25/44 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 25/44 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 25/44 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 25/44 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 25/44 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 25/44 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 25/44 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 25/44 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 25/44 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 25/44 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 25/44 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 25/44 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 25/44 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 25/44 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 25/44 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 25/44 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 25/44 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 25/44 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 25/44 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 25/44 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 25/44 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 25/44 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 25/44 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 25/44 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 25/44 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 25/44 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 25/44 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 25/44 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 25/44 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 25/44 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 25/44 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 25/44 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 25/44 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 25/44 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 25/44 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 25/44 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 25/44 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 25/44 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 25/44 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 25/44 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 25/44 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 25/44 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 25/44 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 25/44 [SQLAlchemy]\n",
      "   ---------------------- ----------------- 25/44 [SQLAlchemy]\n",
      "   ----------------------- ---------------- 26/44 [requests-toolbelt]\n",
      "   ----------------------- ---------------- 26/44 [requests-toolbelt]\n",
      "   ----------------------- ---------------- 26/44 [requests-toolbelt]\n",
      "   ----------------------- ---------------- 26/44 [requests-toolbelt]\n",
      "   ----------------------- ---------------- 26/44 [requests-toolbelt]\n",
      "   ------------------------ --------------- 27/44 [multiprocess]\n",
      "   ------------------------ --------------- 27/44 [multiprocess]\n",
      "   ------------------------ --------------- 27/44 [multiprocess]\n",
      "   ------------------------ --------------- 27/44 [multiprocess]\n",
      "   ------------------------ --------------- 27/44 [multiprocess]\n",
      "   ------------------------ --------------- 27/44 [multiprocess]\n",
      "   ------------------------ --------------- 27/44 [multiprocess]\n",
      "   ------------------------- -------------- 28/44 [jsonpatch]\n",
      "   -------------------------- ------------- 29/44 [gitdb]\n",
      "   -------------------------- ------------- 29/44 [gitdb]\n",
      "   -------------------------- ------------- 29/44 [gitdb]\n",
      "   -------------------------- ------------- 29/44 [gitdb]\n",
      "   -------------------------- ------------- 29/44 [gitdb]\n",
      "   --------------------------- ------------ 30/44 [aiosignal]\n",
      "   ---------------------------- ----------- 31/44 [pydantic-settings]\n",
      "   ---------------------------- ----------- 31/44 [pydantic-settings]\n",
      "   ---------------------------- ----------- 31/44 [pydantic-settings]\n",
      "   ---------------------------- ----------- 31/44 [pydantic-settings]\n",
      "   ----------------------------- ---------- 32/44 [langsmith]\n",
      "   ----------------------------- ---------- 32/44 [langsmith]\n",
      "   ----------------------------- ---------- 32/44 [langsmith]\n",
      "   ----------------------------- ---------- 32/44 [langsmith]\n",
      "   ----------------------------- ---------- 32/44 [langsmith]\n",
      "   ----------------------------- ---------- 32/44 [langsmith]\n",
      "   ----------------------------- ---------- 32/44 [langsmith]\n",
      "   ----------------------------- ---------- 32/44 [langsmith]\n",
      "   ----------------------------- ---------- 32/44 [langsmith]\n",
      "   ----------------------------- ---------- 32/44 [langsmith]\n",
      "   ----------------------------- ---------- 32/44 [langsmith]\n",
      "   ------------------------------ --------- 33/44 [gitpython]\n",
      "   ------------------------------ --------- 33/44 [gitpython]\n",
      "   ------------------------------ --------- 33/44 [gitpython]\n",
      "   ------------------------------ --------- 33/44 [gitpython]\n",
      "   ------------------------------ --------- 33/44 [gitpython]\n",
      "   ------------------------------ --------- 33/44 [gitpython]\n",
      "   ------------------------------ --------- 33/44 [gitpython]\n",
      "   ------------------------------ --------- 34/44 [dataclasses-json]\n",
      "   ------------------------------ --------- 34/44 [dataclasses-json]\n",
      "   ------------------------------- -------- 35/44 [aiohttp]\n",
      "   ------------------------------- -------- 35/44 [aiohttp]\n",
      "   ------------------------------- -------- 35/44 [aiohttp]\n",
      "   ------------------------------- -------- 35/44 [aiohttp]\n",
      "   ------------------------------- -------- 35/44 [aiohttp]\n",
      "   ------------------------------- -------- 35/44 [aiohttp]\n",
      "   ------------------------------- -------- 35/44 [aiohttp]\n",
      "   ------------------------------- -------- 35/44 [aiohttp]\n",
      "   ------------------------------- -------- 35/44 [aiohttp]\n",
      "   ------------------------------- -------- 35/44 [aiohttp]\n",
      "   ------------------------------- -------- 35/44 [aiohttp]\n",
      "   ------------------------------- -------- 35/44 [aiohttp]\n",
      "   ------------------------------- -------- 35/44 [aiohttp]\n",
      "   -------------------------------- ------- 36/44 [langchain-core]\n",
      "   -------------------------------- ------- 36/44 [langchain-core]\n",
      "   -------------------------------- ------- 36/44 [langchain-core]\n",
      "   -------------------------------- ------- 36/44 [langchain-core]\n",
      "   -------------------------------- ------- 36/44 [langchain-core]\n",
      "   -------------------------------- ------- 36/44 [langchain-core]\n",
      "   -------------------------------- ------- 36/44 [langchain-core]\n",
      "   -------------------------------- ------- 36/44 [langchain-core]\n",
      "   -------------------------------- ------- 36/44 [langchain-core]\n",
      "   -------------------------------- ------- 36/44 [langchain-core]\n",
      "   -------------------------------- ------- 36/44 [langchain-core]\n",
      "   -------------------------------- ------- 36/44 [langchain-core]\n",
      "   -------------------------------- ------- 36/44 [langchain-core]\n",
      "   -------------------------------- ------- 36/44 [langchain-core]\n",
      "   -------------------------------- ------- 36/44 [langchain-core]\n",
      "   -------------------------------- ------- 36/44 [langchain-core]\n",
      "   -------------------------------- ------- 36/44 [langchain-core]\n",
      "   -------------------------------- ------- 36/44 [langchain-core]\n",
      "   -------------------------------- ------- 36/44 [langchain-core]\n",
      "   -------------------------------- ------- 36/44 [langchain-core]\n",
      "   -------------------------------- ------- 36/44 [langchain-core]\n",
      "   -------------------------------- ------- 36/44 [langchain-core]\n",
      "   -------------------------------- ------- 36/44 [langchain-core]\n",
      "   -------------------------------- ------- 36/44 [langchain-core]\n",
      "   -------------------------------- ------- 36/44 [langchain-core]\n",
      "   -------------------------------- ------- 36/44 [langchain-core]\n",
      "   -------------------------------- ------- 36/44 [langchain-core]\n",
      "   -------------------------------- ------- 36/44 [langchain-core]\n",
      "   -------------------------------- ------- 36/44 [langchain-core]\n",
      "   -------------------------------- ------- 36/44 [langchain-core]\n",
      "   -------------------------------- ------- 36/44 [langchain-core]\n",
      "   --------------------------------- ------ 37/44 [instructor]\n",
      "   --------------------------------- ------ 37/44 [instructor]\n",
      "   --------------------------------- ------ 37/44 [instructor]\n",
      "   --------------------------------- ------ 37/44 [instructor]\n",
      "   --------------------------------- ------ 37/44 [instructor]\n",
      "   --------------------------------- ------ 37/44 [instructor]\n",
      "   --------------------------------- ------ 37/44 [instructor]\n",
      "   --------------------------------- ------ 37/44 [instructor]\n",
      "   --------------------------------- ------ 37/44 [instructor]\n",
      "   --------------------------------- ------ 37/44 [instructor]\n",
      "   --------------------------------- ------ 37/44 [instructor]\n",
      "   ---------------------------------- ----- 38/44 [langchain-text-splitters]\n",
      "   ---------------------------------- ----- 38/44 [langchain-text-splitters]\n",
      "   ---------------------------------- ----- 38/44 [langchain-text-splitters]\n",
      "   ----------------------------------- ---- 39/44 [langchain_openai]\n",
      "   ----------------------------------- ---- 39/44 [langchain_openai]\n",
      "   ----------------------------------- ---- 39/44 [langchain_openai]\n",
      "   ------------------------------------ --- 40/44 [datasets]\n",
      "   ------------------------------------ --- 40/44 [datasets]\n",
      "   ------------------------------------ --- 40/44 [datasets]\n",
      "   ------------------------------------ --- 40/44 [datasets]\n",
      "   ------------------------------------ --- 40/44 [datasets]\n",
      "   ------------------------------------ --- 40/44 [datasets]\n",
      "   ------------------------------------ --- 40/44 [datasets]\n",
      "   ------------------------------------ --- 40/44 [datasets]\n",
      "   ------------------------------------ --- 40/44 [datasets]\n",
      "   ------------------------------------ --- 40/44 [datasets]\n",
      "   ------------------------------------ --- 40/44 [datasets]\n",
      "   ------------------------------------ --- 40/44 [datasets]\n",
      "   ------------------------------------ --- 40/44 [datasets]\n",
      "   ------------------------------------ --- 40/44 [datasets]\n",
      "   ------------------------------------ --- 40/44 [datasets]\n",
      "   ------------------------------------ --- 40/44 [datasets]\n",
      "   ------------------------------------ --- 40/44 [datasets]\n",
      "   ------------------------------------ --- 40/44 [datasets]\n",
      "   ------------------------------------ --- 40/44 [datasets]\n",
      "   ------------------------------------ --- 40/44 [datasets]\n",
      "   ------------------------------------ --- 40/44 [datasets]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   ------------------------------------- -- 41/44 [langchain]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   -------------------------------------- - 42/44 [langchain-community]\n",
      "   ---------------------------------------  43/44 [ragas]\n",
      "   ---------------------------------------  43/44 [ragas]\n",
      "   ---------------------------------------  43/44 [ragas]\n",
      "   ---------------------------------------  43/44 [ragas]\n",
      "   ---------------------------------------  43/44 [ragas]\n",
      "   ---------------------------------------  43/44 [ragas]\n",
      "   ---------------------------------------  43/44 [ragas]\n",
      "   ---------------------------------------  43/44 [ragas]\n",
      "   ---------------------------------------  43/44 [ragas]\n",
      "   ---------------------------------------  43/44 [ragas]\n",
      "   ---------------------------------------  43/44 [ragas]\n",
      "   ---------------------------------------  43/44 [ragas]\n",
      "   ---------------------------------------  43/44 [ragas]\n",
      "   ---------------------------------------  43/44 [ragas]\n",
      "   ---------------------------------------  43/44 [ragas]\n",
      "   ---------------------------------------  43/44 [ragas]\n",
      "   ---------------------------------------  43/44 [ragas]\n",
      "   ---------------------------------------  43/44 [ragas]\n",
      "   ---------------------------------------  43/44 [ragas]\n",
      "   ---------------------------------------  43/44 [ragas]\n",
      "   ---------------------------------------  43/44 [ragas]\n",
      "   ---------------------------------------  43/44 [ragas]\n",
      "   ---------------------------------------  43/44 [ragas]\n",
      "   ---------------------------------------- 44/44 [ragas]\n",
      "\n",
      "Successfully installed SQLAlchemy-2.0.43 aiohappyeyeballs-2.6.1 aiohttp-3.12.15 aiosignal-1.4.0 appdirs-1.4.4 attrs-25.3.0 dataclasses-json-0.6.7 datasets-4.0.0 dill-0.3.8 diskcache-5.6.3 docstring-parser-0.17.0 frozenlist-1.7.0 fsspec-2025.3.0 gitdb-4.0.12 gitpython-3.1.45 greenlet-3.2.4 httpx-sse-0.4.1 instructor-1.10.0 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.3.27 langchain-community-0.3.28 langchain-core-0.3.75 langchain-text-splitters-0.3.9 langchain_openai-0.3.32 langsmith-0.4.18 marshmallow-3.26.1 multidict-6.6.4 multiprocess-0.70.16 mypy-extensions-1.1.0 propcache-0.3.2 pyarrow-21.0.0 pydantic-settings-2.10.1 python-dotenv-1.1.1 ragas-0.3.2 requests-2.32.5 requests-toolbelt-1.0.0 smmap-5.0.2 tenacity-9.1.2 tiktoken-0.11.0 typing-inspect-0.9.0 xxhash-3.5.0 yarl-1.20.1 zstandard-0.24.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install ragas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "72a256b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ragas in d:\\tfm_rag_nor\\venv\\lib\\site-packages (0.3.2)\n",
      "Requirement already satisfied: langchain_openai in d:\\tfm_rag_nor\\venv\\lib\\site-packages (0.3.32)\n",
      "Requirement already satisfied: numpy in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from ragas) (2.3.2)\n",
      "Requirement already satisfied: datasets in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from ragas) (4.0.0)\n",
      "Requirement already satisfied: tiktoken in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from ragas) (0.11.0)\n",
      "Requirement already satisfied: pydantic>=2.0.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from ragas) (2.11.7)\n",
      "Requirement already satisfied: nest-asyncio in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from ragas) (1.6.0)\n",
      "Requirement already satisfied: appdirs in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from ragas) (1.4.4)\n",
      "Requirement already satisfied: diskcache>=5.6.3 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from ragas) (5.6.3)\n",
      "Requirement already satisfied: langchain in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from ragas) (0.3.27)\n",
      "Requirement already satisfied: langchain-core in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from ragas) (0.3.75)\n",
      "Requirement already satisfied: langchain-community in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from ragas) (0.3.28)\n",
      "Requirement already satisfied: typer in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from ragas) (0.16.0)\n",
      "Requirement already satisfied: rich in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from ragas) (14.1.0)\n",
      "Requirement already satisfied: openai>=1.0.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from ragas) (1.101.0)\n",
      "Requirement already satisfied: tqdm in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from ragas) (4.67.1)\n",
      "Requirement already satisfied: instructor in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from ragas) (1.10.0)\n",
      "Requirement already satisfied: gitpython in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from ragas) (3.1.45)\n",
      "Requirement already satisfied: pillow>=10.4.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from ragas) (11.3.0)\n",
      "Requirement already satisfied: langsmith>=0.3.45 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from langchain-core->ragas) (0.4.18)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from langchain-core->ragas) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from langchain-core->ragas) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from langchain-core->ragas) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from langchain-core->ragas) (4.14.1)\n",
      "Requirement already satisfied: packaging>=23.2 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from langchain-core->ragas) (25.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core->ragas) (3.0.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from openai>=1.0.0->ragas) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from openai>=1.0.0->ragas) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from openai>=1.0.0->ragas) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from openai>=1.0.0->ragas) (0.10.0)\n",
      "Requirement already satisfied: sniffio in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from openai>=1.0.0->ragas) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from anyio<5,>=3.5.0->openai>=1.0.0->ragas) (3.10)\n",
      "Requirement already satisfied: certifi in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai>=1.0.0->ragas) (2025.7.14)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai>=1.0.0->ragas) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.0.0->ragas) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from pydantic>=2.0.0->ragas) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from pydantic>=2.0.0->ragas) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from pydantic>=2.0.0->ragas) (0.4.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from tiktoken->ragas) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from tiktoken->ragas) (2.32.5)\n",
      "Requirement already satisfied: orjson>=3.9.14 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from langsmith>=0.3.45->langchain-core->ragas) (3.11.1)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from langsmith>=0.3.45->langchain-core->ragas) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from langsmith>=0.3.45->langchain-core->ragas) (0.24.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from requests>=2.26.0->tiktoken->ragas) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from requests>=2.26.0->tiktoken->ragas) (2.5.0)\n",
      "Requirement already satisfied: colorama in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from tqdm->ragas) (0.4.6)\n",
      "Requirement already satisfied: filelock in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from datasets->ragas) (3.18.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from datasets->ragas) (21.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from datasets->ragas) (0.3.8)\n",
      "Requirement already satisfied: pandas in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from datasets->ragas) (2.3.1)\n",
      "Requirement already satisfied: xxhash in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from datasets->ragas) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from datasets->ragas) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets->ragas) (2025.3.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from datasets->ragas) (0.34.1)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets->ragas) (3.12.15)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->ragas) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->ragas) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->ragas) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->ragas) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->ragas) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->ragas) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->ragas) (1.20.1)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from gitpython->ragas) (4.0.12)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython->ragas) (5.0.2)\n",
      "Requirement already satisfied: docstring-parser<1.0,>=0.16 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from instructor->ragas) (0.17.0)\n",
      "Requirement already satisfied: jinja2<4.0.0,>=3.1.4 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from instructor->ragas) (3.1.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from jinja2<4.0.0,>=3.1.4->instructor->ragas) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from rich->ragas) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from rich->ragas) (2.19.2)\n",
      "Requirement already satisfied: click>=8.0.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from typer->ragas) (8.2.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from typer->ragas) (1.5.4)\n",
      "Requirement already satisfied: mdurl~=0.1 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->ragas) (0.1.2)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from langchain->ragas) (0.3.9)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from langchain->ragas) (2.0.43)\n",
      "Requirement already satisfied: greenlet>=1 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain->ragas) (3.2.4)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.6.7 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from langchain-community->ragas) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from langchain-community->ragas) (2.10.1)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from langchain-community->ragas) (0.4.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from dataclasses-json<0.7,>=0.6.7->langchain-community->ragas) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from dataclasses-json<0.7,>=0.6.7->langchain-community->ragas) (0.9.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community->ragas) (1.1.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.6.7->langchain-community->ragas) (1.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from pandas->datasets->ragas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from pandas->datasets->ragas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from pandas->datasets->ragas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in d:\\tfm_rag_nor\\venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets->ragas) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install ragas langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f526014c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aalex\\AppData\\Local\\Temp\\ipykernel_7444\\2731550102.py:40: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
      "Evaluating:   0%|          | 0/30 [00:00<?, ?it/s]Exception raised in Job[15]: NotFoundError(Error code: 404 - {'error': {'message': 'The model `llama-3-8b-instruct` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'code': 'model_not_found'}})\n",
      "Evaluating:   3%|▎         | 1/30 [00:01<00:39,  1.37s/it]Exception raised in Job[9]: NotFoundError(Error code: 404 - {'error': {'message': 'The model `llama-3-8b-instruct` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'code': 'model_not_found'}})\n",
      "Exception raised in Job[10]: NotFoundError(Error code: 404 - {'error': {'message': 'The model `llama-3-8b-instruct` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'code': 'model_not_found'}})\n",
      "Exception raised in Job[11]: NotFoundError(Error code: 404 - {'error': {'message': 'The model `llama-3-8b-instruct` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'code': 'model_not_found'}})\n",
      "Exception raised in Job[6]: NotFoundError(Error code: 404 - {'error': {'message': 'The model `llama-3-8b-instruct` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'code': 'model_not_found'}})\n",
      "Exception raised in Job[0]: NotFoundError(Error code: 404 - {'error': {'message': 'The model `llama-3-8b-instruct` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'code': 'model_not_found'}})\n",
      "Exception raised in Job[14]: NotFoundError(Error code: 404 - {'error': {'message': 'The model `llama-3-8b-instruct` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'code': 'model_not_found'}})\n",
      "Exception raised in Job[5]: NotFoundError(Error code: 404 - {'error': {'message': 'The model `llama-3-8b-instruct` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'code': 'model_not_found'}})\n",
      "Evaluating:   7%|▋         | 2/30 [00:01<00:19,  1.46it/s]Exception raised in Job[1]: NotFoundError(Error code: 404 - {'error': {'message': 'The model `llama-3-8b-instruct` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'code': 'model_not_found'}})\n",
      "Exception raised in Job[7]: NotFoundError(Error code: 404 - {'error': {'message': 'The model `llama-3-8b-instruct` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'code': 'model_not_found'}})\n",
      "Exception raised in Job[4]: NotFoundError(Error code: 404 - {'error': {'message': 'The model `llama-3-8b-instruct` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'code': 'model_not_found'}})\n",
      "Exception raised in Job[13]: NotFoundError(Error code: 404 - {'error': {'message': 'The model `llama-3-8b-instruct` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'code': 'model_not_found'}})\n",
      "Exception raised in Job[2]: NotFoundError(Error code: 404 - {'error': {'message': 'The model `llama-3-8b-instruct` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'code': 'model_not_found'}})\n",
      "Exception raised in Job[8]: NotFoundError(Error code: 404 - {'error': {'message': 'The model `llama-3-8b-instruct` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'code': 'model_not_found'}})\n",
      "Exception raised in Job[12]: NotFoundError(Error code: 404 - {'error': {'message': 'The model `llama-3-8b-instruct` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'code': 'model_not_found'}})\n",
      "Exception raised in Job[3]: NotFoundError(Error code: 404 - {'error': {'message': 'The model `llama-3-8b-instruct` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'code': 'model_not_found'}})\n",
      "Evaluating:  43%|████▎     | 13/30 [00:01<00:01, 13.04it/s]Exception raised in Job[16]: NotFoundError(Error code: 404 - {'error': {'message': 'The model `llama-3-8b-instruct` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'code': 'model_not_found'}})\n",
      "Exception raised in Job[17]: NotFoundError(Error code: 404 - {'error': {'message': 'The model `llama-3-8b-instruct` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'code': 'model_not_found'}})\n",
      "Evaluating:  60%|██████    | 18/30 [00:01<00:00, 14.96it/s]Exception raised in Job[23]: NotFoundError(Error code: 404 - {'error': {'message': 'The model `llama-3-8b-instruct` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'code': 'model_not_found'}})\n",
      "Exception raised in Job[27]: NotFoundError(Error code: 404 - {'error': {'message': 'The model `llama-3-8b-instruct` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'code': 'model_not_found'}})\n",
      "Exception raised in Job[25]: NotFoundError(Error code: 404 - {'error': {'message': 'The model `llama-3-8b-instruct` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'code': 'model_not_found'}})\n",
      "Exception raised in Job[18]: NotFoundError(Error code: 404 - {'error': {'message': 'The model `llama-3-8b-instruct` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'code': 'model_not_found'}})\n",
      "Exception raised in Job[22]: NotFoundError(Error code: 404 - {'error': {'message': 'The model `llama-3-8b-instruct` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'code': 'model_not_found'}})\n",
      "Evaluating:  73%|███████▎  | 22/30 [00:02<00:00, 14.27it/s]Exception raised in Job[20]: NotFoundError(Error code: 404 - {'error': {'message': 'The model `llama-3-8b-instruct` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'code': 'model_not_found'}})\n",
      "Exception raised in Job[26]: NotFoundError(Error code: 404 - {'error': {'message': 'The model `llama-3-8b-instruct` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'code': 'model_not_found'}})\n",
      "Exception raised in Job[29]: NotFoundError(Error code: 404 - {'error': {'message': 'The model `llama-3-8b-instruct` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'code': 'model_not_found'}})\n",
      "Exception raised in Job[19]: NotFoundError(Error code: 404 - {'error': {'message': 'The model `llama-3-8b-instruct` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'code': 'model_not_found'}})\n",
      "Exception raised in Job[21]: NotFoundError(Error code: 404 - {'error': {'message': 'The model `llama-3-8b-instruct` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'code': 'model_not_found'}})\n",
      "Exception raised in Job[28]: NotFoundError(Error code: 404 - {'error': {'message': 'The model `llama-3-8b-instruct` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'code': 'model_not_found'}})\n",
      "Exception raised in Job[24]: NotFoundError(Error code: 404 - {'error': {'message': 'The model `llama-3-8b-instruct` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'code': 'model_not_found'}})\n",
      "Evaluating: 100%|██████████| 30/30 [00:02<00:00, 12.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados RAGAS: {'faithfulness': nan, 'answer_relevancy': nan, 'context_recall': nan}\n",
      "Resultados guardados en ../results/rag_generation_ragas.csv\n"
     ]
    }
   ],
   "source": [
    "from ragas.metrics import faithfulness, answer_relevancy, context_recall\n",
    "from ragas import evaluate\n",
    "from datasets import Dataset\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "import pandas as pd\n",
    "\n",
    "def prepare_ragas_dataset(results):\n",
    "    \"\"\"\n",
    "    Convierte los resultados del pipeline a un Dataset de HuggingFace\n",
    "    en el formato esperado por RAGAS.\n",
    "    \"\"\"\n",
    "    ragas_data = {\n",
    "        \"question\": [],\n",
    "        \"answer\": [],\n",
    "        \"contexts\": [],\n",
    "        \"ground_truth\": []\n",
    "    }\n",
    "\n",
    "    for r in results:\n",
    "        ragas_data[\"question\"].append(r[\"query\"])\n",
    "        ragas_data[\"answer\"].append(r[\"generated\"])\n",
    "        ragas_data[\"contexts\"].append([c if isinstance(c, str) else str(c) for c in r[\"chunks\"]])\n",
    "        ragas_data[\"ground_truth\"].append(r[\"expected\"])\n",
    "\n",
    "    return Dataset.from_dict(ragas_data)\n",
    "\n",
    "\n",
    "# Crear dataset con resultados\n",
    "ragas_dataset = prepare_ragas_dataset(results_with_scores)\n",
    "\n",
    "# Configurar Groq LLaMA-3 como LLM backend\n",
    "llm = ChatOpenAI(\n",
    "    model=\"llama-3-8b-instruct\",\n",
    "    api_key=\"GROQ_API_KEY\",\n",
    "    base_url=\"https://api.groq.com/openai/v1\"\n",
    ")\n",
    "\n",
    "# Configurar embeddings HuggingFace (MPNet)\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
    "\n",
    "# Evaluación con métricas RAGAS\n",
    "metrics = [faithfulness, answer_relevancy, context_recall]\n",
    "ragas_results = evaluate(ragas_dataset, metrics=metrics, llm=llm, embeddings=embeddings)\n",
    "\n",
    "print(\"Resultados RAGAS:\", ragas_results)\n",
    "\n",
    "df_ragas = pd.DataFrame([ragas_results])\n",
    "df_ragas.to_csv(\"../results/rag_generation_ragas.csv\", index=False)\n",
    "print(\"Resultados guardados en ../results/rag_generation_ragas.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d7429133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[np.float64(nan), np.float64(nan), np.float64(nan)]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "vals = [\n",
    "    round(np.mean(ragas_results[\"faithfulness\"]), 3),\n",
    "    round(np.mean(ragas_results[\"answer_relevancy\"]), 3),\n",
    "    round(np.mean(ragas_results[\"context_recall\"]), 3)\n",
    "]\n",
    "\n",
    "print(vals)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04dd16af",
   "metadata": {},
   "source": [
    "## 5. Demo tester\n",
    "\n",
    "En esta sección se incluye una demostración práctica del sistema RAG desarrollado.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "455c7513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Query ===\n",
      "What are the three pillars of the European Commission's vision on AI \n",
      "\n",
      "=== Answer ===\n",
      "According to the provided context, the three pillars of the European Commission's vision on AI are:\n",
      "\n",
      "1. Increasing public and private investments in AI to boost its uptake.\n",
      "2. Preparing for socio-economic changes.\n",
      "3. Ensuring an appropriate ethical and legal framework to strengthen European values.\n",
      "\n",
      "These pillars are mentioned in the document \"AI Hleg Ethics Guidelines.pdf\" on page [6]. \n",
      "\n",
      "=== Chunks usados ===\n",
      "- Doc: ai_hleg_ethics_guidelines.pdf | Page: [] | Title: []\n",
      "  Text: are trustworthy. When drafting these Guidelines, Trustworthy AI has, therefore, been our foundational ambition. Trustworthy AI has three components: (1) it should be lawful, ensuring compliance with a...\n",
      "\n",
      "- Doc: eu_ai_act_regulation.pdf | Page: [] | Title: []\n",
      "  Text: examined in the White Paper on AI. Consistency and complementarity is therefore ensured with other ongoing or planned initiatives of the Commission that also aim to address those problems, including t...\n",
      "\n",
      "- Doc: ai_hleg_ethics_guidelines.pdf | Page: [6] | Title: ['A. INTRODUCTION']\n",
      "  Text: in December 2018 by the Commission and Member States. A. INTRODUCTION In its Communication of 25 April 2018 and 7 December 2018, the European Commission set out its vision for artificial intelligence ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Demo interactiva en el notebook\n",
    "\n",
    "while True:\n",
    "    user_query = input(\"Escribe tu pregunta (o 'exit' para salir): \")\n",
    "    if user_query.lower() == \"exit\":\n",
    "        break\n",
    "    \n",
    "    chunks = hybrid_retrieval(user_query, alpha=0.3, top_k=3)\n",
    "    prompt = build_prompt(user_query, chunks)\n",
    "    response = generate_response(prompt)\n",
    "    \n",
    "    display_result(user_query, response, chunks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ada0fb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
