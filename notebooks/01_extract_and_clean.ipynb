{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b54b87d",
   "metadata": {},
   "source": [
    "## Índice\n",
    "\n",
    "1. [Introducción y objetivos](#1-introducción-y-objetivos)\n",
    "2. [Carga de datos y preparación](#2-carga-de-datos-y-preparación)\n",
    "3. [Extracción y limpieza de texto](#3-extracción-y-limpieza-de-texto)\n",
    "    - 3.1. Ejemplo de estructura del PDF\n",
    "    - 3.2. Detección y eliminación de ruido\n",
    "    - 3.3. Análisis de títulos y secciones\n",
    "4. [Generación de chunks](#4-generación-de-chunks)\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Introducción y objetivos\n",
    "\n",
    "En este notebook se va a extraer y limpiar texto de documentos normativos en PDF para montar un corpus usable en tareas de recuperación de información. El objetivo es dejar los datos listos para probar chunking y modelos de RAG sobre casos reales, no solo datasets de ejemplo.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Carga de datos y preparación\n",
    "\n",
    "Se cargan los PDFs en bruto desde la carpeta del proyecto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4869c7d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ai_hleg_ethics_guidelines.pdf',\n",
       " 'eu_ai_act_regulation.pdf',\n",
       " 'nist_privacy_framework_v1.pdf',\n",
       " 'oecd_ai_classification_framework.pdf',\n",
       " 'oecd_legal_0449_en.pdf']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "pdf_dir = \"../data/raw_pdfs\"\n",
    "pdf_files = [f for f in os.listdir(pdf_dir) if f.lower().endswith(\".pdf\")]\n",
    "pdf_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24db1ac",
   "metadata": {},
   "source": [
    "## 3. Extracción y limpieza de texto\n",
    "\n",
    "Se empieza la extracción del texto de los PDFs para ver la estructura y el tipo de contenido que tiene cada uno. El objetivo aquí es detectar qué ruido hay (como encabezados, pies de página o tablas raras) y ver si los títulos y secciones se pueden distinguir bien.\n",
    "\n",
    "De manera manual, se han revisado por encima los PDFs y se quitan las sigiuentes páginas:\n",
    "\n",
    "| PDF                           | Páginas útiles       |\n",
    "|-------------------------------|---------------------|\n",
    "| oecd_legal_0449_en.pdf        | 3 a 9               | \n",
    "| eu_ai_act_regulation.pdf      | 2 a 95              | \n",
    "| oecd_ai_classification_framework.pdf | 16 a 67       |\n",
    "| ai_hleg_ethics_guidelines.pdf | 4 a 37              |\n",
    "| nist_privacy_framework_v1.pdf | 5 a 43              |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b35c915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- ai_hleg_ethics_guidelines.pdf (34 páginas útiles) ---\n",
      "\n",
      "--- Página real 4 (índice útil 1) ---\n",
      "2 \n",
      " \n",
      "EXECUTIVE SUMMARY \n",
      "The aim of the Guidelines is to promote Trustworthy AI. Trustworthy AI has three components, which should be \n",
      "met throughout the system's entire life cycle: (1) it should be lawful, complying with all applicable laws and \n",
      "regulations (2) it should be ethical, ensuring adherence to ethical principles and values and (3) it should be robust, \n",
      "both from a technical and social perspective since, even with good intentions, AI systems can cause unintentional \n",
      "harm. Each component in itself is necessary but not sufficient for the achievement of Trustworthy AI. Ideally, all \n",
      "three components work in harmony and overlap in their operation. If, in practice, tensions arise between these \n",
      "components, society should endeavour to align them.  \n",
      "These Guidelines set out a framework for achieving Trustworthy AI. The framework does not explicitly deal with \n",
      "Trustworthy AI’s first component (lawful AI).1 Instead, it aims to offer guidance on the second and third \n",
      "components: fostering and securing ethical and robust AI. Addressed to all stakeholders, these Guidelines seek to go \n",
      "beyond a list of ethical principles, by providing guidance on how such principles can be operationalised in socio-\n",
      "technical systems. Guidance is provided in three layers of abstraction, from the most abstract in Chapter I to the \n",
      "most concrete in Chapter III, closing with examples of opportunities and critical concerns raised by AI systems. \n",
      "I. \n",
      "Based on an approach founded on fundamental rights, Chapter I identifies the ethical principles and their \n",
      "correlated values that must be respected in the development, deployment and use of AI systems.  \n",
      "Key guidance derived from Chapter I: \n",
      " Develop, deploy and use AI systems in a way that adheres to the ethical principles of: respect for human \n",
      "autonomy, prevention of harm, fairness and explicability. Acknowledge and address the potential tensions \n",
      "between these principles.  \n",
      " Pay particular attention to situations involving more vulnerable groups such as children, persons with \n",
      "disabilities and others that have historically been disadvantaged or are at risk of exclusion, and to situations \n",
      "which are characterised by asymmetries of power or information, such as between employers and workers, \n",
      "or between businesses and consumers.2 \n",
      " Acknowledge that, while bringing substantial benefits to individuals and society, AI systems also pose \n",
      "certain risks and may have a negative impact, including impacts which may be difficult to anticipate, \n",
      "identify or measure (e.g. on democracy, the rule of law and distributive justice, or on the human mind \n",
      "itself.) Adopt adequate measures to mitigate these risks when appropriate, and proportionately to the \n",
      "magnitude of the risk. \n",
      "II. Drawing upon Chapter I, Chapter II provides guidance on how Trustworthy AI can be realised, by listing seven \n",
      "requirements that AI systems should meet. Both technical and non-technical methods can be used for their \n",
      "implementation.  \n",
      "Key guidance derived from Chapter II: \n",
      " Ensure that the development, deployment and use of AI systems meets the seven key requirements for \n",
      "Trustworthy AI: (1) human agency and oversight, (2) technical robustness and safety, (3) privacy and data \n",
      "governance, (4) transparency, (5) diversity, non-discrimination and fairness, (6) environmental and societal \n",
      "well-being and (7) accountability.  \n",
      " Consider technical and non-technical methods to ensure the implementation of those requirements.  \n",
      "                                                          \n",
      "1  \n",
      "All normative statements in this document aim to reflect guidance towards achieving the second and third component of \n",
      "trustworthy AI (ethical and robust AI). These statements are hence not meant to provide legal advice or to offer guidance on \n",
      "compliance with applicable laws, though it is acknowledged that many of these statements are to some extent already reflected \n",
      "in existing laws. In this regard, see §21 and following.  \n",
      "2  \n",
      "See articles 24 to 27 of the Charter of Fundamental Rights of the EU (EU Charter), dealing with the rights of the child and the \n",
      "elderly, the integration of persons with disabilities and workers’ rights. See also article 38 dealing with consumer protection.  \n",
      "\n",
      "\n",
      "--- Página real 6 (índice útil 3) ---\n",
      "4 \n",
      " \n",
      "A. INTRODUCTION \n",
      "In its Communication of 25 April 2018 and 7 December 2018, the European Commission set out its vision for \n",
      "artificial intelligence (AI), which supports “ethical, secure and cutting-edge AI made in Europe”.5 Three pillars \n",
      "underpin the Commission’s vision: (i) increasing public and private investments in AI to boost its uptake, (ii) \n",
      "preparing for socio-economic changes, and (iii) ensuring an appropriate ethical and legal framework to strengthen \n",
      "European values. \n",
      "To support the implementation of this vision, the Commission established the High-Level Expert Group on Artificial \n",
      "Intelligence (AI HLEG), an independent group mandated with the drafting of two deliverables: (1) AI Ethics \n",
      "Guidelines and (2) Policy and Investment Recommendations.  \n",
      "This document contains the AI Ethics Guidelines, which have been revised following further deliberation by our \n",
      "Group in light of feedback received from the public consultation on the draft published on 18 December 2018. It \n",
      "builds on the work of the European Group on Ethics in Science and New Technologies6 and takes inspiration from \n",
      "other similar efforts.7 \n",
      "Over the past months, the 52 of us met, discussed and interacted, committed to the European motto: united in \n",
      "diversity. We believe that AI has the potential to significantly transform society. AI is not an end in itself, but rather \n",
      "a promising means to increase human flourishing, thereby enhancing individual and societal well-being and the \n",
      "common good, as well as bringing progress and innovation. In particular, AI systems can help to facilitate the \n",
      "achievement of the UN’s Sustainable Development Goals, such as promoting gender balance and tackling climate \n",
      "change, rationalising our use of natural resources, enhancing our health, mobility and production processes, and \n",
      "supporting how we monitor progress against sustainability and social cohesion indicators. \n",
      "To do this, AI systems8 need to be human-centric, resting on a commitment to their use in the service of humanity \n",
      "and the common good, with the goal of improving human welfare and freedom. While offering great opportunities, \n",
      "AI systems also give rise to certain risks that must be handled appropriately and proportionately. We now have an \n",
      "important window of opportunity to shape their development. We want to ensure that we can trust the socio-\n",
      "technical environments in which they are embedded. We also want producers of AI systems to get a competitive \n",
      "advantage by embedding Trustworthy AI in their products and services. This entails seeking to maximise the \n",
      "benefits of AI systems while at the same time preventing and minimising their risks.   \n",
      "In a context of rapid technological change, we believe it is essential that trust remains the bedrock of societies, \n",
      "communities, economies and sustainable development. We therefore identify Trustworthy AI as our foundational \n",
      "ambition, since human beings and communities will only be able to have confidence in the technology’s \n",
      "development and its applications when a clear and comprehensive framework for achieving its trustworthiness is in \n",
      "place.  \n",
      "This is the path that we believe Europe should follow to become the home and leader of cutting-edge and ethical \n",
      "technology. It is through Trustworthy AI that we, as European citizens, will seek to reap its benefits in a way that is \n",
      "aligned with our foundational values of respect for human rights, democracy and the rule of law. \n",
      "Trustworthy AI \n",
      "Trustworthiness is a prerequisite for people and societies to develop, deploy and use AI systems. Without AI \n",
      "systems – and the human beings behind them – being demonstrably worthy of trust, unwanted consequences may \n",
      "ensue and their uptake might be hindered, preventing the realisation of the potentially vast social and economic \n",
      "                                                          \n",
      "5  \n",
      " COM(2018)237 and COM(2018)795. Note that the term “made in Europe” is used throughout the Commission’s communication. \n",
      "The scope of these Guidelines however aims to encompass not only those AI systems made in Europe, but also those developed \n",
      "elsewhere and deployed or used in Europe. Throughout this document, we hence aim to promote trustworthy AI “for” Europe.  \n",
      "6  \n",
      " The European Group on Ethics in Science and New Technologies (EGE) is an advisory group of the Commission. \n",
      "7  \n",
      " See Section 3.3 of COM(2018)237. \n",
      "8  \n",
      " The Glossary at the end of this document provides a definition of AI systems for the purpose of this document. This definition is \n",
      "further elaborated on in a dedicated document prepared by the AI HLEG that accompanies these Guidelines, titled \"A definition \n",
      "of AI: Main capabilities and scientific disciplines\". \n",
      "\n",
      "\n",
      "--- eu_ai_act_regulation.pdf (94 páginas útiles) ---\n",
      "\n",
      "--- Página real 2 (índice útil 1) ---\n",
      "EN \n",
      "1 \n",
      " EN \n",
      "EXPLANATORY MEMORANDUM \n",
      "1. \n",
      "CONTEXT OF THE PROPOSAL \n",
      "1.1. \n",
      "Reasons for and objectives of the proposal \n",
      "This explanatory memorandum accompanies the proposal for a Regulation laying down \n",
      "harmonised rules on artificial intelligence (Artificial Intelligence Act). Artificial Intelligence \n",
      "(AI) is a fast evolving family of technologies that can bring a wide array of economic and \n",
      "societal benefits across the entire spectrum of industries and social activities. By improving \n",
      "prediction, optimising operations and resource allocation, and personalising service delivery, \n",
      "the use of artificial intelligence can support socially and environmentally beneficial outcomes \n",
      "and provide key competitive advantages to companies and the European economy. Such \n",
      "action is especially needed in high-impact sectors, including climate change, environment and \n",
      "health, the public sector, finance, mobility, home affairs and agriculture. However, the same \n",
      "elements and techniques that power the socio-economic benefits of AI can also bring about \n",
      "new risks or negative consequences for individuals or the society. In light of the speed of \n",
      "technological change and possible challenges, the EU is committed to strive for a balanced \n",
      "approach. It is in the Union interest to preserve the EU’s technological leadership and to \n",
      "ensure that Europeans can benefit from new technologies developed and functioning \n",
      "according to Union values, fundamental rights and principles. \n",
      "This proposal delivers on the political commitment by President von der Leyen, who \n",
      "announced in her political guidelines for the 2019-2024 Commission “A Union that strives for \n",
      "more”1, that the Commission would put forward legislation for a coordinated European \n",
      "approach on the human and ethical implications of AI. Following on that announcement, on \n",
      "19 February 2020 the Commission published the White Paper on AI - A European approach \n",
      "to excellence and trust2. The White Paper sets out policy options on how to achieve the twin \n",
      "objective of promoting the uptake of AI and of addressing the risks associated with certain \n",
      "uses of such technology. This proposal aims to implement the second objective for the \n",
      "development of an ecosystem of trust by proposing a legal framework for trustworthy AI. The \n",
      "proposal is based on EU values and fundamental rights and aims to give people and other \n",
      "users the confidence to embrace AI-based solutions, while encouraging businesses to develop \n",
      "them. AI should be a tool for people and be a force for good in society with the ultimate aim \n",
      "of increasing human well-being. Rules for AI available in the Union market or otherwise \n",
      "affecting people in the Union should therefore be human centric, so that people can trust that \n",
      "the technology is used in a way that is safe and compliant with the law, including the respect \n",
      "of fundamental rights. Following the publication of the White Paper, the Commission \n",
      "launched a broad stakeholder consultation, which was met with a great interest by a large \n",
      "number of stakeholders who were largely supportive of regulatory intervention to address the \n",
      "challenges and concerns raised by the increasing use of AI.  \n",
      "The proposal also responds to explicit requests from the European Parliament (EP) and the \n",
      "European Council, which have repeatedly expressed calls for legislative action to ensure a \n",
      "well-functioning internal market for artificial intelligence systems (‘AI systems’) where both \n",
      "benefits and risks of AI are adequately addressed at Union level. It supports the objective of \n",
      "the Union being a global leader in the development of secure, trustworthy and ethical artificial \n",
      "                                                 \n",
      "1 \n",
      "https://ec.europa.eu/commission/sites/beta-political/files/political-guidelines-next-commission_en.pdf \n",
      "2 \n",
      "European Commission, White Paper on Artificial Intelligence - A European approach to excellence and \n",
      "trust, COM(2020) 65 final, 2020. \n",
      "\n",
      "\n",
      "--- Página real 4 (índice útil 3) ---\n",
      "EN \n",
      "3 \n",
      " EN \n",
      "proposal takes into account the aforementioned resolution of the European Parliament in full \n",
      "respect of proportionality, subsidiarity and better law making principles.  \n",
      "Against this political context, the Commission puts forward the proposed regulatory \n",
      "framework on Artificial Intelligence with the following specific objectives: \n",
      " ensure that AI systems placed on the Union market and used are safe and respect \n",
      "existing law on fundamental rights and Union values; \n",
      " ensure legal certainty to facilitate investment and innovation in AI; \n",
      " enhance governance and effective enforcement of existing law on fundamental \n",
      "rights and safety requirements applicable to AI systems; \n",
      " facilitate the development of a single market for lawful, safe and trustworthy AI \n",
      "applications and prevent market fragmentation. \n",
      "To achieve those objectives, this proposal presents a balanced and proportionate horizontal \n",
      "regulatory approach to AI that is limited to the minimum necessary requirements to address \n",
      "the risks and problems linked to AI, without unduly constraining or hindering technological \n",
      "development or otherwise disproportionately increasing the cost of placing AI solutions on \n",
      "the market. The proposal sets a robust and flexible legal framework. On the one hand, it is \n",
      "comprehensive and future-proof in its fundamental regulatory choices, including the \n",
      "principle-based requirements that AI systems should comply with. On the other hand, it puts \n",
      "in place a proportionate regulatory system centred on a well-defined risk-based regulatory \n",
      "approach that does not create unnecessary restrictions to trade, whereby legal intervention is \n",
      "tailored to those concrete situations where there is a justified cause for concern or where such \n",
      "concern can reasonably be anticipated in the near future. At the same time, the legal \n",
      "framework includes flexible mechanisms that enable it to be dynamically adapted as the \n",
      "technology evolves and new concerning situations emerge. \n",
      "The proposal sets harmonised rules for the development, placement on the market and use of \n",
      "AI systems in the Union following a proportionate risk-based approach. It proposes a single \n",
      "future-proof definition of AI. Certain particularly harmful AI practices are prohibited as \n",
      "contravening Union values, while specific restrictions and safeguards are proposed in relation \n",
      "to certain uses of remote biometric identification systems for the purpose of law enforcement. \n",
      "The proposal lays down a solid risk methodology to define “high-risk” AI systems that pose \n",
      "significant risks to the health and safety or fundamental rights of persons. Those AI systems \n",
      "will have to comply with a set of horizontal mandatory requirements for trustworthy AI and \n",
      "follow conformity assessment procedures before those systems can be placed on the Union \n",
      "market. Predictable, proportionate and clear obligations are also placed on providers and users \n",
      "of those systems to ensure safety and respect of existing legislation protecting fundamental \n",
      "rights throughout the whole AI systems’ lifecycle. For some specific AI systems, only \n",
      "minimum transparency obligations are proposed, in particular when chatbots or ‘deep fakes’ \n",
      "are used.  \n",
      "The proposed rules will be enforced through a governance system at Member States level, \n",
      "building on already existing structures, and a cooperation mechanism at Union level with the \n",
      "establishment of a European Artificial Intelligence Board. Additional measures are also \n",
      "proposed to support innovation, in particular through AI regulatory sandboxes and other \n",
      "measures to reduce the regulatory burden and to support Small and Medium-Sized Enterprises \n",
      "(‘SMEs’) and start-ups. \n",
      "\n",
      "\n",
      "--- nist_privacy_framework_v1.pdf (39 páginas útiles) ---\n",
      "\n",
      "--- Página real 5 (índice útil 1) ---\n",
      "NIST Privacy Framework \n",
      " \n",
      "January 16, 2020 \n",
      "1 \n",
      " \n",
      " \n",
      "1.0 Privacy Framework Introduction \n",
      "For more than two decades, the Internet and associated information technologies have driven \n",
      "unprecedented innovation, economic value, and access to social services. Many of these benefits are \n",
      "fueled by data about individuals that flow through a complex ecosystem. As a result, individuals may not \n",
      "be able to understand the potential consequences for their privacy as they interact with systems, \n",
      "products, and services. Organizations may not fully realize the consequences either. Failure to manage \n",
      "privacy risks can have direct adverse consequences at both the individual and societal levels, with \n",
      "follow-on effects on organizations’ brands, bottom lines, and future prospects for growth. Finding ways \n",
      "to continue to derive benefits from data processing while simultaneously protecting individuals’ privacy \n",
      "is challenging, and not well-suited to one-size-fits-all solutions. \n",
      "Privacy is challenging because not only is it an all-encompassing concept that helps to safeguard \n",
      "important values such as human autonomy and dignity, but also the means for achieving it can vary.3 For \n",
      "example, privacy can be achieved through seclusion, limiting observation, or individuals’ control of \n",
      "facets of their identities (e.g., body, data, reputation).4 Moreover, human autonomy and dignity are not \n",
      "fixed, quantifiable constructs; they are filtered through cultural diversity and individual differences. This \n",
      "broad and shifting nature of privacy makes it difficult to communicate clearly about privacy risks within \n",
      "and between organizations and with individuals. What has been missing is a common language and \n",
      "practical tool that is flexible enough to address diverse privacy needs. \n",
      "This voluntary NIST Privacy Framework: A Tool for Improving Privacy through Enterprise Risk \n",
      "Management (Privacy Framework) is intended to be widely usable by organizations of all sizes and \n",
      "agnostic to any particular technology, sector, law, or jurisdiction. Using a common approach—adaptable \n",
      "to any organization’s role(s) in the data processing ecosystem—the Privacy Framework’s purpose is to \n",
      "help organizations manage privacy risks by: \n",
      "• \n",
      "Taking privacy into account as they design and deploy systems, products, and services that \n",
      "affect individuals; \n",
      "• \n",
      "Communicating about their privacy practices; and \n",
      "• \n",
      "Encouraging cross-organizational workforce collaboration—for example, among executives, \n",
      "legal, and information technology (IT)—through the development of Profiles, selection of Tiers, \n",
      "and achievement of outcomes. \n",
      "                                                 \n",
      "3  \n",
      "Autonomy and dignity are concepts covered in the United Nations Universal Declaration of Human Rights at \n",
      "https://www.un.org/en/universal-declaration-human-rights/. \n",
      "4  \n",
      "There are many publications that provide an in-depth treatment on the background of privacy or different \n",
      "aspects of the concept. For two examples, see Solove D (2010) Understanding Privacy (Harvard University \n",
      "Press, Cambridge, MA), https://ssrn.com/abstract=1127888; and Selinger E, Hartzog W (2017) Obscurity and \n",
      "Privacy, Spaces for the Future: A Companion to Philosophy of Technology, eds Pitt J, Shew A (Taylor & Francis, \n",
      "New York, NY), Chapter 12, 1st Ed., https://doi.org/10.4324/9780203735657. \n",
      "\n",
      "\n",
      "--- Página real 7 (índice útil 3) ---\n",
      "NIST Privacy Framework \n",
      " \n",
      "January 16, 2020 \n",
      "3 \n",
      " \n",
      " \n",
      "about privacy risk management. Appendix D provides additional information on key privacy risk \n",
      "management practices. \n",
      "1.2.1  Cybersecurity and Privacy Risk Management \n",
      "Since its release in 2014, the Cybersecurity \n",
      "Framework has helped organizations to \n",
      "communicate and manage cybersecurity \n",
      "risk. [1] While managing cybersecurity \n",
      "risk contributes to managing privacy risk, \n",
      "it is not sufficient, as privacy risks can \n",
      "also arise by means unrelated to \n",
      "cybersecurity incidents, as illustrated by \n",
      "Figure 2. Having a general understanding \n",
      "of the different origins of cybersecurity \n",
      "and privacy risks is important for \n",
      "determining the most effective solutions to \n",
      "address the risks. \n",
      "The Privacy Framework approach to privacy \n",
      "risk is to consider privacy events as potential problems individuals could experience arising from system, \n",
      "product, or service operations with data, whether in digital or non-digital form, through a complete life \n",
      "cycle from data collection through disposal. \n",
      "The Privacy Framework describes these data operations in the singular as a data action and collectively \n",
      "as data processing. The problems individuals can experience as a result of data \n",
      "processing can be expressed in various ways, but NIST describes them as \n",
      "ranging from dignity-type effects such as embarrassment or stigmas to more \n",
      "tangible harms such as discrimination, economic loss, or physical harm.6 \n",
      "The basis for the problems that individuals may experience can vary. As \n",
      "depicted in Figure 2, problems arise as an adverse effect of data processing \n",
      "that organizations conduct to meet their mission or business objectives. An \n",
      "example is the concerns that certain communities had about the installation of \n",
      "“smart meters” as part of the Smart Grid, a nationwide technological effort to \n",
      "increase energy efficiency.7 The ability of these meters to collect, record, and \n",
      "distribute highly granular information about household electrical use could \n",
      "provide insight into people’s behavior inside their homes.8 The meters were \n",
      "                                                 \n",
      "6  \n",
      "NIST has created an illustrative catalog of problems for use in privacy risk assessment. See NIST Privacy Risk \n",
      "Assessment Methodology [3]. Other organizations may have created other categories of problems, or may \n",
      "refer to them as adverse consequences or harms. \n",
      "7  \n",
      "See, for example, NIST Interagency or Internal Report (IR) 7628 Revision 1 Volume 1, Guidelines for Smart Grid \n",
      "Cybersecurity: Volume 1 – Smart Grid Cybersecurity Strategy, Architecture, and High-Level Requirements at [4] \n",
      "p. 26. \n",
      "8  \n",
      "See NIST IR 8062, An Introduction to Privacy Engineering and Risk Management in Federal Systems at [5] p. 2. \n",
      "For additional types of privacy risks associated with adverse effects on individuals of data processing, see \n",
      "Appendix E of NIST IR 8062. \n",
      " \n",
      "Data Action \n",
      "A data life cycle \n",
      "operation, including, \n",
      "but not limited to \n",
      "collection, retention, \n",
      "logging, generation, \n",
      "transformation, use, \n",
      "disclosure, sharing, \n",
      "transmission, and \n",
      "disposal. \n",
      " \n",
      "Data Processing \n",
      "The collective set of \n",
      "data actions. \n",
      "Figure 2: Cybersecurity and Privacy Risk \n",
      "Relationship \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "Cybersecurity \n",
      "Risks   \n",
      "Privacy \n",
      "Risks \n",
      "associated with \n",
      "cybersecurity \n",
      "incidents arising from \n",
      "loss of confidentiality, \n",
      "integrity, or \n",
      "availability \n",
      "associated with \n",
      "privacy events \n",
      "arising from data \n",
      "processing \n",
      "cyber \n",
      "security-\n",
      "related \n",
      "privacy \n",
      "events \n",
      "\n",
      "\n",
      "--- oecd_ai_classification_framework.pdf (52 páginas útiles) ---\n",
      "\n",
      "--- Página real 16 (índice útil 1) ---\n",
      "16    OECD FRAMEWORK FOR THE CLASSIFICATION OF AI SYSTEMS \n",
      " © OECD 2022 \n",
      "  \n",
      "Different types of AI systems raise different policy opportunities and challenges. Section 2 of this report \n",
      "introduces and describes a framework to assess AI systems’ impact on public policy in areas covered by \n",
      "the OECD AI Principles (OECD, 2019d[1]). Section 3 puts the framework into use to classify specific AI \n",
      "systems and applications. Section 4 discusses how the framework could be used to help assess basic \n",
      "social, physical and ethical risks associated with specific types of AI systems.  \n",
      "Introducing the framework and its purpose \n",
      "The framework primary purpose is to characterise the application of an AI system deployed in a specific \n",
      "project and context, although some dimensions are also relevant to generic AI systems. It classifies AI \n",
      "systems and applications along the following dimensions: People & Planet, Economic Context, Data & \n",
      "Input, AI Model and Task & Output (Figure 1). These dimensions build on the conceptual view of a generic \n",
      "AI system established in previous OECD work (see Box 1 later in this section).  \n",
      "Figure 1. Key high-level dimensions of the OECD Framework for the Classification of AI Systems  \n",
      " \n",
      "The AI Principles as a lens for analysing policy considerations  \n",
      "Each of the framework’s dimensions has distinct properties and attributes, or sub-dimensions that are \n",
      "relevant to assessing policy considerations associated with a particular AI system. The 10 OECD AI \n",
      "Principles, adopted in 2019, help structure the analysis of policy considerations associated with each \n",
      "dimension and sub-dimension. The Principles cover the following themes: \n",
      "Table 1. The OECD AI Principles \n",
      "Values-based principles for all AI actors \n",
      "Recommendations to policy makers for AI policies  \n",
      "Principle 1.1. People and planet  \n",
      "Principle 2.1. Investment in R&D  \n",
      "Principle 1.2. Human rights, privacy, fairness \n",
      "Principle 2.2. Data, compute, technologies \n",
      "Principle 1.3. Transparency, explainability \n",
      "Principle 2.3. Enabling policy and regulatory environment  \n",
      "Principle 1.4. Robustness, security, safety \n",
      "Principle 2.4. Jobs, automation, skills \n",
      "Principle 1.5. Accountability \n",
      "Principle 2.5. International cooperation \n",
      "Source: (OECD, 2019d[1]) \n",
      "1 Overview and goal of the framework  \n",
      "\n",
      "\n",
      "--- Página real 18 (índice útil 3) ---\n",
      "18    OECD FRAMEWORK FOR THE CLASSIFICATION OF AI SYSTEMS \n",
      " © OECD 2022 \n",
      "  \n",
      "Table 2. Classification framework dimensions and criteria at a glance \n",
      "PEOPLE & PLANET \n",
      "Criteria \n",
      "Description \n",
      "USERS \n",
      "Users of AI system \n",
      "What is the level of competency of users who interact with the system? \n",
      "STAKEHOLDERS \n",
      "Impacted stakeholders \n",
      "Who is impacted by the system (e.g. consumers, workers, government agencies)? \n",
      "OPTIONALITY \n",
      "Optionality and redress \n",
      "Can users opt out, e.g. switch systems? Can users challenge or correct the output? \n",
      "HUMAN RIGHTS \n",
      "Human rights and democratic values Can the system’s outputs impact fundamental human rights (e.g. human dignity, \n",
      "privacy, freedom of expression, non-discrimination, fair trial, remedy, safety)? \n",
      "WELL-BEING & \n",
      "ENVIRONMENT \n",
      "Well-being, society and the \n",
      "environment \n",
      "Can the system’s outputs impact areas of life related to well-being (e.g. job quality, \n",
      "the environment, health, social interactions, civic engagement, education)? \n",
      "DISPLACEMENT \n",
      "{Displacement potential} \n",
      "Could the system automate tasks that are or were being executed by humans? \n",
      "ECONOMIC CONTEXT \n",
      "Criteria \n",
      "Description \n",
      "SECTOR \n",
      "Industrial sector \n",
      "Which industrial sector is the system deployed in (e.g. finance, agriculture)? \n",
      "BUSINESS FUNCTION & \n",
      "MODEL \n",
      "Business function \n",
      "What business function(s) is the system employed in (e.g. sales, customer service)? \n",
      "Business model \n",
      "Is the system a for-profit use, non-profit use or public service system? \n",
      "CRITICALITY \n",
      "Impacts critical functions / activities \n",
      "Would a disruption of the system’s function / activity affect essential services? \n",
      "SCALE & MATURITY \n",
      "Breadth of deployment \n",
      "Is the AI system deployment a pilot, narrow, broad or widespread? \n",
      "{Technical maturity} \n",
      "How technically mature is the system (Technology Readiness Level –TRL) \n",
      "DATA & INPUT \n",
      "Criteria \n",
      "Description \n",
      "COLLECTION \n",
      "Detection and collection  \n",
      "Are the data and input collected by humans, automated sensors or both? \n",
      " \n",
      "Provenance of data and input \n",
      "Are the data and input from experts; provided, observed, synthetic or derived?  \n",
      " \n",
      "Dynamic nature  \n",
      "Are the data dynamic, static, dynamic updated from time to time or real-time?  \n",
      "RIGHTS & \n",
      "IDENTIFIABILITY \n",
      "Rights  \n",
      "Are the data proprietary, public or personal data (related to identifiable individual)? \n",
      "“Identifiability” of personal data \n",
      "If personal data, are they anonymised; pseudonymised? \n",
      "STRUCTURE & FORMAT {Structure of data and input} \n",
      "Are the data structured, semi-structured, complex structured or unstructured? \n",
      "{Format of data and metadata} \n",
      "Is the format of the data and metadata standardised or non-standardised? \n",
      "SCALE \n",
      "{Scale} \n",
      "What is the dataset’s scale? \n",
      "QUALITY AND \n",
      "APPROPRIATENESS \n",
      "{Data quality and appropriateness} \n",
      "Is the dataset fit for purpose? Is the sample size adequate? Is it representative and \n",
      "complete enough? How noisy are the data?  \n",
      "AI MODEL \n",
      "Criteria \n",
      "Description \n",
      "MODEL \n",
      "CHARACTERISTICS \n",
      "Model information availability \n",
      "Is any information available about the system’s model? \n",
      "AI model type \n",
      "Is the model symbolic (human-generated rules), statistical (uses data) or hybrid? \n",
      "{Rights associated with model} \n",
      "Is the model open-source or proprietary, self or third-party managed? \n",
      "{Discriminative or generative} \n",
      "Is the model generative, discriminative or both? \n",
      "{Single or multiple model(s)} \n",
      "Is the system composed of one model or several interlinked models? \n",
      "MODEL-BUILDING \n",
      "Model-building from machine or \n",
      "human knowledge \n",
      "Does the system learn based on human-written rules, from data, through supervised \n",
      "learning, through reinforcement learning? \n",
      "Model evolution in the field ML \n",
      "Does the model evolve and / or acquire abilities from interacting with data in the field? \n",
      "Central or federated learning ML \n",
      "Is the model trained centrally or in a number of local servers or “edge” devices? \n",
      "MODEL INFERENCE \n",
      "{Model development / maintenance} \n",
      "Is the model universal, customisable or tailored to the AI actor’s data? \n",
      "{Deterministic and probabilistic} \n",
      "Is the model used in a deterministic or probabilistic manner? \n",
      "Transparency and explainability \n",
      "If information available to users to allow them to understand model outputs? \n",
      "TASK & OUTPUT \n",
      "Criteria \n",
      "Description \n",
      "TASKS \n",
      "Task(s) of the system \n",
      "What tasks does the system perform (e.g. recognition, event detection, forecasting)? \n",
      " \n",
      "{Combining tasks and actions into \n",
      "composite systems} \n",
      "Does the system combine several tasks and actions (e.g. content generation \n",
      "systems, autonomous systems, control systems)? \n",
      "ACTION \n",
      "Action autonomy \n",
      "How autonomous are the system’s actions and what role do humans play? \n",
      "APPLICATION AREA \n",
      "Core application area(s) \n",
      "Does the system belong to a core application area such as human language \n",
      "technologies, computer vision, automation and / or optimisation or robotics? \n",
      "EVALUATION \n",
      "{Evaluation methods} \n",
      "Are standards or methods available for evaluating system output? \n",
      "Note: Criteria and descriptions in grey and marked with an {} symbol = those where objective and consistent information is available. ML = for \n",
      "machine learning AI models. \n",
      "\n",
      "\n",
      "--- oecd_legal_0449_en.pdf (7 páginas útiles) ---\n",
      "\n",
      "--- Página real 3 (índice útil 1) ---\n",
      "Date(s)\n",
      "Adopted on 22/05/2019\n",
      "Background Information\n",
      "The Recommendation on Artificial Intelligence (AI) – the first intergovernmental standard on AI –\n",
      "was adopted by the OECD Council at Ministerial level on 22 May 2019 on the proposal of the\n",
      "Committee on Digital Economy Policy (CDEP). The Recommendation aims to foster innovation and\n",
      "trust in AI by promoting the responsible stewardship of trustworthy AI while ensuring respect for\n",
      "human rights and democratic values. Complementing existing OECD standards in areas such as\n",
      "privacy, digital security risk management, and responsible business conduct, the Recommendation\n",
      "focuses on AI-specific issues and sets a standard that is implementable and sufficiently flexible to\n",
      "stand the test of time in this rapidly evolving field. \n",
      "The Recommendation identifies five complementary values-based principles for the responsible\n",
      "stewardship of trustworthy AI and calls on AI actors to promote and implement them: \n",
      "inclusive growth, sustainable development and well-being;\n",
      "human-centred values and fairness;\n",
      "transparency and explainability;\n",
      "robustness, security and safety;\n",
      "and accountability.\n",
      "In addition to and consistent with these value-based principles, the Recommendation also provides\n",
      "five recommendations to policy-makers pertaining to national policies and international co-operation\n",
      "for trustworthy AI, namely: \n",
      "investing in AI research and development;\n",
      "fostering a digital ecosystem for AI;\n",
      "shaping an enabling policy environment for AI;\n",
      "building human capacity and preparing for labour market transformation;\n",
      "and international co-operation for trustworthy AI.\n",
      "The Recommendation also includes a provision for the development of metrics to measure AI\n",
      "research, development and deployment, and for building an evidence base to assess progress in its\n",
      "implementation.\n",
      "The OECD’s  work on Artificial Intelligence and rationale for developing the OECD\n",
      "Recommendation on Artificial Intelligence\n",
      "Artificial Intelligence (AI) is a general-purpose technology that has the potential to improve the\n",
      "welfare and well-being of people, to contribute to positive sustainable global economic activity, to\n",
      "increase innovation and productivity, and to help respond to key global challenges. It is deployed in\n",
      "many sectors ranging from production, finance and transport to healthcare and security. \n",
      "Alongside benefits, AI also raises challenges for our societies and economies, notably regarding\n",
      "economic shifts and inequalities, competition, transitions in the labour market, and implications for\n",
      "democracy and human rights.\n",
      "The OECD has undertaken empirical and policy activities on AI in support of the policy debate over\n",
      "the past two years, starting with a Technology Foresight Forum on AI in 2016 and an international\n",
      "conference on AI: Intelligent Machines, Smart Policies  in 2017. The Organisation also conducted\n",
      "analytical and measurement work that provides an overview of the AI technical landscape, maps\n",
      "economic and social impacts of AI technologies and their applications, identifies major policy\n",
      "considerations, and describes AI initiatives from governments and other stakeholders at national and\n",
      "international levels.\n",
      "\n",
      "\n",
      "--- Página real 5 (índice útil 3) ---\n",
      "Follow-up, monitoring of implementation and dissemination tools\n",
      "The OECD Recommendation on AI provides the first intergovernmental standard for AI policies and\n",
      "a foundation on which to conduct further analysis and develop tools to support governments in their\n",
      "implementation efforts. In this regard, it instructs the CDEP to monitor the implementation of the\n",
      "Recommendation and report to the Council on its implementation and continued relevance five years\n",
      "after its adoption and regularly thereafter. The CDEP is also instructed to continue its work on AI,\n",
      "building on this Recommendation, and taking into account work in other international fora, such as\n",
      "UNESCO, the Council of Europe and the initiative to build an International Panel on\n",
      "AI \n",
      "(see \n",
      "https://pm.gc.ca/eng/news/2018/12/06/mandate-international-panel-artificial-\n",
      "intelligence and https://www.gouvernement.fr/en/france-and-canada-create-new-expert-international-\n",
      "panel-on-artificial-intelligence).\n",
      "In order to support implementation of the Recommendation, the Council instructed the CDEP to\n",
      "develop practical guidance for implementation, to provide a forum for exchanging information on AI\n",
      "policy and activities, and to foster multi-stakeholder and interdisciplinary dialogue. This will be\n",
      "achieved largely through the OECD AI Policy Observatory, an inclusive hub for public policy on AI\n",
      "that aims to help countries encourage, nurture and monitor the responsible development of\n",
      "trustworthy artificial intelligence systems for the benefit of society. It will combine resources from\n",
      "across the OECD with those of partners from all stakeholder groups to provide multidisciplinary,\n",
      "evidence-based policy analysis on AI. The Observatory is planned to be launched late 2019 and will\n",
      "include a live database of AI strategies, policies and initiatives that countries and other stakeholders\n",
      "can share and update, enabling the comparison of their key elements in an interactive manner. It will\n",
      "also be continuously updated with AI metrics, measurements, policies and good practices that could\n",
      "lead to further updates in the practical guidance for implementation. \n",
      "The Recommendation is open to non-OECD Member adherence, underscoring the global relevance\n",
      "of OECD AI policy work as well as the Recommendation’s call for international co-operation. \n",
      "For further information please consult: oecd.ai.\n",
      "Contact information: ai@oecd.org.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "\n",
    "# zero-based index\n",
    "pages_dict = {\n",
    "    \"oecd_legal_0449_en.pdf\": range(2, 9),\n",
    "    \"eu_ai_act_regulation.pdf\": range(1, 95),\n",
    "    \"oecd_ai_classification_framework.pdf\": range(15, 67),\n",
    "    \"ai_hleg_ethics_guidelines.pdf\": range(3, 37),\n",
    "    \"nist_privacy_framework_v1.pdf\": range(4, 43),\n",
    "}\n",
    "\n",
    "for pdf_file in pdf_files:\n",
    "    if pdf_file not in pages_dict:\n",
    "        continue\n",
    "    pdf_path = os.path.join(pdf_dir, pdf_file)\n",
    "    doc = fitz.open(pdf_path)\n",
    "    page_idxs = list(pages_dict[pdf_file])\n",
    "    print(f\"\\n--- {pdf_file} ({len(page_idxs)} páginas útiles) ---\")\n",
    "\n",
    "    for idx, pagina_idx in enumerate([0, 2]):\n",
    "        if pagina_idx >= len(page_idxs):\n",
    "            continue\n",
    "        p = page_idxs[pagina_idx]\n",
    "        page = doc.load_page(p)\n",
    "        print(f\"\\n--- Página real {p+1} (índice útil {pagina_idx+1}) ---\")\n",
    "        print(page.get_text())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc915f68",
   "metadata": {},
   "source": [
    "Se guarda el texto y los metadatos de cada página útil por separado. Así luego es fácil saber de dónde sale cada fragmento cuando se hagan los chunks, aunque todavía no esté decidido el tamaño o la forma del chunking.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cf40b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "page_records = []\n",
    "\n",
    "for pdf_file in pdf_files:\n",
    "    if pdf_file not in pages_dict:\n",
    "        continue\n",
    "    pdf_path = os.path.join(pdf_dir, pdf_file)\n",
    "    doc = fitz.open(pdf_path)\n",
    "    page_idxs = list(pages_dict[pdf_file])\n",
    "    for i, p in enumerate(page_idxs):\n",
    "        page = doc.load_page(p)\n",
    "        text = page.get_text()\n",
    "        page_records.append({\n",
    "            \"pdf\": pdf_file,\n",
    "            \"page_real\": p + 1,  # página dentro del pdf\n",
    "            \"page_util\": i + 1,  # posición dentro de las útiles\n",
    "            \"text\": text\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0430b81e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ejemplo 1:\n",
      "  PDF: ai_hleg_ethics_guidelines.pdf\n",
      "  Página real: 4\n",
      "  Página útil: 1\n",
      "  Texto (primeros 300 caracteres):\n",
      "2 \n",
      " \n",
      "EXECUTIVE SUMMARY \n",
      "The aim of the Guidelines is to promote Trustworthy AI. Trustworthy AI has three components, which should be \n",
      "met throughout the system's entire life cycle: (1) it should be lawful, complying with all applicable laws and \n",
      "regulations (2) it should be ethical, ensuring adheren\n",
      "------------------------------------------------------------\n",
      "Ejemplo 2:\n",
      "  PDF: ai_hleg_ethics_guidelines.pdf\n",
      "  Página real: 5\n",
      "  Página útil: 2\n",
      "  Texto (primeros 300 caracteres):\n",
      "3 \n",
      " \n",
      " Foster research and innovation to help assess AI systems and to further the achievement of the \n",
      "requirements; disseminate results and open questions to the wider public, and systematically train a new \n",
      "generation of experts in AI ethics. \n",
      " Communicate, in a clear and proactive manner, inform\n",
      "------------------------------------------------------------\n",
      "Ejemplo 3:\n",
      "  PDF: ai_hleg_ethics_guidelines.pdf\n",
      "  Página real: 6\n",
      "  Página útil: 3\n",
      "  Texto (primeros 300 caracteres):\n",
      "4 \n",
      " \n",
      "A. INTRODUCTION \n",
      "In its Communication of 25 April 2018 and 7 December 2018, the European Commission set out its vision for \n",
      "artificial intelligence (AI), which supports “ethical, secure and cutting-edge AI made in Europe”.5 Three pillars \n",
      "underpin the Commission’s vision: (i) increasing public \n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 3 ejemplos\n",
    "for i, record in enumerate(page_records[:3]):\n",
    "    print(f\"Ejemplo {i+1}:\")\n",
    "    print(f\"  PDF: {record['pdf']}\")\n",
    "    print(f\"  Página real: {record['page_real']}\")\n",
    "    print(f\"  Página útil: {record['page_util']}\")\n",
    "    print(f\"  Texto (primeros 300 caracteres):\\n{record['text'][:300]}\")\n",
    "    print(\"-\" * 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a940e185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de palabras en todas las páginas útiles: 107749\n",
      "ai_hleg_ethics_guidelines.pdf | Página real: 4 | Palabras: 632\n",
      "ai_hleg_ethics_guidelines.pdf | Página real: 5 | Palabras: 590\n",
      "ai_hleg_ethics_guidelines.pdf | Página real: 6 | Palabras: 712\n",
      "ai_hleg_ethics_guidelines.pdf | Página real: 7 | Palabras: 652\n",
      "ai_hleg_ethics_guidelines.pdf | Página real: 8 | Palabras: 674\n"
     ]
    }
   ],
   "source": [
    "total_words = sum(len(record[\"text\"].split()) for record in page_records)\n",
    "print(f\"Total de palabras en todas las páginas útiles: {total_words}\")\n",
    "\n",
    "for i, record in enumerate(page_records[:5]):\n",
    "    n_words = len(record[\"text\"].split())\n",
    "    print(f\"{record['pdf']} | Página real: {record['page_real']} | Palabras: {n_words}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4a983f",
   "metadata": {},
   "source": [
    "Se procede a:\n",
    "\n",
    "Eliminar líneas vacías.\n",
    "\n",
    "Quitar líneas que son solo números (números de página).\n",
    "\n",
    "Quitar líneas con solo espacios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12e4d10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for record in page_records:\n",
    "    lines = record[\"text\"].split(\"\\n\")\n",
    "    clean_lines = []\n",
    "    for line in lines:\n",
    "        l = line.strip()\n",
    "        if not l:\n",
    "            continue  # línea vacía\n",
    "        if l.isdigit():\n",
    "            continue  # solo número\n",
    "        clean_lines.append(l)\n",
    "    record[\"text_clean\"] = \"\\n\".join(clean_lines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c4b080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Palabras totales por documento ---\n",
      "ai_hleg_ethics_guidelines.pdf: 20480 palabras\n",
      "eu_ai_act_regulation.pdf: 44606 palabras\n",
      "nist_privacy_framework_v1.pdf: 14465 palabras\n",
      "oecd_ai_classification_framework.pdf: 24491 palabras\n",
      "oecd_legal_0449_en.pdf: 3269 palabras\n",
      "\n",
      "--- Headers/footers más repetidos (top 10) ---\n",
      "'EN' aparece 94 veces\n",
      "'NIST Privacy Framework' aparece 39 veces\n",
      "'' aparece 3 veces\n",
      "'Figure 1: The Guidelines as a framework for Trustworthy AI' aparece 2 veces\n",
      "'surrender procedures between Member States (OJ L 190, 18.7.2002, p. 1).' aparece 2 veces\n",
      "'EXECUTIVE SUMMARY' aparece 1 veces\n",
      "'elderly, the integration of persons with disabilities and workers’ rights. See also article 38 dealing with consumer protection.' aparece 1 veces\n",
      "' Foster research and innovation to help assess AI systems and to further the achievement of the' aparece 1 veces\n",
      "'published in December 2018 by the Commission and Member States.' aparece 1 veces\n",
      "'A. INTRODUCTION' aparece 1 veces\n",
      "\n",
      "--- Ejemplos de títulos o secciones detectados (top 10) ---\n",
      "ai_hleg_ethics_guidelines.pdf | Página 4: EXECUTIVE SUMMARY\n",
      "ai_hleg_ethics_guidelines.pdf | Página 4: I.\n",
      "ai_hleg_ethics_guidelines.pdf | Página 6: A. INTRODUCTION\n",
      "ai_hleg_ethics_guidelines.pdf | Página 7: 1. it should be lawful, complying with all applicable laws and regulations;\n",
      "ai_hleg_ethics_guidelines.pdf | Página 7: 2. it should be ethical, ensuring adherence to ethical principles and values; and\n",
      "ai_hleg_ethics_guidelines.pdf | Página 7: 3. it should be robust, both from a technical and social perspective, since, even with good intentions, AI\n",
      "ai_hleg_ethics_guidelines.pdf | Página 8: B. A FRAMEWORK FOR TRUSTWORTHY AI\n",
      "ai_hleg_ethics_guidelines.pdf | Página 11: I.\n",
      "ai_hleg_ethics_guidelines.pdf | Página 11: 1. Fundamental rights as moral and legal entitlements\n",
      "ai_hleg_ethics_guidelines.pdf | Página 12: 2. From fundamental rights to ethical principles\n",
      "\n",
      "--- Ejemplos de posibles tablas o líneas sospechosas (top 5) ---\n",
      "ai_hleg_ethics_guidelines.pdf | Página 34: A number of EU projects aim for the development of Smart  Grids  and  Energy  Storage,  which  have  the  potential  to\n",
      "nist_privacy_framework_v1.pdf | Página 39: Problematic Data Action | Likelihood | Impact\n",
      "\n",
      "--- Páginas casi vacías (<20 palabras) ---\n",
      "ai_hleg_ethics_guidelines.pdf | Página 10 | Palabras: 10\n",
      "\n",
      "--- Ejemplos de líneas con URLs (top 5) ---\n",
      "ai_hleg_ethics_guidelines.pdf | Página 11: https://ec.europa.eu/commission/publications/reflection-paper-towards-sustainable-europe-2030_en\n",
      "ai_hleg_ethics_guidelines.pdf | Página 11: https://sustainabledevelopment.un.org/?menu=1300\n",
      "ai_hleg_ethics_guidelines.pdf | Página 20: http://fra.europa.eu/en/publication/2018/big-data-discrimination.\n",
      "ai_hleg_ethics_guidelines.pdf | Página 21: http://ec.europa.eu/research/infocentre/article_en.cfm?id=/research/headlines/news/article_19_03_12_en.html?infocentre&it\n",
      "ai_hleg_ethics_guidelines.pdf | Página 22: human rights at the EU level’, 2017, https://fra.europa.eu/en/opinion/2017/business-human-rights.\n",
      "\n",
      "--- Ejemplos de líneas con caracteres raros (top 5) ---\n",
      "ai_hleg_ethics_guidelines.pdf | Página 4: Trustworthy AI’s first component (lawful AI).1 Instead, it aims to offer guidance on the second and third\n",
      "ai_hleg_ethics_guidelines.pdf | Página 4:  Develop, deploy and use AI systems in a way that adheres to the ethical principles of: respect for human\n",
      "ai_hleg_ethics_guidelines.pdf | Página 4:  Pay particular attention to situations involving more vulnerable groups such as children, persons with\n",
      "ai_hleg_ethics_guidelines.pdf | Página 4:  Acknowledge that, while bringing substantial benefits to individuals and society, AI systems also pose\n",
      "ai_hleg_ethics_guidelines.pdf | Página 4:  Ensure that the development, deployment and use of AI systems meets the seven key requirements for\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter, defaultdict\n",
    "\n",
    "palabras_por_pdf = defaultdict(int)\n",
    "all_lines = []\n",
    "posibles_headers = Counter()\n",
    "posibles_titulos = []\n",
    "posibles_tablas = []\n",
    "paginas_vacias = []\n",
    "lineas_con_urls = []\n",
    "lineas_con_caracteres_raros = []\n",
    "\n",
    "for record in page_records:\n",
    "    pdf = record[\"pdf\"]\n",
    "    page = record[\"page_real\"]\n",
    "    text = record[\"text_clean\"]\n",
    "    n_words = len(text.split())\n",
    "    palabras_por_pdf[pdf] += n_words\n",
    "\n",
    "    # Separar por líneas\n",
    "    lines = [l.strip() for l in text.split(\"\\n\") if l.strip()]\n",
    "    all_lines.extend(lines)\n",
    "\n",
    "    # Headers/footers candidatos: primeras y últimas líneas\n",
    "    if lines:\n",
    "        posibles_headers[lines[0]] += 1\n",
    "        posibles_headers[lines[-1]] += 1\n",
    "\n",
    "    # Títulos/secciones: mayúsculas o numeración tipo \"1.\", \"2.1\", etc.\n",
    "    for line in lines:\n",
    "        if line.isupper() or line.startswith(tuple(f\"{i}.\" for i in range(10))):\n",
    "            posibles_titulos.append((pdf, page, line))\n",
    "        # Tablas o líneas sospechosas\n",
    "        if \"|\" in line or \"----\" in line or line.count(\"  \") > 3:\n",
    "            posibles_tablas.append((pdf, page, line))\n",
    "        # URLs/enlaces\n",
    "        if \"http\" in line or \"www.\" in line:\n",
    "            lineas_con_urls.append((pdf, page, line))\n",
    "        # Caracteres no ASCII\n",
    "        if any(ord(char) > 127 for char in line):\n",
    "            lineas_con_caracteres_raros.append((pdf, page, line))\n",
    "\n",
    "    # Páginas vacías\n",
    "    if n_words < 20:\n",
    "        paginas_vacias.append((pdf, page, n_words))\n",
    "\n",
    "# Resultados principales\n",
    "\n",
    "print(\"\\n--- Palabras totales por documento ---\")\n",
    "for pdf, n in palabras_por_pdf.items():\n",
    "    print(f\"{pdf}: {n} palabras\")\n",
    "\n",
    "print(\"\\n--- Headers/footers más repetidos (top 10) ---\")\n",
    "for header, count in posibles_headers.most_common(10):\n",
    "    print(f\"'{header}' aparece {count} veces\")\n",
    "\n",
    "print(\"\\n--- Ejemplos de títulos o secciones detectados (top 10) ---\")\n",
    "for t in posibles_titulos[:10]:\n",
    "    print(f\"{t[0]} | Página {t[1]}: {t[2]}\")\n",
    "\n",
    "print(\"\\n--- Ejemplos de posibles tablas o líneas sospechosas (top 5) ---\")\n",
    "for t in posibles_tablas[:5]:\n",
    "    print(f\"{t[0]} | Página {t[1]}: {t[2]}\")\n",
    "\n",
    "print(\"\\n--- Páginas casi vacías (<20 palabras) ---\")\n",
    "for v in paginas_vacias:\n",
    "    print(f\"{v[0]} | Página {v[1]} | Palabras: {v[2]}\")\n",
    "\n",
    "print(\"\\n--- Ejemplos de líneas con URLs (top 5) ---\")\n",
    "for u in lineas_con_urls[:5]:\n",
    "    print(f\"{u[0]} | Página {u[1]}: {u[2]}\")\n",
    "\n",
    "print(\"\\n--- Ejemplos de líneas con caracteres raros (top 5) ---\")\n",
    "for r in lineas_con_caracteres_raros[:5]:\n",
    "    print(f\"{r[0]} | Página {r[1]}: {r[2]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8295ee59",
   "metadata": {},
   "source": [
    "> Se aplican reglas extra de limpieza:\n",
    "> - Se eliminan los headers y footers repetidos que se han detectado (como 'EN' y 'NIST Privacy Framework').\n",
    "> - Los títulos que encajan con patrones se guardan como metadato 'titulo_interpretado' para cada página.\n",
    "> - Se omiten páginas casi vacías, ya que suelen ser separadores o finales de sección.\n",
    "> - Se eliminan las líneas que solo son URLs, porque no se enlazará a fuentes externas.\n",
    "> - Se sustituyen los caracteres raros (no ASCII) por espacios para que el texto quede limpio pero no se pierda info útil."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e2b62db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Headers y footers a eliminar\n",
    "headers_a_eliminar = {\"EN\", \"NIST Privacy Framework\"}\n",
    "\n",
    "def es_url(line):\n",
    "    return \"http\" in line or \"www.\" in line\n",
    "\n",
    "def tiene_caracter_raro(line):\n",
    "    return any(ord(char) > 127 for char in line)\n",
    "\n",
    "def limpiar_caracteres_raros(line):\n",
    "    return ''.join(char if ord(char) < 128 else ' ' for char in line)\n",
    "\n",
    "nuevos_records = []\n",
    "for record in page_records:\n",
    "    lines = [l.strip() for l in record[\"text\"].split(\"\\n\") if l.strip()]\n",
    "    clean_lines = []\n",
    "    titulo_interpretado = None\n",
    "    for i, line in enumerate(lines):\n",
    "        if line in headers_a_eliminar:\n",
    "            continue\n",
    "        if es_url(line):\n",
    "            continue\n",
    "        if line.isdigit():\n",
    "            continue\n",
    "        line_limpia = limpiar_caracteres_raros(line)\n",
    "        # Detección de títulos\n",
    "        if (line_limpia.isupper() or re.match(r\"^[A-Z]\\.\\s\", line_limpia) or re.match(r\"^\\d+(\\.\\d+)*\", line_limpia)):\n",
    "            if titulo_interpretado is None:\n",
    "                titulo_interpretado = line_limpia\n",
    "        clean_lines.append(line_limpia)\n",
    "    texto_final = \"\\n\".join(clean_lines)\n",
    "    if len(texto_final.split()) < 20:\n",
    "        continue\n",
    "    nuevos_records.append({\n",
    "        \"pdf\": record[\"pdf\"],\n",
    "        \"page_real\": record[\"page_real\"],\n",
    "        \"page_util\": record[\"page_util\"],\n",
    "        \"titulo_interpretado\": titulo_interpretado,\n",
    "        \"text_clean\": texto_final\n",
    "    })\n",
    "\n",
    "# Reemplaza page_records por los nuevos\n",
    "page_records = nuevos_records\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7af2a27c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ai_hleg_ethics_guidelines.pdf ===\n",
      "  Página 4: EXECUTIVE SUMMARY\n",
      "  Página 6: A. INTRODUCTION\n",
      "  Página 7: 1. it should be lawful, complying with all applicable laws and regulations;\n",
      "  Página 8: B. A FRAMEWORK FOR TRUSTWORTHY AI\n",
      "  Página 11: I.\n",
      "  Página 12: 2. From fundamental rights to ethical principles\n",
      "  Página 13: 2.2 Ethical Principles in the Context of AI Systems22\n",
      "  Página 15: 2.3 Tensions between the principles\n",
      "  Página 16: II.\n",
      "  Página 17: 1.1 Human agency and oversight\n",
      "  Página 18: 1.2 Technical robustness and safety\n",
      "  Página 19: 1.3 Privacy and data governance\n",
      "  Página 20: 1.4 Transparency\n",
      "  Página 21: 1.6 Societal and environmental well-being\n",
      "  Página 22: 2. Technical and non-technical methods to realise Trustworthy AI\n",
      "  Página 23: 2.1. Technical methods\n",
      "  Página 24: 2.2. Non-technical methods\n",
      "  Página 25: IEEE\n",
      "  Página 27: HR\n",
      "  Página 28: TRUSTWORTHY AI ASSESSMENT LIST (PILOT VERSION)\n",
      "  Página 29: 2. Technical robustness and safety\n",
      "  Página 30: 3. Privacy and data governance\n",
      "  Página 31: 5. Diversity, non-discrimination and fairness\n",
      "  Página 32: 6. Societal and environmental well-being\n",
      "  Página 33: 7. Accountability\n",
      "  Página 34: C.\n",
      "  Página 35: 2.\n",
      "  Página 37: D. CONCLUSION\n",
      "\n",
      "=== eu_ai_act_regulation.pdf ===\n",
      "  Página 2: EXPLANATORY MEMORANDUM\n",
      "  Página 3: 2020/2012(INL).\n",
      "  Página 5: 1.2.\n",
      "  Página 6: 1.3.\n",
      "  Página 7: 2.\n",
      "  Página 8: 2.3.\n",
      "  Página 9: 27. Depending on the question, between 81 and 598 of the respondents used the free text\n",
      "  Página 10: 130 comments27. Additional stakeholder workshops and events were also organised the\n",
      "  Página 11: 3.4.\n",
      "  Página 12: 3.5.\n",
      "  Página 13: 5.\n",
      "  Página 14: 5.2.3.\n",
      "  Página 15: 5.2.4.\n",
      "  Página 16: 5.2.5.\n",
      "  Página 17: 5.2.7.\n",
      "  Página 18: 2021/0106 (COD)\n",
      "  Página 19: 2020/2012(INL).\n",
      "  Página 20: 3(18) of Regulation (EU) 2018/1725 of the European Parliament and of the Council36\n",
      "  Página 23: 2002/584/JHA, some are in practice likely to be more relevant than others, in that the\n",
      "  Página 24: 2016/680. However, the use of  real-time  remote biometric identification systems in\n",
      "  Página 25: 167/2013 of the European Parliament and of the Council40, Regulation (EU) No\n",
      "  Página 26: 661/2009 of the European Parliament and of the Council and Commission Regulations (EC) No\n",
      "  Página 27: 1223/2009 and repealing Council Directives 90/385/EEC and 93/42/EEC (OJ L 117, 5.5.2017, p. 1).\n",
      "  Página 29: 2013/32/EU of the European Parliament and of the Council49, the Regulation (EC) No\n",
      "  Página 32: 2019/1020 of the European Parliament and of the Council53 on market surveillance\n",
      "  Página 33: 94/9/EC, 94/25/EC, 95/16/EC, 97/23/EC, 98/34/EC, 2004/22/EC, 2007/23/EC, 2009/23/EC and\n",
      "  Página 36: 83(2) of Regulation 2016/679 and Article 57 of Directive 2016/680.\n",
      "  Página 37: 2013/36/EU of the European Parliament and of the Council56, it is also appropriate to\n",
      "  Página 39: 85]. However, the infrastructure related to the governance and the conformity\n",
      "  Página 40: 2.\n",
      "  Página 44: TITLE II\n",
      "  Página 45: 2.\n",
      "  Página 46: TITLE III\n",
      "  Página 47: CHAPTER 2\n",
      "  Página 48: 3.\n",
      "  Página 49: 8.\n",
      "  Página 50: 6.\n",
      "  Página 51: 1.\n",
      "  Página 52: 1.\n",
      "  Página 53: 2.\n",
      "  Página 54: 1.\n",
      "  Página 55: 2.\n",
      "  Página 56: 1.\n",
      "  Página 57: 1.\n",
      "  Página 58: 1.\n",
      "  Página 59: 1.\n",
      "  Página 60: 3.\n",
      "  Página 61: 3.\n",
      "  Página 62: 10.\n",
      "  Página 63: 1.\n",
      "  Página 64: CHAPTER 5\n",
      "  Página 65: 2.\n",
      "  Página 66: 4.\n",
      "  Página 67: 1.\n",
      "  Página 68: 2.\n",
      "  Página 69: 4.\n",
      "  Página 70: TITLE IV\n",
      "  Página 71: 3.\n",
      "  Página 72: 2.\n",
      "  Página 73: TITLE VI\n",
      "  Página 74: CHAPTER 2\n",
      "  Página 75: 7.\n",
      "  Página 76: 2.\n",
      "  Página 77: CHAPTER 3\n",
      "  Página 78: 1.\n",
      "  Página 79: 3.\n",
      "  Página 80: 9.\n",
      "  Página 81: 5.\n",
      "  Página 82: 4.\n",
      "  Página 83: 1.\n",
      "  Página 84: 1.\n",
      "  Página 85: 2.\n",
      "  Página 87: 1 concerning Artificial Intelligence systems which are safety components in the meaning of\n",
      "  Página 88: 1.\n",
      "  Página 89: 71(1), applied by Member States to infringements of the provisions of this\n",
      "  Página 90: LEGISLATIVE FINANCIAL STATEMENT\n",
      "  Página 91: 2.3. Measures to prevent fraud and irregularities\n",
      "  Página 92: LEGISLATIVE FINANCIAL STATEMENT\n",
      "  Página 94: 1.4.3.\n",
      "  Página 95: 1.5.3.\n",
      "\n",
      "=== nist_privacy_framework_v1.pdf ===\n",
      "  Página 5: 1.0 Privacy Framework Introduction\n",
      "  Página 6: CURRENT\n",
      "  Página 7: 1.2.1  Cybersecurity and Privacy Risk Management\n",
      "  Página 8: 1.2.2 Privacy Risk Assessment\n",
      "  Página 9: 11  See NIST Special Publication (SP) 800-39, Managing Information Security Risk: Organization, Mission, and\n",
      "  Página 10: 2.0 Privacy Framework Basics\n",
      "  Página 11: IDENTIFY-P\n",
      "  Página 12: PROFILES\n",
      "  Página 13: 3.0 How to Use the Privacy Framework\n",
      "  Página 14: 13  See, e.g., Organisation for Economic Co-operation and Development (OECD) (2013) OECD Guidelines on the\n",
      "  Página 15: 14  See, e.g., NIST SP 800-37, Rev. 2, Risk Management Framework for Information Systems and Organizations: A\n",
      "  Página 16: 16  NIST SP 800-37, Rev. 2 [7] provides additional information on steps to execute on the action plan, including\n",
      "  Página 19: 12_0.pdf\n",
      "  Página 23: ID-P\n",
      "  Página 24: IDENTIFY-P (ID-\n",
      "  Página 26: GOVERN-P (GV-P):\n",
      "  Página 27: CONTROL-P (CT-\n",
      "  Página 29: COMMUNICATE-P\n",
      "  Página 32: (NIST SP 800-63-3 [8])\n",
      "  Página 33: 8062 [5])\n",
      "  Página 34: 8062 [5])\n",
      "  Página 35: IEC\n",
      "  Página 38: 18  The privacy engineering objectives are adapted from NIST IR 8062 [5]. The security objectives are from NIST SP\n",
      "  Página 39: 19  NIST has developed a Privacy Risk Assessment Methodology (PRAM) that can help organizations identify,\n",
      "  Página 40: 23  The NIST PRAM uses organizational costs such as non-compliance costs, direct business costs, reputational\n",
      "\n",
      "=== oecd_ai_classification_framework.pdf ===\n",
      "  Página 16: 16     OECD FRAMEWORK FOR THE CLASSIFICATION OF AI SYSTEMS\n",
      "  Página 17: OECD FRAMEWORK FOR THE CLASSIFICATION OF AI SYSTEMS   17\n",
      "  Página 18: 18     OECD FRAMEWORK FOR THE CLASSIFICATION OF AI SYSTEMS\n",
      "  Página 19: OECD FRAMEWORK FOR THE CLASSIFICATION OF AI SYSTEMS   19\n",
      "  Página 20: 20     OECD FRAMEWORK FOR THE CLASSIFICATION OF AI SYSTEMS\n",
      "  Página 21: OECD FRAMEWORK FOR THE CLASSIFICATION OF AI SYSTEMS   21\n",
      "  Página 22: 22     OECD FRAMEWORK FOR THE CLASSIFICATION OF AI SYSTEMS\n",
      "  Página 23: OECD FRAMEWORK FOR THE CLASSIFICATION OF AI SYSTEMS   23\n",
      "  Página 24: 24     OECD FRAMEWORK FOR THE CLASSIFICATION OF AI SYSTEMS\n",
      "  Página 25: OECD FRAMEWORK FOR THE CLASSIFICATION OF AI SYSTEMS   25\n",
      "  Página 26: 26     OECD FRAMEWORK FOR THE CLASSIFICATION OF AI SYSTEMS\n",
      "  Página 27: OECD FRAMEWORK FOR THE CLASSIFICATION OF AI SYSTEMS   27\n",
      "  Página 28: 28     OECD FRAMEWORK FOR THE CLASSIFICATION OF AI SYSTEMS\n",
      "  Página 29: OECD FRAMEWORK FOR THE CLASSIFICATION OF AI SYSTEMS   29\n",
      "  Página 30: 30     OECD FRAMEWORK FOR THE CLASSIFICATION OF AI SYSTEMS\n",
      "  Página 31: OECD FRAMEWORK FOR THE CLASSIFICATION OF AI SYSTEMS   31\n",
      "  Página 32: 32     OECD FRAMEWORK FOR THE CLASSIFICATION OF AI SYSTEMS\n",
      "  Página 33: OECD FRAMEWORK FOR THE CLASSIFICATION OF AI SYSTEMS   33\n",
      "  Página 34: 34     OECD FRAMEWORK FOR THE CLASSIFICATION OF AI SYSTEMS\n",
      "  Página 35: OECD FRAMEWORK FOR THE CLASSIFICATION OF AI SYSTEMS   35\n",
      "  Página 36: 36     OECD FRAMEWORK FOR THE CLASSIFICATION OF AI SYSTEMS\n",
      "  Página 37: OECD FRAMEWORK FOR THE CLASSIFICATION OF AI SYSTEMS   37\n",
      "  Página 38: 38     OECD FRAMEWORK FOR THE CLASSIFICATION OF AI SYSTEMS\n",
      "  Página 39: OECD FRAMEWORK FOR THE CLASSIFICATION OF AI SYSTEMS   39\n",
      "  Página 40: 40     OECD FRAMEWORK FOR THE CLASSIFICATION OF AI SYSTEMS\n",
      "  Página 41: OECD FRAMEWORK FOR THE CLASSIFICATION OF AI SYSTEMS   41\n",
      "  Página 42: 42     OECD FRAMEWORK FOR THE CLASSIFICATION OF AI SYSTEMS\n",
      "  Página 43: OECD FRAMEWORK FOR THE CLASSIFICATION OF AI SYSTEMS   43\n",
      "  Página 44: 44     OECD FRAMEWORK FOR THE CLASSIFICATION OF AI SYSTEMS\n",
      "  Página 45: OECD FRAMEWORK FOR THE CLASSIFICATION OF AI SYSTEMS   45\n",
      "  Página 46: 46     OECD FRAMEWORK FOR THE CLASSIFICATION OF AI SYSTEMS\n",
      "  Página 47: OECD FRAMEWORK FOR THE CLASSIFICATION OF AI SYSTEMS   47\n",
      "  Página 48: 48     OECD FRAMEWORK FOR THE CLASSIFICATION OF AI SYSTEMS\n",
      "  Página 49: OECD FRAMEWORK FOR THE CLASSIFICATION OF AI SYSTEMS   49\n",
      "  Página 50: 50     OECD FRAMEWORK FOR THE CLASSIFICATION OF AI SYSTEMS\n",
      "  Página 51: OECD FRAMEWORK FOR THE CLASSIFICATION OF AI SYSTEMS   51\n",
      "  Página 52: 52     OECD FRAMEWORK FOR THE CLASSIFICATION OF AI SYSTEMS\n",
      "  Página 53: OECD FRAMEWORK FOR THE CLASSIFICATION OF AI SYSTEMS   53\n",
      "  Página 54: 54     OECD FRAMEWORK FOR THE CLASSIFICATION OF AI SYSTEMS\n",
      "  Página 55: OECD FRAMEWORK FOR THE CLASSIFICATION OF AI SYSTEMS   55\n",
      "  Página 56: 56     OECD FRAMEWORK FOR THE CLASSIFICATION OF AI SYSTEMS\n",
      "  Página 57: OECD FRAMEWORK FOR THE CLASSIFICATION OF AI SYSTEMS   57\n",
      "  Página 58: 58     OECD FRAMEWORK FOR THE CLASSIFICATION OF AI SYSTEMS\n",
      "  Página 59: OECD FRAMEWORK FOR THE CLASSIFICATION OF AI SYSTEMS   59\n",
      "  Página 60: 60     OECD FRAMEWORK FOR THE CLASSIFICATION OF AI SYSTEMS\n",
      "  Página 61: OECD FRAMEWORK FOR THE CLASSIFICATION OF AI SYSTEMS   61\n",
      "  Página 62: 62     OECD FRAMEWORK FOR THE CLASSIFICATION OF AI SYSTEMS\n",
      "  Página 63: OECD FRAMEWORK FOR THE CLASSIFICATION OF AI SYSTEMS   63\n",
      "  Página 64: 64     OECD FRAMEWORK FOR THE CLASSIFICATION OF AI SYSTEMS\n",
      "  Página 65: OECD FRAMEWORK FOR THE CLASSIFICATION OF AI SYSTEMS   65\n",
      "  Página 66: 66     OECD FRAMEWORK FOR THE CLASSIFICATION OF AI SYSTEMS\n",
      "  Página 67: OECD FRAMEWORK FOR THE CLASSIFICATION OF AI SYSTEMS   67\n",
      "\n",
      "=== oecd_legal_0449_en.pdf ===\n",
      "  Página 4: 1. Principles for responsible stewardship of trustworthy AI: the first section sets out five\n",
      "  Página 5: AI\n",
      "  Página 6: THE COUNCIL,\n",
      "  Página 7: I.\n",
      "  Página 8: 1.3.\n",
      "  Página 9: 2.3.\n"
     ]
    }
   ],
   "source": [
    "titulos_por_pdf = defaultdict(list)\n",
    "for record in page_records:\n",
    "    if record[\"titulo_interpretado\"]:\n",
    "        titulos_por_pdf[record[\"pdf\"]].append((record[\"page_real\"], record[\"titulo_interpretado\"]))\n",
    "\n",
    "# índice de cada PDF\n",
    "for pdf, titulos in titulos_por_pdf.items():\n",
    "    print(f\"\\n=== {pdf} ===\")\n",
    "    for page, titulo in titulos:\n",
    "        print(f\"  Página {page}: {titulo}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3fc2e0",
   "metadata": {},
   "source": [
    "Muchos de los títulos detectados no aportan mucha información, ya que algunos son solo números o referencias de página. Aunque no son muy útiles por sí mismos, los dejamos en los metadatos porque ocupan poco y pueden servir como referencia extra si hace falta luego.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Generación de chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8da80bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 300\n",
    "\n",
    "chunks = []\n",
    "for pdf in set(r[\"pdf\"] for r in page_records):\n",
    "    # Filtra las páginas de este PDF y las ordena\n",
    "    paginas = [r for r in page_records if r[\"pdf\"] == pdf]\n",
    "    paginas.sort(key=lambda x: x[\"page_real\"])\n",
    "    \n",
    "    palabras = []\n",
    "    paginas_chunk = []\n",
    "    titulos_chunk = set()\n",
    "    idx_chunk = 1\n",
    "    \n",
    "    for p in paginas:\n",
    "        palabras_pagina = p[\"text_clean\"].split()\n",
    "        if p[\"titulo_interpretado\"]:\n",
    "            titulos_chunk.add(p[\"titulo_interpretado\"])\n",
    "        paginas_chunk.append(p[\"page_real\"])\n",
    "        \n",
    "        for w in palabras_pagina:\n",
    "            palabras.append(w)\n",
    "            if len(palabras) == chunk_size:\n",
    "                chunk_text = \" \".join(palabras)\n",
    "                chunks.append({\n",
    "                    \"pdf\": pdf,\n",
    "                    \"pages\": paginas_chunk.copy(),\n",
    "                    \"titles\": list(titulos_chunk),\n",
    "                    \"chunk_index\": idx_chunk,\n",
    "                    \"text\": chunk_text,\n",
    "                    \"n_words\": len(palabras)\n",
    "                })\n",
    "                idx_chunk += 1\n",
    "                palabras = []\n",
    "                paginas_chunk = []\n",
    "                titulos_chunk = set()\n",
    "    \n",
    "    if palabras:\n",
    "        chunk_text = \" \".join(palabras)\n",
    "        chunks.append({\n",
    "            \"pdf\": pdf,\n",
    "            \"pages\": paginas_chunk.copy(),\n",
    "            \"titles\": list(titulos_chunk),\n",
    "            \"chunk_index\": idx_chunk,\n",
    "            \"text\": chunk_text,\n",
    "            \"n_words\": len(palabras)\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8d4e5a94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardado el corpus en d:\\TFM_RAG_NOR\\data\\chunks\\corpus_chunks_300w.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "output_dir = os.path.join(project_root, \"data\", \"chunks\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "output_file = os.path.join(output_dir, \"corpus_chunks_300w.json\")\n",
    "\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(chunks, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"Guardado el corpus en {output_file}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3d6c7895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de chunks: 357\n",
      "oecd_ai_classification_framework.pdf: 81 chunks\n",
      "ai_hleg_ethics_guidelines.pdf: 68 chunks\n",
      "nist_privacy_framework_v1.pdf: 48 chunks\n",
      "eu_ai_act_regulation.pdf: 149 chunks\n",
      "oecd_legal_0449_en.pdf: 11 chunks\n",
      "\n",
      "Palabras por chunk: min=74, max=300, media=298\n",
      "\n",
      "Ejemplos aleatorios de chunks:\n",
      "\n",
      "PDF: eu_ai_act_regulation.pdf\n",
      "Chunk #92, Páginas: [54], Títulos: ['1.']\n",
      "Nº palabras: 300\n",
      "Texto (primeros 200 caracteres):\n",
      "AI systems shall: (a) ensure that their high-risk AI systems are compliant with the requirements set out in Chapter 2 of this Title; (b) have a quality management system in place which complies with A\n",
      "--------------------------------------------------------------------------------\n",
      "PDF: ai_hleg_ethics_guidelines.pdf\n",
      "Chunk #44, Páginas: [], Títulos: []\n",
      "Nº palabras: 300\n",
      "Texto (primeros 200 caracteres):\n",
      "or board, is to provide oversight and advice. As set out above, certification specifications and bodies can also play a role to this end. Communication channels should be ensured with industry and/or \n",
      "--------------------------------------------------------------------------------\n",
      "PDF: ai_hleg_ethics_guidelines.pdf\n",
      "Chunk #9, Páginas: [8], Títulos: ['B. A FRAMEWORK FOR TRUSTWORTHY AI']\n",
      "Nº palabras: 300\n",
      "Texto (primeros 200 caracteres):\n",
      "AI, including but not limited to companies, organisations, researchers, public services, government agencies, institutions, civil society organisations, individuals, workers and consumers. Stakeholder\n",
      "--------------------------------------------------------------------------------\n",
      "PDF: ai_hleg_ethics_guidelines.pdf\n",
      "Chunk #13, Páginas: [11], Títulos: ['I.']\n",
      "Nº palabras: 300\n",
      "Texto (primeros 200 caracteres):\n",
      "1 below Fundamental rights lie at the foundation of both international and EU human rights law and underpin the legally enforceable rights guaranteed by the EU Treaties and the EU Charter. Being legal\n",
      "--------------------------------------------------------------------------------\n",
      "PDF: nist_privacy_framework_v1.pdf\n",
      "Chunk #35, Páginas: [33], Títulos: ['8062 [5])']\n",
      "Nº palabras: 300\n",
      "Texto (primeros 200 caracteres):\n",
      "manage privacy risks. Core A set of privacy protection activities and outcomes. The Framework Core comprises three elements: Functions, Categories, and Subcategories. Cybersecurity Incident (Framework\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# chunks en total y por documento\n",
    "from collections import Counter\n",
    "\n",
    "print(f\"Total de chunks: {len(chunks)}\")\n",
    "chunks_por_pdf = Counter(chunk[\"pdf\"] for chunk in chunks)\n",
    "for pdf, n in chunks_por_pdf.items():\n",
    "    print(f\"{pdf}: {n} chunks\")\n",
    "\n",
    "# distribución de palabras por chunk\n",
    "palabras_por_chunk = [chunk[\"n_words\"] for chunk in chunks]\n",
    "print(f\"\\nPalabras por chunk: min={min(palabras_por_chunk)}, max={max(palabras_por_chunk)}, media={sum(palabras_por_chunk)//len(palabras_por_chunk)}\")\n",
    "\n",
    "# metadatos\n",
    "print(\"\\nEjemplos aleatorios de chunks:\\n\")\n",
    "for i in random.sample(range(len(chunks)), min(5, len(chunks))):\n",
    "    c = chunks[i]\n",
    "    print(f\"PDF: {c['pdf']}\")\n",
    "    print(f\"Chunk #{c['chunk_index']}, Páginas: {c['pages']}, Títulos: {c['titles']}\")\n",
    "    print(f\"Nº palabras: {c['n_words']}\")\n",
    "    print(f\"Texto (primeros 200 caracteres):\\n{c['text'][:200]}\")\n",
    "    print(\"-\" * 80)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
