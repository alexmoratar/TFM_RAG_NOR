{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b54b87d",
   "metadata": {},
   "source": [
    "## Índice\n",
    "\n",
    "1. [Introducción y objetivos](#1-introducción-y-objetivos)\n",
    "2. [Carga de datos y preparación](#2-carga-de-datos-y-preparación)\n",
    "3. [Extracción y limpieza de texto](#3-extracción-y-limpieza-de-texto)\n",
    "    - 3.1. Ejemplo de estructura del PDF\n",
    "    - 3.2. Detección y eliminación de ruido\n",
    "    - 3.3. Análisis de títulos y secciones\n",
    "4. [Generación del corpus estructurado](#4-generación-del-corpus-estructurado)\n",
    "5. [Notas y próximos pasos](#5-notas-y-próximos-pasos)\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Introducción y objetivos\n",
    "\n",
    "En este notebook se va a extraer y limpiar texto de documentos normativos en PDF para montar un corpus usable en tareas de recuperación de información. El objetivo es dejar los datos listos para probar chunking y modelos de RAG sobre casos reales, no solo datasets de ejemplo.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Carga de datos y preparación\n",
    "\n",
    "Se cargan los PDFs en bruto desde la carpeta del proyecto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4869c7d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ai_hleg_ethics_guidelines.pdf',\n",
       " 'eu_ai_act_regulation.pdf',\n",
       " 'nist_privacy_framework_v1.pdf',\n",
       " 'oecd_ai_classification_framework.pdf',\n",
       " 'oecd_legal_0449_en.pdf']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "pdf_dir = \"../data/raw_pdfs\"\n",
    "pdf_files = [f for f in os.listdir(pdf_dir) if f.lower().endswith(\".pdf\")]\n",
    "pdf_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24db1ac",
   "metadata": {},
   "source": [
    "## 3. Extracción y limpieza de texto\n",
    "\n",
    "Se empieza la extracción del texto de los PDFs para ver la estructura y el tipo de contenido que tiene cada uno. El objetivo aquí es detectar qué ruido hay (como encabezados, pies de página o tablas raras) y ver si los títulos y secciones se pueden distinguir bien.\n",
    "\n",
    "De manera manual, se han revisado por encima los PDFs y se quitan las sigiuentes páginas:\n",
    "\n",
    "| PDF                           | Páginas útiles       |\n",
    "|-------------------------------|---------------------|\n",
    "| oecd_legal_0449_en.pdf        | 3 a 9               | \n",
    "| eu_ai_act_regulation.pdf      | 2 a 95              | \n",
    "| oecd_ai_classification_framework.pdf | 16 a 67       |\n",
    "| ai_hleg_ethics_guidelines.pdf | 4 a 37              |\n",
    "| nist_privacy_framework_v1.pdf | 5 a 43              |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b35c915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- ai_hleg_ethics_guidelines.pdf (34 páginas útiles) ---\n",
      "\n",
      "--- Página real 4 (índice útil 1) ---\n",
      "2 \n",
      " \n",
      "EXECUTIVE SUMMARY \n",
      "The aim of the Guidelines is to promote Trustworthy AI. Trustworthy AI has three components, which should be \n",
      "met throughout the system's entire life cycle: (1) it should be lawful, complying with all applicable laws and \n",
      "regulations (2) it should be ethical, ensuring adherence to ethical principles and values and (3) it should be robust, \n",
      "both from a technical and social perspective since, even with good intentions, AI systems can cause unintentional \n",
      "harm. Each component in itself is necessary but not sufficient for the achievement of Trustworthy AI. Ideally, all \n",
      "three components work in harmony and overlap in their operation. If, in practice, tensions arise between these \n",
      "components, society should endeavour to align them.  \n",
      "These Guidelines set out a framework for achieving Trustworthy AI. The framework does not explicitly deal with \n",
      "Trustworthy AI’s first component (lawful AI).1 Instead, it aims to offer guidance on the second and third \n",
      "components: fostering and securing ethical and robust AI. Addressed to all stakeholders, these Guidelines seek to go \n",
      "beyond a list of ethical principles, by providing guidance on how such principles can be operationalised in socio-\n",
      "technical systems. Guidance is provided in three layers of abstraction, from the most abstract in Chapter I to the \n",
      "most concrete in Chapter III, closing with examples of opportunities and critical concerns raised by AI systems. \n",
      "I. \n",
      "Based on an approach founded on fundamental rights, Chapter I identifies the ethical principles and their \n",
      "correlated values that must be respected in the development, deployment and use of AI systems.  \n",
      "Key guidance derived from Chapter I: \n",
      " Develop, deploy and use AI systems in a way that adheres to the ethical principles of: respect for human \n",
      "autonomy, prevention of harm, fairness and explicability. Acknowledge and address the potential tensions \n",
      "between these principles.  \n",
      " Pay particular attention to situations involving more vulnerable groups such as children, persons with \n",
      "disabilities and others that have historically been disadvantaged or are at risk of exclusion, and to situations \n",
      "which are characterised by asymmetries of power or information, such as between employers and workers, \n",
      "or between businesses and consumers.2 \n",
      " Acknowledge that, while bringing substantial benefits to individuals and society, AI systems also pose \n",
      "certain risks and may have a negative impact, including impacts which may be difficult to anticipate, \n",
      "identify or measure (e.g. on democracy, the rule of law and distributive justice, or on the human mind \n",
      "itself.) Adopt adequate measures to mitigate these risks when appropriate, and proportionately to the \n",
      "magnitude of the risk. \n",
      "II. Drawing upon Chapter I, Chapter II provides guidance on how Trustworthy AI can be realised, by listing seven \n",
      "requirements that AI systems should meet. Both technical and non-technical methods can be used for their \n",
      "implementation.  \n",
      "Key guidance derived from Chapter II: \n",
      " Ensure that the development, deployment and use of AI systems meets the seven key requirements for \n",
      "Trustworthy AI: (1) human agency and oversight, (2) technical robustness and safety, (3) privacy and data \n",
      "governance, (4) transparency, (5) diversity, non-discrimination and fairness, (6) environmental and societal \n",
      "well-being and (7) accountability.  \n",
      " Consider technical and non-technical methods to ensure the implementation of those requirements.  \n",
      "                                                          \n",
      "1  \n",
      "All normative statements in this document aim to reflect guidance towards achieving the second and third component of \n",
      "trustworthy AI (ethical and robust AI). These statements are hence not meant to provide legal advice or to offer guidance on \n",
      "compliance with applicable laws, though it is acknowledged that many of these statements are to some extent already reflected \n",
      "in existing laws. In this regard, see §21 and following.  \n",
      "2  \n",
      "See articles 24 to 27 of the Charter of Fundamental Rights of the EU (EU Charter), dealing with the rights of the child and the \n",
      "elderly, the integration of persons with disabilities and workers’ rights. See also article 38 dealing with consumer protection.  \n",
      "\n",
      "\n",
      "--- Página real 6 (índice útil 3) ---\n",
      "4 \n",
      " \n",
      "A. INTRODUCTION \n",
      "In its Communication of 25 April 2018 and 7 December 2018, the European Commission set out its vision for \n",
      "artificial intelligence (AI), which supports “ethical, secure and cutting-edge AI made in Europe”.5 Three pillars \n",
      "underpin the Commission’s vision: (i) increasing public and private investments in AI to boost its uptake, (ii) \n",
      "preparing for socio-economic changes, and (iii) ensuring an appropriate ethical and legal framework to strengthen \n",
      "European values. \n",
      "To support the implementation of this vision, the Commission established the High-Level Expert Group on Artificial \n",
      "Intelligence (AI HLEG), an independent group mandated with the drafting of two deliverables: (1) AI Ethics \n",
      "Guidelines and (2) Policy and Investment Recommendations.  \n",
      "This document contains the AI Ethics Guidelines, which have been revised following further deliberation by our \n",
      "Group in light of feedback received from the public consultation on the draft published on 18 December 2018. It \n",
      "builds on the work of the European Group on Ethics in Science and New Technologies6 and takes inspiration from \n",
      "other similar efforts.7 \n",
      "Over the past months, the 52 of us met, discussed and interacted, committed to the European motto: united in \n",
      "diversity. We believe that AI has the potential to significantly transform society. AI is not an end in itself, but rather \n",
      "a promising means to increase human flourishing, thereby enhancing individual and societal well-being and the \n",
      "common good, as well as bringing progress and innovation. In particular, AI systems can help to facilitate the \n",
      "achievement of the UN’s Sustainable Development Goals, such as promoting gender balance and tackling climate \n",
      "change, rationalising our use of natural resources, enhancing our health, mobility and production processes, and \n",
      "supporting how we monitor progress against sustainability and social cohesion indicators. \n",
      "To do this, AI systems8 need to be human-centric, resting on a commitment to their use in the service of humanity \n",
      "and the common good, with the goal of improving human welfare and freedom. While offering great opportunities, \n",
      "AI systems also give rise to certain risks that must be handled appropriately and proportionately. We now have an \n",
      "important window of opportunity to shape their development. We want to ensure that we can trust the socio-\n",
      "technical environments in which they are embedded. We also want producers of AI systems to get a competitive \n",
      "advantage by embedding Trustworthy AI in their products and services. This entails seeking to maximise the \n",
      "benefits of AI systems while at the same time preventing and minimising their risks.   \n",
      "In a context of rapid technological change, we believe it is essential that trust remains the bedrock of societies, \n",
      "communities, economies and sustainable development. We therefore identify Trustworthy AI as our foundational \n",
      "ambition, since human beings and communities will only be able to have confidence in the technology’s \n",
      "development and its applications when a clear and comprehensive framework for achieving its trustworthiness is in \n",
      "place.  \n",
      "This is the path that we believe Europe should follow to become the home and leader of cutting-edge and ethical \n",
      "technology. It is through Trustworthy AI that we, as European citizens, will seek to reap its benefits in a way that is \n",
      "aligned with our foundational values of respect for human rights, democracy and the rule of law. \n",
      "Trustworthy AI \n",
      "Trustworthiness is a prerequisite for people and societies to develop, deploy and use AI systems. Without AI \n",
      "systems – and the human beings behind them – being demonstrably worthy of trust, unwanted consequences may \n",
      "ensue and their uptake might be hindered, preventing the realisation of the potentially vast social and economic \n",
      "                                                          \n",
      "5  \n",
      " COM(2018)237 and COM(2018)795. Note that the term “made in Europe” is used throughout the Commission’s communication. \n",
      "The scope of these Guidelines however aims to encompass not only those AI systems made in Europe, but also those developed \n",
      "elsewhere and deployed or used in Europe. Throughout this document, we hence aim to promote trustworthy AI “for” Europe.  \n",
      "6  \n",
      " The European Group on Ethics in Science and New Technologies (EGE) is an advisory group of the Commission. \n",
      "7  \n",
      " See Section 3.3 of COM(2018)237. \n",
      "8  \n",
      " The Glossary at the end of this document provides a definition of AI systems for the purpose of this document. This definition is \n",
      "further elaborated on in a dedicated document prepared by the AI HLEG that accompanies these Guidelines, titled \"A definition \n",
      "of AI: Main capabilities and scientific disciplines\". \n",
      "\n",
      "\n",
      "--- eu_ai_act_regulation.pdf (94 páginas útiles) ---\n",
      "\n",
      "--- Página real 2 (índice útil 1) ---\n",
      "EN \n",
      "1 \n",
      " EN \n",
      "EXPLANATORY MEMORANDUM \n",
      "1. \n",
      "CONTEXT OF THE PROPOSAL \n",
      "1.1. \n",
      "Reasons for and objectives of the proposal \n",
      "This explanatory memorandum accompanies the proposal for a Regulation laying down \n",
      "harmonised rules on artificial intelligence (Artificial Intelligence Act). Artificial Intelligence \n",
      "(AI) is a fast evolving family of technologies that can bring a wide array of economic and \n",
      "societal benefits across the entire spectrum of industries and social activities. By improving \n",
      "prediction, optimising operations and resource allocation, and personalising service delivery, \n",
      "the use of artificial intelligence can support socially and environmentally beneficial outcomes \n",
      "and provide key competitive advantages to companies and the European economy. Such \n",
      "action is especially needed in high-impact sectors, including climate change, environment and \n",
      "health, the public sector, finance, mobility, home affairs and agriculture. However, the same \n",
      "elements and techniques that power the socio-economic benefits of AI can also bring about \n",
      "new risks or negative consequences for individuals or the society. In light of the speed of \n",
      "technological change and possible challenges, the EU is committed to strive for a balanced \n",
      "approach. It is in the Union interest to preserve the EU’s technological leadership and to \n",
      "ensure that Europeans can benefit from new technologies developed and functioning \n",
      "according to Union values, fundamental rights and principles. \n",
      "This proposal delivers on the political commitment by President von der Leyen, who \n",
      "announced in her political guidelines for the 2019-2024 Commission “A Union that strives for \n",
      "more”1, that the Commission would put forward legislation for a coordinated European \n",
      "approach on the human and ethical implications of AI. Following on that announcement, on \n",
      "19 February 2020 the Commission published the White Paper on AI - A European approach \n",
      "to excellence and trust2. The White Paper sets out policy options on how to achieve the twin \n",
      "objective of promoting the uptake of AI and of addressing the risks associated with certain \n",
      "uses of such technology. This proposal aims to implement the second objective for the \n",
      "development of an ecosystem of trust by proposing a legal framework for trustworthy AI. The \n",
      "proposal is based on EU values and fundamental rights and aims to give people and other \n",
      "users the confidence to embrace AI-based solutions, while encouraging businesses to develop \n",
      "them. AI should be a tool for people and be a force for good in society with the ultimate aim \n",
      "of increasing human well-being. Rules for AI available in the Union market or otherwise \n",
      "affecting people in the Union should therefore be human centric, so that people can trust that \n",
      "the technology is used in a way that is safe and compliant with the law, including the respect \n",
      "of fundamental rights. Following the publication of the White Paper, the Commission \n",
      "launched a broad stakeholder consultation, which was met with a great interest by a large \n",
      "number of stakeholders who were largely supportive of regulatory intervention to address the \n",
      "challenges and concerns raised by the increasing use of AI.  \n",
      "The proposal also responds to explicit requests from the European Parliament (EP) and the \n",
      "European Council, which have repeatedly expressed calls for legislative action to ensure a \n",
      "well-functioning internal market for artificial intelligence systems (‘AI systems’) where both \n",
      "benefits and risks of AI are adequately addressed at Union level. It supports the objective of \n",
      "the Union being a global leader in the development of secure, trustworthy and ethical artificial \n",
      "                                                 \n",
      "1 \n",
      "https://ec.europa.eu/commission/sites/beta-political/files/political-guidelines-next-commission_en.pdf \n",
      "2 \n",
      "European Commission, White Paper on Artificial Intelligence - A European approach to excellence and \n",
      "trust, COM(2020) 65 final, 2020. \n",
      "\n",
      "\n",
      "--- Página real 4 (índice útil 3) ---\n",
      "EN \n",
      "3 \n",
      " EN \n",
      "proposal takes into account the aforementioned resolution of the European Parliament in full \n",
      "respect of proportionality, subsidiarity and better law making principles.  \n",
      "Against this political context, the Commission puts forward the proposed regulatory \n",
      "framework on Artificial Intelligence with the following specific objectives: \n",
      " ensure that AI systems placed on the Union market and used are safe and respect \n",
      "existing law on fundamental rights and Union values; \n",
      " ensure legal certainty to facilitate investment and innovation in AI; \n",
      " enhance governance and effective enforcement of existing law on fundamental \n",
      "rights and safety requirements applicable to AI systems; \n",
      " facilitate the development of a single market for lawful, safe and trustworthy AI \n",
      "applications and prevent market fragmentation. \n",
      "To achieve those objectives, this proposal presents a balanced and proportionate horizontal \n",
      "regulatory approach to AI that is limited to the minimum necessary requirements to address \n",
      "the risks and problems linked to AI, without unduly constraining or hindering technological \n",
      "development or otherwise disproportionately increasing the cost of placing AI solutions on \n",
      "the market. The proposal sets a robust and flexible legal framework. On the one hand, it is \n",
      "comprehensive and future-proof in its fundamental regulatory choices, including the \n",
      "principle-based requirements that AI systems should comply with. On the other hand, it puts \n",
      "in place a proportionate regulatory system centred on a well-defined risk-based regulatory \n",
      "approach that does not create unnecessary restrictions to trade, whereby legal intervention is \n",
      "tailored to those concrete situations where there is a justified cause for concern or where such \n",
      "concern can reasonably be anticipated in the near future. At the same time, the legal \n",
      "framework includes flexible mechanisms that enable it to be dynamically adapted as the \n",
      "technology evolves and new concerning situations emerge. \n",
      "The proposal sets harmonised rules for the development, placement on the market and use of \n",
      "AI systems in the Union following a proportionate risk-based approach. It proposes a single \n",
      "future-proof definition of AI. Certain particularly harmful AI practices are prohibited as \n",
      "contravening Union values, while specific restrictions and safeguards are proposed in relation \n",
      "to certain uses of remote biometric identification systems for the purpose of law enforcement. \n",
      "The proposal lays down a solid risk methodology to define “high-risk” AI systems that pose \n",
      "significant risks to the health and safety or fundamental rights of persons. Those AI systems \n",
      "will have to comply with a set of horizontal mandatory requirements for trustworthy AI and \n",
      "follow conformity assessment procedures before those systems can be placed on the Union \n",
      "market. Predictable, proportionate and clear obligations are also placed on providers and users \n",
      "of those systems to ensure safety and respect of existing legislation protecting fundamental \n",
      "rights throughout the whole AI systems’ lifecycle. For some specific AI systems, only \n",
      "minimum transparency obligations are proposed, in particular when chatbots or ‘deep fakes’ \n",
      "are used.  \n",
      "The proposed rules will be enforced through a governance system at Member States level, \n",
      "building on already existing structures, and a cooperation mechanism at Union level with the \n",
      "establishment of a European Artificial Intelligence Board. Additional measures are also \n",
      "proposed to support innovation, in particular through AI regulatory sandboxes and other \n",
      "measures to reduce the regulatory burden and to support Small and Medium-Sized Enterprises \n",
      "(‘SMEs’) and start-ups. \n",
      "\n",
      "\n",
      "--- nist_privacy_framework_v1.pdf (39 páginas útiles) ---\n",
      "\n",
      "--- Página real 5 (índice útil 1) ---\n",
      "NIST Privacy Framework \n",
      " \n",
      "January 16, 2020 \n",
      "1 \n",
      " \n",
      " \n",
      "1.0 Privacy Framework Introduction \n",
      "For more than two decades, the Internet and associated information technologies have driven \n",
      "unprecedented innovation, economic value, and access to social services. Many of these benefits are \n",
      "fueled by data about individuals that flow through a complex ecosystem. As a result, individuals may not \n",
      "be able to understand the potential consequences for their privacy as they interact with systems, \n",
      "products, and services. Organizations may not fully realize the consequences either. Failure to manage \n",
      "privacy risks can have direct adverse consequences at both the individual and societal levels, with \n",
      "follow-on effects on organizations’ brands, bottom lines, and future prospects for growth. Finding ways \n",
      "to continue to derive benefits from data processing while simultaneously protecting individuals’ privacy \n",
      "is challenging, and not well-suited to one-size-fits-all solutions. \n",
      "Privacy is challenging because not only is it an all-encompassing concept that helps to safeguard \n",
      "important values such as human autonomy and dignity, but also the means for achieving it can vary.3 For \n",
      "example, privacy can be achieved through seclusion, limiting observation, or individuals’ control of \n",
      "facets of their identities (e.g., body, data, reputation).4 Moreover, human autonomy and dignity are not \n",
      "fixed, quantifiable constructs; they are filtered through cultural diversity and individual differences. This \n",
      "broad and shifting nature of privacy makes it difficult to communicate clearly about privacy risks within \n",
      "and between organizations and with individuals. What has been missing is a common language and \n",
      "practical tool that is flexible enough to address diverse privacy needs. \n",
      "This voluntary NIST Privacy Framework: A Tool for Improving Privacy through Enterprise Risk \n",
      "Management (Privacy Framework) is intended to be widely usable by organizations of all sizes and \n",
      "agnostic to any particular technology, sector, law, or jurisdiction. Using a common approach—adaptable \n",
      "to any organization’s role(s) in the data processing ecosystem—the Privacy Framework’s purpose is to \n",
      "help organizations manage privacy risks by: \n",
      "• \n",
      "Taking privacy into account as they design and deploy systems, products, and services that \n",
      "affect individuals; \n",
      "• \n",
      "Communicating about their privacy practices; and \n",
      "• \n",
      "Encouraging cross-organizational workforce collaboration—for example, among executives, \n",
      "legal, and information technology (IT)—through the development of Profiles, selection of Tiers, \n",
      "and achievement of outcomes. \n",
      "                                                 \n",
      "3  \n",
      "Autonomy and dignity are concepts covered in the United Nations Universal Declaration of Human Rights at \n",
      "https://www.un.org/en/universal-declaration-human-rights/. \n",
      "4  \n",
      "There are many publications that provide an in-depth treatment on the background of privacy or different \n",
      "aspects of the concept. For two examples, see Solove D (2010) Understanding Privacy (Harvard University \n",
      "Press, Cambridge, MA), https://ssrn.com/abstract=1127888; and Selinger E, Hartzog W (2017) Obscurity and \n",
      "Privacy, Spaces for the Future: A Companion to Philosophy of Technology, eds Pitt J, Shew A (Taylor & Francis, \n",
      "New York, NY), Chapter 12, 1st Ed., https://doi.org/10.4324/9780203735657. \n",
      "\n",
      "\n",
      "--- Página real 7 (índice útil 3) ---\n",
      "NIST Privacy Framework \n",
      " \n",
      "January 16, 2020 \n",
      "3 \n",
      " \n",
      " \n",
      "about privacy risk management. Appendix D provides additional information on key privacy risk \n",
      "management practices. \n",
      "1.2.1  Cybersecurity and Privacy Risk Management \n",
      "Since its release in 2014, the Cybersecurity \n",
      "Framework has helped organizations to \n",
      "communicate and manage cybersecurity \n",
      "risk. [1] While managing cybersecurity \n",
      "risk contributes to managing privacy risk, \n",
      "it is not sufficient, as privacy risks can \n",
      "also arise by means unrelated to \n",
      "cybersecurity incidents, as illustrated by \n",
      "Figure 2. Having a general understanding \n",
      "of the different origins of cybersecurity \n",
      "and privacy risks is important for \n",
      "determining the most effective solutions to \n",
      "address the risks. \n",
      "The Privacy Framework approach to privacy \n",
      "risk is to consider privacy events as potential problems individuals could experience arising from system, \n",
      "product, or service operations with data, whether in digital or non-digital form, through a complete life \n",
      "cycle from data collection through disposal. \n",
      "The Privacy Framework describes these data operations in the singular as a data action and collectively \n",
      "as data processing. The problems individuals can experience as a result of data \n",
      "processing can be expressed in various ways, but NIST describes them as \n",
      "ranging from dignity-type effects such as embarrassment or stigmas to more \n",
      "tangible harms such as discrimination, economic loss, or physical harm.6 \n",
      "The basis for the problems that individuals may experience can vary. As \n",
      "depicted in Figure 2, problems arise as an adverse effect of data processing \n",
      "that organizations conduct to meet their mission or business objectives. An \n",
      "example is the concerns that certain communities had about the installation of \n",
      "“smart meters” as part of the Smart Grid, a nationwide technological effort to \n",
      "increase energy efficiency.7 The ability of these meters to collect, record, and \n",
      "distribute highly granular information about household electrical use could \n",
      "provide insight into people’s behavior inside their homes.8 The meters were \n",
      "                                                 \n",
      "6  \n",
      "NIST has created an illustrative catalog of problems for use in privacy risk assessment. See NIST Privacy Risk \n",
      "Assessment Methodology [3]. Other organizations may have created other categories of problems, or may \n",
      "refer to them as adverse consequences or harms. \n",
      "7  \n",
      "See, for example, NIST Interagency or Internal Report (IR) 7628 Revision 1 Volume 1, Guidelines for Smart Grid \n",
      "Cybersecurity: Volume 1 – Smart Grid Cybersecurity Strategy, Architecture, and High-Level Requirements at [4] \n",
      "p. 26. \n",
      "8  \n",
      "See NIST IR 8062, An Introduction to Privacy Engineering and Risk Management in Federal Systems at [5] p. 2. \n",
      "For additional types of privacy risks associated with adverse effects on individuals of data processing, see \n",
      "Appendix E of NIST IR 8062. \n",
      " \n",
      "Data Action \n",
      "A data life cycle \n",
      "operation, including, \n",
      "but not limited to \n",
      "collection, retention, \n",
      "logging, generation, \n",
      "transformation, use, \n",
      "disclosure, sharing, \n",
      "transmission, and \n",
      "disposal. \n",
      " \n",
      "Data Processing \n",
      "The collective set of \n",
      "data actions. \n",
      "Figure 2: Cybersecurity and Privacy Risk \n",
      "Relationship \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "  \n",
      "Cybersecurity \n",
      "Risks   \n",
      "Privacy \n",
      "Risks \n",
      "associated with \n",
      "cybersecurity \n",
      "incidents arising from \n",
      "loss of confidentiality, \n",
      "integrity, or \n",
      "availability \n",
      "associated with \n",
      "privacy events \n",
      "arising from data \n",
      "processing \n",
      "cyber \n",
      "security-\n",
      "related \n",
      "privacy \n",
      "events \n",
      "\n",
      "\n",
      "--- oecd_ai_classification_framework.pdf (52 páginas útiles) ---\n",
      "\n",
      "--- Página real 16 (índice útil 1) ---\n",
      "16    OECD FRAMEWORK FOR THE CLASSIFICATION OF AI SYSTEMS \n",
      " © OECD 2022 \n",
      "  \n",
      "Different types of AI systems raise different policy opportunities and challenges. Section 2 of this report \n",
      "introduces and describes a framework to assess AI systems’ impact on public policy in areas covered by \n",
      "the OECD AI Principles (OECD, 2019d[1]). Section 3 puts the framework into use to classify specific AI \n",
      "systems and applications. Section 4 discusses how the framework could be used to help assess basic \n",
      "social, physical and ethical risks associated with specific types of AI systems.  \n",
      "Introducing the framework and its purpose \n",
      "The framework primary purpose is to characterise the application of an AI system deployed in a specific \n",
      "project and context, although some dimensions are also relevant to generic AI systems. It classifies AI \n",
      "systems and applications along the following dimensions: People & Planet, Economic Context, Data & \n",
      "Input, AI Model and Task & Output (Figure 1). These dimensions build on the conceptual view of a generic \n",
      "AI system established in previous OECD work (see Box 1 later in this section).  \n",
      "Figure 1. Key high-level dimensions of the OECD Framework for the Classification of AI Systems  \n",
      " \n",
      "The AI Principles as a lens for analysing policy considerations  \n",
      "Each of the framework’s dimensions has distinct properties and attributes, or sub-dimensions that are \n",
      "relevant to assessing policy considerations associated with a particular AI system. The 10 OECD AI \n",
      "Principles, adopted in 2019, help structure the analysis of policy considerations associated with each \n",
      "dimension and sub-dimension. The Principles cover the following themes: \n",
      "Table 1. The OECD AI Principles \n",
      "Values-based principles for all AI actors \n",
      "Recommendations to policy makers for AI policies  \n",
      "Principle 1.1. People and planet  \n",
      "Principle 2.1. Investment in R&D  \n",
      "Principle 1.2. Human rights, privacy, fairness \n",
      "Principle 2.2. Data, compute, technologies \n",
      "Principle 1.3. Transparency, explainability \n",
      "Principle 2.3. Enabling policy and regulatory environment  \n",
      "Principle 1.4. Robustness, security, safety \n",
      "Principle 2.4. Jobs, automation, skills \n",
      "Principle 1.5. Accountability \n",
      "Principle 2.5. International cooperation \n",
      "Source: (OECD, 2019d[1]) \n",
      "1 Overview and goal of the framework  \n",
      "\n",
      "\n",
      "--- Página real 18 (índice útil 3) ---\n",
      "18    OECD FRAMEWORK FOR THE CLASSIFICATION OF AI SYSTEMS \n",
      " © OECD 2022 \n",
      "  \n",
      "Table 2. Classification framework dimensions and criteria at a glance \n",
      "PEOPLE & PLANET \n",
      "Criteria \n",
      "Description \n",
      "USERS \n",
      "Users of AI system \n",
      "What is the level of competency of users who interact with the system? \n",
      "STAKEHOLDERS \n",
      "Impacted stakeholders \n",
      "Who is impacted by the system (e.g. consumers, workers, government agencies)? \n",
      "OPTIONALITY \n",
      "Optionality and redress \n",
      "Can users opt out, e.g. switch systems? Can users challenge or correct the output? \n",
      "HUMAN RIGHTS \n",
      "Human rights and democratic values Can the system’s outputs impact fundamental human rights (e.g. human dignity, \n",
      "privacy, freedom of expression, non-discrimination, fair trial, remedy, safety)? \n",
      "WELL-BEING & \n",
      "ENVIRONMENT \n",
      "Well-being, society and the \n",
      "environment \n",
      "Can the system’s outputs impact areas of life related to well-being (e.g. job quality, \n",
      "the environment, health, social interactions, civic engagement, education)? \n",
      "DISPLACEMENT \n",
      "{Displacement potential} \n",
      "Could the system automate tasks that are or were being executed by humans? \n",
      "ECONOMIC CONTEXT \n",
      "Criteria \n",
      "Description \n",
      "SECTOR \n",
      "Industrial sector \n",
      "Which industrial sector is the system deployed in (e.g. finance, agriculture)? \n",
      "BUSINESS FUNCTION & \n",
      "MODEL \n",
      "Business function \n",
      "What business function(s) is the system employed in (e.g. sales, customer service)? \n",
      "Business model \n",
      "Is the system a for-profit use, non-profit use or public service system? \n",
      "CRITICALITY \n",
      "Impacts critical functions / activities \n",
      "Would a disruption of the system’s function / activity affect essential services? \n",
      "SCALE & MATURITY \n",
      "Breadth of deployment \n",
      "Is the AI system deployment a pilot, narrow, broad or widespread? \n",
      "{Technical maturity} \n",
      "How technically mature is the system (Technology Readiness Level –TRL) \n",
      "DATA & INPUT \n",
      "Criteria \n",
      "Description \n",
      "COLLECTION \n",
      "Detection and collection  \n",
      "Are the data and input collected by humans, automated sensors or both? \n",
      " \n",
      "Provenance of data and input \n",
      "Are the data and input from experts; provided, observed, synthetic or derived?  \n",
      " \n",
      "Dynamic nature  \n",
      "Are the data dynamic, static, dynamic updated from time to time or real-time?  \n",
      "RIGHTS & \n",
      "IDENTIFIABILITY \n",
      "Rights  \n",
      "Are the data proprietary, public or personal data (related to identifiable individual)? \n",
      "“Identifiability” of personal data \n",
      "If personal data, are they anonymised; pseudonymised? \n",
      "STRUCTURE & FORMAT {Structure of data and input} \n",
      "Are the data structured, semi-structured, complex structured or unstructured? \n",
      "{Format of data and metadata} \n",
      "Is the format of the data and metadata standardised or non-standardised? \n",
      "SCALE \n",
      "{Scale} \n",
      "What is the dataset’s scale? \n",
      "QUALITY AND \n",
      "APPROPRIATENESS \n",
      "{Data quality and appropriateness} \n",
      "Is the dataset fit for purpose? Is the sample size adequate? Is it representative and \n",
      "complete enough? How noisy are the data?  \n",
      "AI MODEL \n",
      "Criteria \n",
      "Description \n",
      "MODEL \n",
      "CHARACTERISTICS \n",
      "Model information availability \n",
      "Is any information available about the system’s model? \n",
      "AI model type \n",
      "Is the model symbolic (human-generated rules), statistical (uses data) or hybrid? \n",
      "{Rights associated with model} \n",
      "Is the model open-source or proprietary, self or third-party managed? \n",
      "{Discriminative or generative} \n",
      "Is the model generative, discriminative or both? \n",
      "{Single or multiple model(s)} \n",
      "Is the system composed of one model or several interlinked models? \n",
      "MODEL-BUILDING \n",
      "Model-building from machine or \n",
      "human knowledge \n",
      "Does the system learn based on human-written rules, from data, through supervised \n",
      "learning, through reinforcement learning? \n",
      "Model evolution in the field ML \n",
      "Does the model evolve and / or acquire abilities from interacting with data in the field? \n",
      "Central or federated learning ML \n",
      "Is the model trained centrally or in a number of local servers or “edge” devices? \n",
      "MODEL INFERENCE \n",
      "{Model development / maintenance} \n",
      "Is the model universal, customisable or tailored to the AI actor’s data? \n",
      "{Deterministic and probabilistic} \n",
      "Is the model used in a deterministic or probabilistic manner? \n",
      "Transparency and explainability \n",
      "If information available to users to allow them to understand model outputs? \n",
      "TASK & OUTPUT \n",
      "Criteria \n",
      "Description \n",
      "TASKS \n",
      "Task(s) of the system \n",
      "What tasks does the system perform (e.g. recognition, event detection, forecasting)? \n",
      " \n",
      "{Combining tasks and actions into \n",
      "composite systems} \n",
      "Does the system combine several tasks and actions (e.g. content generation \n",
      "systems, autonomous systems, control systems)? \n",
      "ACTION \n",
      "Action autonomy \n",
      "How autonomous are the system’s actions and what role do humans play? \n",
      "APPLICATION AREA \n",
      "Core application area(s) \n",
      "Does the system belong to a core application area such as human language \n",
      "technologies, computer vision, automation and / or optimisation or robotics? \n",
      "EVALUATION \n",
      "{Evaluation methods} \n",
      "Are standards or methods available for evaluating system output? \n",
      "Note: Criteria and descriptions in grey and marked with an {} symbol = those where objective and consistent information is available. ML = for \n",
      "machine learning AI models. \n",
      "\n",
      "\n",
      "--- oecd_legal_0449_en.pdf (7 páginas útiles) ---\n",
      "\n",
      "--- Página real 3 (índice útil 1) ---\n",
      "Date(s)\n",
      "Adopted on 22/05/2019\n",
      "Background Information\n",
      "The Recommendation on Artificial Intelligence (AI) – the first intergovernmental standard on AI –\n",
      "was adopted by the OECD Council at Ministerial level on 22 May 2019 on the proposal of the\n",
      "Committee on Digital Economy Policy (CDEP). The Recommendation aims to foster innovation and\n",
      "trust in AI by promoting the responsible stewardship of trustworthy AI while ensuring respect for\n",
      "human rights and democratic values. Complementing existing OECD standards in areas such as\n",
      "privacy, digital security risk management, and responsible business conduct, the Recommendation\n",
      "focuses on AI-specific issues and sets a standard that is implementable and sufficiently flexible to\n",
      "stand the test of time in this rapidly evolving field. \n",
      "The Recommendation identifies five complementary values-based principles for the responsible\n",
      "stewardship of trustworthy AI and calls on AI actors to promote and implement them: \n",
      "inclusive growth, sustainable development and well-being;\n",
      "human-centred values and fairness;\n",
      "transparency and explainability;\n",
      "robustness, security and safety;\n",
      "and accountability.\n",
      "In addition to and consistent with these value-based principles, the Recommendation also provides\n",
      "five recommendations to policy-makers pertaining to national policies and international co-operation\n",
      "for trustworthy AI, namely: \n",
      "investing in AI research and development;\n",
      "fostering a digital ecosystem for AI;\n",
      "shaping an enabling policy environment for AI;\n",
      "building human capacity and preparing for labour market transformation;\n",
      "and international co-operation for trustworthy AI.\n",
      "The Recommendation also includes a provision for the development of metrics to measure AI\n",
      "research, development and deployment, and for building an evidence base to assess progress in its\n",
      "implementation.\n",
      "The OECD’s  work on Artificial Intelligence and rationale for developing the OECD\n",
      "Recommendation on Artificial Intelligence\n",
      "Artificial Intelligence (AI) is a general-purpose technology that has the potential to improve the\n",
      "welfare and well-being of people, to contribute to positive sustainable global economic activity, to\n",
      "increase innovation and productivity, and to help respond to key global challenges. It is deployed in\n",
      "many sectors ranging from production, finance and transport to healthcare and security. \n",
      "Alongside benefits, AI also raises challenges for our societies and economies, notably regarding\n",
      "economic shifts and inequalities, competition, transitions in the labour market, and implications for\n",
      "democracy and human rights.\n",
      "The OECD has undertaken empirical and policy activities on AI in support of the policy debate over\n",
      "the past two years, starting with a Technology Foresight Forum on AI in 2016 and an international\n",
      "conference on AI: Intelligent Machines, Smart Policies  in 2017. The Organisation also conducted\n",
      "analytical and measurement work that provides an overview of the AI technical landscape, maps\n",
      "economic and social impacts of AI technologies and their applications, identifies major policy\n",
      "considerations, and describes AI initiatives from governments and other stakeholders at national and\n",
      "international levels.\n",
      "\n",
      "\n",
      "--- Página real 5 (índice útil 3) ---\n",
      "Follow-up, monitoring of implementation and dissemination tools\n",
      "The OECD Recommendation on AI provides the first intergovernmental standard for AI policies and\n",
      "a foundation on which to conduct further analysis and develop tools to support governments in their\n",
      "implementation efforts. In this regard, it instructs the CDEP to monitor the implementation of the\n",
      "Recommendation and report to the Council on its implementation and continued relevance five years\n",
      "after its adoption and regularly thereafter. The CDEP is also instructed to continue its work on AI,\n",
      "building on this Recommendation, and taking into account work in other international fora, such as\n",
      "UNESCO, the Council of Europe and the initiative to build an International Panel on\n",
      "AI \n",
      "(see \n",
      "https://pm.gc.ca/eng/news/2018/12/06/mandate-international-panel-artificial-\n",
      "intelligence and https://www.gouvernement.fr/en/france-and-canada-create-new-expert-international-\n",
      "panel-on-artificial-intelligence).\n",
      "In order to support implementation of the Recommendation, the Council instructed the CDEP to\n",
      "develop practical guidance for implementation, to provide a forum for exchanging information on AI\n",
      "policy and activities, and to foster multi-stakeholder and interdisciplinary dialogue. This will be\n",
      "achieved largely through the OECD AI Policy Observatory, an inclusive hub for public policy on AI\n",
      "that aims to help countries encourage, nurture and monitor the responsible development of\n",
      "trustworthy artificial intelligence systems for the benefit of society. It will combine resources from\n",
      "across the OECD with those of partners from all stakeholder groups to provide multidisciplinary,\n",
      "evidence-based policy analysis on AI. The Observatory is planned to be launched late 2019 and will\n",
      "include a live database of AI strategies, policies and initiatives that countries and other stakeholders\n",
      "can share and update, enabling the comparison of their key elements in an interactive manner. It will\n",
      "also be continuously updated with AI metrics, measurements, policies and good practices that could\n",
      "lead to further updates in the practical guidance for implementation. \n",
      "The Recommendation is open to non-OECD Member adherence, underscoring the global relevance\n",
      "of OECD AI policy work as well as the Recommendation’s call for international co-operation. \n",
      "For further information please consult: oecd.ai.\n",
      "Contact information: ai@oecd.org.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "\n",
    "# zero-based index\n",
    "pages_dict = {\n",
    "    \"oecd_legal_0449_en.pdf\": range(2, 9),\n",
    "    \"eu_ai_act_regulation.pdf\": range(1, 95),\n",
    "    \"oecd_ai_classification_framework.pdf\": range(15, 67),\n",
    "    \"ai_hleg_ethics_guidelines.pdf\": range(3, 37),\n",
    "    \"nist_privacy_framework_v1.pdf\": range(4, 43),\n",
    "}\n",
    "\n",
    "for pdf_file in pdf_files:\n",
    "    if pdf_file not in pages_dict:\n",
    "        continue\n",
    "    pdf_path = os.path.join(pdf_dir, pdf_file)\n",
    "    doc = fitz.open(pdf_path)\n",
    "    page_idxs = list(pages_dict[pdf_file])\n",
    "    print(f\"\\n--- {pdf_file} ({len(page_idxs)} páginas útiles) ---\")\n",
    "\n",
    "    for idx, pagina_idx in enumerate([0, 2]):\n",
    "        if pagina_idx >= len(page_idxs):\n",
    "            continue\n",
    "        p = page_idxs[pagina_idx]\n",
    "        page = doc.load_page(p)\n",
    "        print(f\"\\n--- Página real {p+1} (índice útil {pagina_idx+1}) ---\")\n",
    "        print(page.get_text())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf40b77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
